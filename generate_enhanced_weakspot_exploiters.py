#!/usr/bin/env python3
"""
Enhanced Weakspot Exploiters Generator (Version 3.0)
Adds sophisticated vulnerability patterns, situational analysis, and predictive modeling
"""

import json
import os
import sys
import csv
from datetime import datetime, timedelta
from pathlib import Path
import re
from collections import defaultdict

# Import centralized configuration
sys.path.append(str(Path(__file__).parent.parent / 'BaseballScraper'))
from config import PATHS, DATA_PATH

# Team normalization utilities for CHW/CWS and other team abbreviation mismatches
TEAM_MAPPINGS = {
    # Forward mappings (less common â†’ standard)
    'ATH': 'OAK',  # Athletics
    'CWS': 'CHW',  # White Sox  
    'LAD': 'LA',   # Dodgers
    'NYM': 'NYN',  # Mets
    'NYY': 'NY',   # Yankees
    'SD': 'SDN',   # Padres
    'SF': 'SFN',   # Giants
    'TB': 'TBR',   # Rays
    'WSH': 'WAS',  # Nationals
    
    # Reverse mappings (standard â†’ less common)
    'OAK': 'ATH',
    'CHW': 'CWS', 
    'LA': 'LAD',
    'NYN': 'NYM',
    'NY': 'NYY',
    'SDN': 'SD',
    'SFN': 'SF',
    'TBR': 'TB',
    'WAS': 'WSH'
}

def teams_match(team1: str, team2: str) -> bool:
    """Check if two team abbreviations refer to the same team"""
    if not team1 or not team2:
        return False
    
    team1_upper = team1.upper()
    team2_upper = team2.upper()
    
    # Direct match
    if team1_upper == team2_upper:
        return True
    
    # Check if they map to each other
    return (TEAM_MAPPINGS.get(team1_upper) == team2_upper or 
            TEAM_MAPPINGS.get(team2_upper) == team1_upper)

class EnhancedWeakspotAnalyzer:
    def __init__(self, base_path=None, target_date=None):
        # Use centralized data configuration
        self.base_path = DATA_PATH.parent  # BaseballData
        self.stats_path = DATA_PATH / "stats"
        self.data_path = DATA_PATH
        self.target_date = target_date or datetime.now().strftime('%Y-%m-%d')
        
        # Professional data containers
        self.hitter_exit_velocity = {}
        self.pitcher_exit_velocity = {}
        self.custom_batters = {}
        self.custom_pitchers = {}
        self.pitcher_arsenal = {}
        self.handedness_data = {}
        self.rosters = {}
        
        # Enhanced analytics containers
        self.recent_performance = {}
        self.platoon_splits = {}
        self.situational_stats = {}
        self.pitcher_trends = {}
        self.batter_trends = {}
        self.park_factors = {}
        self.weather_context = {}
        self.recent_form_data = {}
        self.lineup_data = {}
        
        # NEW: Pitcher ranking data containers
        self.pitcher_hits_rankings = {}
        self.pitcher_hrs_rankings = {}
        self.starting_pitchers = []  # Will be populated from lineups
        
        # PHASE 1 ENHANCEMENT: New CSV data sources for comprehensive analysis
        self.batted_ball_handedness = {}  # L/L, L/R, R/L, R/R matchup data
        self.swing_path_data = {}         # Swing mechanics by handedness (all/LHP/RHP)
        self.historical_data = {}         # Multi-year data (2022-2025)
        self.comprehensive_batter_stats = {}  # Enhanced batter metrics
        
        print("ðŸš€ Enhanced Weakspot Analyzer V3.0 initializing...")
        self.load_all_data()
    
    def load_all_data(self):
        """Load all data including enhanced analytics"""
        print("ðŸ“Š Loading enhanced baseball analytics data...")
        
        # OPTIMIZATION: First identify today's starting pitchers
        self.identify_starting_pitchers()
        
        # Load base data
        self.load_hitter_exit_velocity_data()
        self.load_pitcher_exit_velocity_data()
        self.load_custom_batter_data()
        self.load_custom_pitcher_data()
        self.load_pitcher_arsenal_data()
        self.load_handedness_data()
        self.load_roster_data()
        
        # PHASE 1 ENHANCEMENT: Load new comprehensive data sources
        self.load_batted_ball_handedness_data()
        self.load_swing_path_data()
        self.load_historical_multi_year_data()
        self.load_comprehensive_batter_stats()
        
        # Load enhanced data
        self.load_recent_performance_data()
        self.load_park_factors()
        self.load_weather_context()
        self.load_recent_form_data()
        self.load_lineup_data()
        self.calculate_trends()
        
        # NEW: Load pitcher ranking data ONLY for today's starters
        self.load_pitcher_ranking_data()
        
        total_data_points = (len(self.hitter_exit_velocity) + len(self.pitcher_exit_velocity) + 
                           len(self.custom_batters) + len(self.custom_pitchers))
        
        print(f"âœ… Enhanced data loading complete: {total_data_points} total data points")
    
    def identify_starting_pitchers(self):
        """Identify today's starting pitchers from lineups to optimize data loading"""
        print(f"ðŸŽ¯ Identifying starting pitchers for {self.target_date}...")
        
        try:
            lineups_data = self.load_starting_lineups(self.target_date)
            
            if lineups_data and 'games' in lineups_data:
                for game in lineups_data['games']:
                    # Extract pitcher names from both teams
                    home_pitcher = game['pitchers']['home']['name']
                    away_pitcher = game['pitchers']['away']['name']
                    
                    # Normalize and store pitcher names
                    if home_pitcher and home_pitcher.upper() not in ['TBD', 'TO BE DECIDED', 'UNKNOWN']:
                        self.starting_pitchers.append(self.normalize_name(home_pitcher))
                    
                    if away_pitcher and away_pitcher.upper() not in ['TBD', 'TO BE DECIDED', 'UNKNOWN']:
                        self.starting_pitchers.append(self.normalize_name(away_pitcher))
                
                # Remove duplicates
                self.starting_pitchers = list(set(self.starting_pitchers))
                print(f"   âš¾ Found {len(self.starting_pitchers)} starting pitchers for today")
            else:
                print("   âš ï¸ No lineups data available, will load all pitcher data")
        except Exception as e:
            print(f"   âš ï¸ Could not identify starting pitchers: {e}")
            # Continue without optimization if lineups can't be loaded
    
    def load_recent_performance_data(self):
        """Load recent game performance for trend analysis"""
        print("ðŸ“ˆ Loading recent performance data...")
        
        # Load last 10 games of data
        end_date = datetime.now()
        start_date = end_date - timedelta(days=10)
        
        games_analyzed = 0
        for i in range(10):
            check_date = end_date - timedelta(days=i)
            date_str = check_date.strftime('%Y-%m-%d')
            
            # Try to load game data
            try:
                year = check_date.year
                month = check_date.strftime('%B').lower()
                day = check_date.day
                
                file_path = self.data_path / f"{year}/{month}/{month}_{day:02d}_{year}.json"
                
                if file_path.exists():
                    with open(file_path, 'r') as f:
                        game_data = json.load(f)
                        self.process_recent_game_data(game_data, date_str)
                        games_analyzed += 1
            except Exception as e:
                continue
        
        print(f"   ðŸ“Š Analyzed {games_analyzed} recent games for trend data")
    
    def process_recent_game_data(self, game_data, date_str):
        """Process recent game data for trend analysis"""
        if 'players' not in game_data:
            return
        
        for player in game_data['players']:
            name = self.normalize_name(player.get('name', ''))
            if not name:
                continue
            
            if name not in self.recent_performance:
                self.recent_performance[name] = []
            
            # Store recent performance
            performance = {
                'date': date_str,
                'AB': player.get('AB', 0),
                'H': player.get('H', 0),
                'HR': player.get('HR', 0),
                'RBI': player.get('RBI', 0),
                'K': player.get('K', 0),
                'BB': player.get('BB', 0),
                'AVG': player.get('AVG', 0)
            }
            
            self.recent_performance[name].append(performance)
    
    def calculate_trends(self):
        """Calculate performance trends for batters and pitchers"""
        print("ðŸ“Š Calculating performance trends...")
        
        # Calculate batter trends
        for batter, performances in self.recent_performance.items():
            if len(performances) >= 3:
                self.batter_trends[batter] = self.calculate_player_trend(performances, 'batter')
        
        print(f"   ðŸ“ˆ Calculated trends for {len(self.batter_trends)} batters")
    
    def calculate_player_trend(self, performances, player_type):
        """Calculate trend metrics for a player"""
        if len(performances) < 3:
            return {'trend': 'insufficient_data'}
        
        # Sort by date
        performances = sorted(performances, key=lambda x: x['date'])
        
        # Calculate rolling averages
        recent_games = performances[-5:] if len(performances) >= 5 else performances
        older_games = performances[:-5] if len(performances) > 5 else []
        
        if player_type == 'batter':
            # Recent stats
            recent_abs = sum(g['AB'] for g in recent_games)
            recent_hits = sum(g['H'] for g in recent_games)
            recent_hrs = sum(g['HR'] for g in recent_games)
            recent_avg = recent_hits / recent_abs if recent_abs > 0 else 0
            
            # Older stats (if available)
            if older_games:
                older_abs = sum(g['AB'] for g in older_games)
                older_hits = sum(g['H'] for g in older_games)
                older_avg = older_hits / older_abs if older_abs > 0 else 0
                
                # Trend direction
                if recent_avg > older_avg + 0.050:
                    trend = 'hot'
                elif recent_avg < older_avg - 0.050:
                    trend = 'cold'
                else:
                    trend = 'stable'
            else:
                trend = 'stable'
            
            return {
                'trend': trend,
                'recent_avg': recent_avg,
                'recent_hrs': recent_hrs,
                'games_analyzed': len(recent_games)
            }
        
        return {'trend': 'stable'}
    
    def load_park_factors(self):
        """Load park factors for venue adjustments"""
        park_factors_file = self.data_path / "stadium/stadium_hr_analysis.json"
        
        if park_factors_file.exists():
            try:
                with open(park_factors_file, 'r') as f:
                    data = json.load(f)
                    stadiums = data.get('stadiums', {})
                    
                    # Calculate league average HR per game for relative factors
                    summary = data.get('summary', {})
                    league_avg_hrs = float(summary.get('averageHRsPerStadium', 0.72))
                    
                    if isinstance(stadiums, dict):
                        for stadium_name, stadium_data in stadiums.items():
                            if isinstance(stadium_data, dict):
                                avg_hrs = float(stadium_data.get('averageHRsPerGame', 0.72))
                                
                                # Calculate HR factor relative to league average
                                hr_factor = avg_hrs / league_avg_hrs if league_avg_hrs > 0 else 1.0
                                
                                # Categorize parks
                                if hr_factor >= 1.15:
                                    category = 'hitter-friendly'
                                elif hr_factor <= 0.85:
                                    category = 'pitcher-friendly'
                                else:
                                    category = 'neutral'
                                
                                self.park_factors[stadium_name] = {
                                    'hr_factor': round(hr_factor, 3),
                                    'category': category,
                                    'avg_hrs_per_game': avg_hrs,
                                    'home_team': stadium_data.get('homeTeam', '')
                                }
                print(f"   ðŸŸï¸ Loaded park factors for {len(self.park_factors)} venues")
            except Exception as e:
                print(f"   âš ï¸ Could not load park factors: {e}")
        else:
            print("   âš ï¸ Stadium HR analysis file not found")
    
    def load_weather_context(self):
        """Load weather context data from MLB Weather Card data and lineup files"""
        try:
            # Look for weather data in various possible locations
            weather_files = [
                self.data_path / "weather/current_weather.json",
                self.data_path / "weather/game_weather.json",
                self.data_path / f"{self.target_date}/weather_data.json"
            ]
            
            # Try dedicated weather files first
            weather_found = False
            for weather_file in weather_files:
                if weather_file.exists():
                    with open(weather_file, 'r') as f:
                        weather_data = json.load(f)
                        
                    # Process weather data by venue
                    if isinstance(weather_data, dict):
                        for venue, data in weather_data.items():
                            self.weather_context[venue] = {
                                'temperature': data.get('temperature', 70),
                                'wind_speed': data.get('wind_speed', 0),
                                'wind_direction': data.get('wind_direction', 'calm'),
                                'precipitation': data.get('precipitation', 0),
                                'dome': data.get('dome', False),
                                'weather_factor': self.calculate_weather_factor(data)
                            }
                    weather_found = True
                    break
            
            # If no dedicated weather files, extract from lineups data
            if not weather_found:
                lineup_file = self.data_path / f"lineups/starting_lineups_{self.target_date}.json"
                if lineup_file.exists():
                    with open(lineup_file, 'r') as f:
                        lineup_data = json.load(f)
                        
                    games = lineup_data.get('games', [])
                    for game in games:
                        venue_info = game.get('venue', {})
                        venue_name = venue_info.get('name', '')
                        weather_info = game.get('weather', {})
                        
                        if venue_name and weather_info:
                            self.weather_context[venue_name] = {
                                'temperature': weather_info.get('temperature', 70),
                                'wind_speed': weather_info.get('wind_speed', 0),
                                'wind_direction': weather_info.get('wind_direction', 'calm'),
                                'precipitation': weather_info.get('precipitation', 0),
                                'dome': self.is_dome_stadium(venue_name),
                                'weather_factor': self.calculate_weather_factor(weather_info)
                            }
            
            print(f"   ðŸŒ¤ï¸ Loaded weather context for {len(self.weather_context)} venues")
        except Exception as e:
            print(f"   âš ï¸ Could not load weather context: {e}")
    
    def is_dome_stadium(self, venue_name):
        """Check if venue is a dome stadium"""
        dome_stadiums = {
            'Tropicana Field', 'Minute Maid Park', 'Rogers Centre', 
            'Globe Life Field', 'Marlins Park', 'Chase Field'
        }
        return venue_name in dome_stadiums
            
    def calculate_weather_factor(self, weather_data):
        """Calculate weather impact factor for HR probability"""
        factor = 1.0
        
        temp = weather_data.get('temperature', 70)
        wind_speed = weather_data.get('wind_speed', 0)
        wind_dir = weather_data.get('wind_direction', 'calm')
        
        # Temperature effects (hot air = less dense = more carry)
        if temp >= 85:
            factor += 0.08  # Hot weather boost
        elif temp >= 75:
            factor += 0.04  # Warm weather slight boost
        elif temp <= 50:
            factor -= 0.12  # Cold weather penalty
        elif temp <= 60:
            factor -= 0.06  # Cool weather penalty
            
        # Wind effects
        if wind_speed >= 15:
            if wind_dir in ['out', 'outfield', 'favorable']:
                factor += 0.15  # Strong favorable wind
            elif wind_dir in ['in', 'infield', 'against']:
                factor -= 0.15  # Strong unfavorable wind
        elif wind_speed >= 8:
            if wind_dir in ['out', 'outfield', 'favorable']:
                factor += 0.08  # Moderate favorable wind
            elif wind_dir in ['in', 'infield', 'against']:
                factor -= 0.08  # Moderate unfavorable wind
                
        # Dome games (controlled environment)
        if weather_data.get('dome', False):
            factor = 1.0  # Neutral conditions
            
        return max(0.7, min(1.3, factor))  # Cap between 0.7 and 1.3
        
    def load_recent_form_data(self):
        """Load recent form and momentum data for enhanced analysis"""
        try:
            # Look for rolling stats files
            recent_files = [
                self.data_path / "rolling_stats/rolling_stats_last_7_latest.json",
                self.data_path / "rolling_stats/rolling_stats_current_latest.json",
                self.data_path / "recent_performance/momentum_analysis.json",
                self.data_path / "predictions/recent_form_latest.json"
            ]
            
            for recent_file in recent_files:
                if recent_file.exists():
                    with open(recent_file, 'r') as f:
                        recent_data = json.load(f)
                        
                    # Process rolling stats data structure
                    players_data = recent_data.get('topMultiHitPerformers', [])
                    
                    if isinstance(players_data, list) and len(players_data) > 0:
                        for player_data in players_data:
                            player_name = player_data.get('name', '')
                            if player_name:
                                # Calculate momentum from multi-hit rates and recent performance
                                multi_hit_rate = player_data.get('multiHitRate', 0)
                                multi_hr_rate = player_data.get('multiHRRate', 0)
                                avg_hits_per_game = player_data.get('avgHitsPerGame', 0)
                                avg_hrs_per_game = player_data.get('avgHRsPerGame', 0)
                                current_hit_drought = player_data.get('currentHitDrought', 0)
                                current_hr_drought = player_data.get('currentHRDrought', 0)
                                
                                # Determine momentum based on performance metrics
                                momentum = 'neutral'
                                hot_streak = False
                                cold_streak = False
                                
                                if multi_hit_rate >= 30 and current_hit_drought <= 1:
                                    momentum = 'hot'
                                    hot_streak = True
                                elif multi_hit_rate <= 15 or current_hit_drought >= 5:
                                    momentum = 'cold'
                                    cold_streak = True
                                
                                # Determine trend direction
                                trend_direction = 'stable'
                                if avg_hits_per_game >= 1.2:
                                    trend_direction = 'improving'
                                elif avg_hits_per_game <= 0.8:
                                    trend_direction = 'declining'
                                
                                self.recent_form_data[player_name] = {
                                    'avg_hits_per_game': avg_hits_per_game,
                                    'avg_hrs_per_game': avg_hrs_per_game,
                                    'multi_hit_rate': multi_hit_rate,
                                    'multi_hr_rate': multi_hr_rate,
                                    'momentum': momentum,
                                    'hot_streak': hot_streak,
                                    'cold_streak': cold_streak,
                                    'trend_direction': trend_direction,
                                    'current_hit_drought': current_hit_drought,
                                    'current_hr_drought': current_hr_drought,
                                    'team': player_data.get('team', '')
                                }
                        break
                    
            print(f"   ðŸ“ˆ Loaded recent form data for {len(self.recent_form_data)} players")
        except Exception as e:
            print(f"   âš ï¸ Could not load recent form data: {e}")
    
    def load_lineup_data(self):
        """Load lineup position and protection data for enhanced analysis"""
        try:
            # Look for lineup data in current format
            lineup_files = [
                self.data_path / f"lineups/starting_lineups_{self.target_date}.json",
                self.data_path / "lineups/starting_lineups_latest.json",
                self.data_path / f"{self.target_date}/starting_lineups.json",
                self.data_path / "predictions/lineup_analysis_latest.json"
            ]
            
            for lineup_file in lineup_files:
                if lineup_file.exists():
                    with open(lineup_file, 'r') as f:
                        lineup_data = json.load(f)
                        
                    # Process the current starting_lineups format
                    games = lineup_data.get('games', [])
                    
                    for game in games:
                        lineups = game.get('lineups', {})
                        teams = game.get('teams', {})
                        
                        # Process home and away lineups
                        for side in ['home', 'away']:
                            lineup_info = lineups.get(side, {})
                            batting_order = lineup_info.get('batting_order', [])
                            team_info = teams.get(side, {})
                            team_abbr = team_info.get('abbr', '')
                            
                            if batting_order:  # Only process if lineup has data
                                for i, player_info in enumerate(batting_order):
                                    if isinstance(player_info, dict):
                                        player_name = player_info.get('name', '')
                                        if player_name:
                                            self.lineup_data[player_name] = {
                                                'position': i + 1,  # 1-9 batting order
                                                'team': team_abbr,
                                                'rbi_opportunities': self.calculate_rbi_opportunities(i + 1),
                                                'run_scoring_opportunities': self.calculate_run_opportunities(i + 1),
                                                'protection_quality': self.calculate_protection_quality(batting_order, i),
                                                'lineup_context': self.get_lineup_context(batting_order, i)
                                            }
                    
                    # If we found any lineup data, break
                    if self.lineup_data:
                        break
                    
            # If no lineups available, create default lineup context based on historical data
            if not self.lineup_data:
                # Use roster data to create basic batting order assumptions
                for player_name in list(self.rosters.keys())[:200]:  # Sample some players
                    # Create default lineup context for key players
                    self.lineup_data[player_name] = {
                        'position': 5,  # Default to middle order
                        'team': '',
                        'rbi_opportunities': 1.0,
                        'run_scoring_opportunities': 1.0,
                        'protection_quality': 0.5,
                        'lineup_context': {'protection_level': 'average'}
                    }
                    
            print(f"   ðŸ“‹ Loaded lineup data for {len(self.lineup_data)} players")
        except Exception as e:
            print(f"   âš ï¸ Could not load lineup data: {e}")
    
    def calculate_rbi_opportunities(self, position):
        """Calculate RBI opportunity factor based on batting order position"""
        # RBI opportunities generally higher in middle of order
        rbi_factors = {
            1: 0.85,  # Leadoff - fewer RBI opportunities
            2: 0.90,  # 2-hole - setup role
            3: 1.15,  # 3-hole - prime RBI spot
            4: 1.25,  # Cleanup - best RBI opportunities  
            5: 1.20,  # 5-hole - good RBI spot
            6: 1.10,  # 6-hole - decent RBI opportunities
            7: 0.95,  # 7-hole - fewer opportunities
            8: 0.85,  # 8-hole - limited opportunities
            9: 0.80   # 9-hole - fewest opportunities
        }
        return rbi_factors.get(position, 1.0)
    
    def calculate_run_opportunities(self, position):
        """Calculate run scoring opportunity factor based on batting order position"""
        # Top of order gets more chances to score
        run_factors = {
            1: 1.25,  # Leadoff - most scoring chances
            2: 1.20,  # 2-hole - many scoring chances
            3: 1.15,  # 3-hole - good scoring chances
            4: 1.10,  # Cleanup - good chances
            5: 1.05,  # 5-hole - decent chances
            6: 1.00,  # 6-hole - average
            7: 0.95,  # 7-hole - fewer chances
            8: 0.90,  # 8-hole - limited chances
            9: 0.85   # 9-hole - fewest chances
        }
        return run_factors.get(position, 1.0)
    
    def calculate_protection_quality(self, lineup, position_index):
        """Calculate quality of lineup protection (batters hitting behind)"""
        protection_score = 0
        protection_count = 0
        
        # Look at next 2-3 batters for protection
        for i in range(position_index + 1, min(position_index + 4, len(lineup))):
            if i < len(lineup) and isinstance(lineup[i], dict):
                # Simple protection scoring (could be enhanced with actual stats)
                protection_score += 1.0  # Base protection value
                protection_count += 1
                
        if protection_count > 0:
            return protection_score / protection_count
        return 0.5  # Neutral if no protection data
    
    def get_lineup_context(self, lineup, position_index):
        """Get contextual information about lineup position"""
        context = []
        
        if position_index == 0:
            context.append("leadoff_table_setter")
        elif position_index in [1, 2]:
            context.append("top_of_order")
        elif position_index in [3, 4, 5]:
            context.append("heart_of_order")
        else:
            context.append("bottom_of_order")
            
        # Add protection context
        if position_index < len(lineup) - 2:
            context.append("has_protection")
        else:
            context.append("limited_protection")
            
        return context
    
    def load_pitcher_ranking_data(self):
        """Load pitcher ranking data ONLY for today's starting pitchers"""
        if not self.starting_pitchers:
            print("   âš ï¸ No starting pitchers identified, skipping ranking data load")
            return
            
        print(f"ðŸ“Š Loading pitcher ranking data for {len(self.starting_pitchers)} starting pitchers...")
        
        try:
            # Use similar logic to PitcherHitsAllowedCard and PitcherHRsAllowedCard
            from datetime import datetime, timedelta
            
            # Get current date and look back for analysis
            current_date = datetime.now()
            
            # Load recent game data to build pitcher rankings (last 60 days)
            pitcher_hits_analysis = {}
            pitcher_hrs_analysis = {}
            dates_processed = 0
            
            for days_back in range(60):
                check_date = current_date - timedelta(days=days_back)
                date_str = check_date.strftime('%Y-%m-%d')
                
                try:
                    year = check_date.year
                    month = check_date.strftime('%B').lower()
                    day = check_date.day
                    
                    file_path = self.data_path / f"{year}/{month}/{month}_{day:02d}_{year}.json"
                    
                    if file_path.exists():
                        with open(file_path, 'r') as f:
                            game_data = json.load(f)
                            
                        if 'players' in game_data:
                            # Process pitchers for ranking analysis
                            pitchers = [p for p in game_data['players'] 
                                      if p.get('playerType') == 'pitcher' 
                                      and p.get('H', 'DNP') != 'DNP' 
                                      and p.get('HR', 'DNP') != 'DNP']
                            
                            for pitcher in pitchers:
                                # OPTIMIZATION: Only process today's starting pitchers
                                normalized_pitcher_name = self.normalize_name(pitcher['name'])
                                
                                # Check if this pitcher is one of today's starters (with flexible matching)
                                is_starting_pitcher = False
                                for starter in self.starting_pitchers:
                                    if (normalized_pitcher_name == starter or 
                                        self.comprehensive_name_matching(normalized_pitcher_name, starter) or
                                        self.comprehensive_name_matching(starter, normalized_pitcher_name)):
                                        is_starting_pitcher = True
                                        break
                                
                                if not is_starting_pitcher:
                                    continue  # Skip non-starting pitchers
                                    
                                pitcher_key = f"{pitcher['name']}_{pitcher['team']}"
                                
                                # Hits allowed analysis
                                hits_allowed = int(pitcher.get('H', 0)) if str(pitcher.get('H', 0)).isdigit() else 0
                                
                                if pitcher_key not in pitcher_hits_analysis:
                                    pitcher_hits_analysis[pitcher_key] = {
                                        'name': pitcher['name'],
                                        'team': pitcher['team'],
                                        'total_hits_allowed': 0,
                                        'games_played': 0,
                                        'total_innings': 0
                                    }
                                
                                pitcher_hits_analysis[pitcher_key]['total_hits_allowed'] += hits_allowed
                                pitcher_hits_analysis[pitcher_key]['games_played'] += 1
                                
                                innings = float(pitcher.get('IP', 0)) if str(pitcher.get('IP', 0)).replace('.', '').isdigit() else 0
                                pitcher_hits_analysis[pitcher_key]['total_innings'] += innings
                                
                                # HRs allowed analysis
                                hrs_allowed = int(pitcher.get('HR', 0)) if str(pitcher.get('HR', 0)).isdigit() else 0
                                
                                if pitcher_key not in pitcher_hrs_analysis:
                                    pitcher_hrs_analysis[pitcher_key] = {
                                        'name': pitcher['name'],
                                        'team': pitcher['team'],
                                        'total_hrs_allowed': 0,
                                        'games_played': 0,
                                        'total_innings': 0
                                    }
                                
                                pitcher_hrs_analysis[pitcher_key]['total_hrs_allowed'] += hrs_allowed
                                pitcher_hrs_analysis[pitcher_key]['games_played'] += 1
                                pitcher_hrs_analysis[pitcher_key]['total_innings'] += innings
                        
                        dates_processed += 1
                        
                except Exception:
                    continue
            
            # Calculate rankings and rates
            hits_ranking_list = []
            for pitcher_key, data in pitcher_hits_analysis.items():
                if data['games_played'] > 0:
                    hits_per_game = data['total_hits_allowed'] / data['games_played']
                    hits_per_inning = data['total_hits_allowed'] / data['total_innings'] if data['total_innings'] > 0 else 0
                    
                    hits_ranking_list.append({
                        'name': data['name'],
                        'team': data['team'],
                        'total_hits_allowed': data['total_hits_allowed'],
                        'hits_per_game': hits_per_game,
                        'hits_per_inning': hits_per_inning,
                        'games_played': data['games_played']
                    })
            
            # Sort by total hits allowed (descending) to get vulnerability ranking
            hits_ranking_list.sort(key=lambda x: x['total_hits_allowed'], reverse=True)
            
            # Store rankings with league position
            for rank, pitcher_data in enumerate(hits_ranking_list, 1):
                pitcher_name = self.normalize_name(pitcher_data['name'])
                self.pitcher_hits_rankings[pitcher_name] = {
                    **pitcher_data,
                    'league_rank_hits': rank,
                    'percentile_hits': (len(hits_ranking_list) - rank) / len(hits_ranking_list) if len(hits_ranking_list) > 0 else 0.5
                }
            
            # Same process for HRs
            hrs_ranking_list = []
            for pitcher_key, data in pitcher_hrs_analysis.items():
                if data['games_played'] > 0:
                    hrs_per_game = data['total_hrs_allowed'] / data['games_played']
                    hrs_per_inning = data['total_hrs_allowed'] / data['total_innings'] if data['total_innings'] > 0 else 0
                    
                    hrs_ranking_list.append({
                        'name': data['name'],
                        'team': data['team'],
                        'total_hrs_allowed': data['total_hrs_allowed'],
                        'hrs_per_game': hrs_per_game,
                        'hrs_per_inning': hrs_per_inning,
                        'games_played': data['games_played']
                    })
            
            # Sort by total HRs allowed (descending) to get vulnerability ranking
            hrs_ranking_list.sort(key=lambda x: x['total_hrs_allowed'], reverse=True)
            
            # Store rankings with league position
            for rank, pitcher_data in enumerate(hrs_ranking_list, 1):
                pitcher_name = self.normalize_name(pitcher_data['name'])
                self.pitcher_hrs_rankings[pitcher_name] = {
                    **pitcher_data,
                    'league_rank_hrs': rank,
                    'percentile_hrs': (len(hrs_ranking_list) - rank) / len(hrs_ranking_list) if len(hrs_ranking_list) > 0 else 0.5
                }
            
            print(f"   ðŸ“ˆ Loaded hits rankings for {len(self.pitcher_hits_rankings)} starting pitchers (optimized from 628+ total)")
            print(f"   ðŸ”¥ Loaded HR rankings for {len(self.pitcher_hrs_rankings)} starting pitchers (optimized from 628+ total)")
            print(f"   ðŸ“Š Processed {dates_processed} days of game data")
            print(f"   âš¡ Optimization: Analyzed only today's starters instead of all pitchers")
            
        except Exception as e:
            print(f"   âš ï¸ Could not load pitcher ranking data: {e}")
    
    def analyze_enhanced_pitcher_vulnerabilities(self, pitcher_name):
        """Enhanced pitcher vulnerability analysis with situational factors"""
        
        # Critical fix: Handle TBD (To Be Decided) pitchers
        if not pitcher_name or pitcher_name.upper() in ['TBD', 'TO BE DECIDED', 'UNKNOWN']:
            return {
                'vulnerabilityScore': 30,  # Much lower than known pitchers
                'vulnerabilities': [{'vulnerability_score': 30, 'factors': ['Unknown pitcher - limited data']}],
                'confidence': 0.2,  # Very low confidence
                'situational_factors': {'pitcher_known': False},
                'data_quality': 'none'
            }
        
        normalized_name = self.normalize_name(pitcher_name)
        
        # Base vulnerability analysis
        vulnerability_analysis = {
            'vulnerabilities': [],
            'confidence': 0.3,
            'data_quality': 'limited',
            'analysis': 'Enhanced vulnerability detection with situational factors',
            'modern_metrics': {},
            'situational_factors': {},
            'trend_analysis': {}
        }
        
        # Enhanced vulnerability detection
        total_vulnerability_score = 0
        all_factors = []
        
        # 1. Contact Quality Vulnerabilities (Enhanced)
        if normalized_name in self.pitcher_exit_velocity:
            pitcher_ev = self.pitcher_exit_velocity[normalized_name]
            
            # Real barrel rate allowed with context - More generous detection
            barrel_rate_allowed = pitcher_ev['real_barrel_rate_allowed']
            league_avg_barrel = 7.5  # Approximate league average
            
            if barrel_rate_allowed > league_avg_barrel * 1.15:  # 15% above league average (was 30%)
                score = 30 + (barrel_rate_allowed - league_avg_barrel) * 2.5
                total_vulnerability_score += score
                all_factors.append(f"Extreme barrel rate allowed ({barrel_rate_allowed:.1f}% vs {league_avg_barrel:.1f}% league avg)")
                vulnerability_analysis['situational_factors']['barrel_vulnerability'] = 'extreme'
            elif barrel_rate_allowed > league_avg_barrel * 1.05:  # 5% above league average (was 15%)
                score = 20 + (barrel_rate_allowed - league_avg_barrel) * 1.5
                total_vulnerability_score += score
                all_factors.append(f"High barrel rate allowed ({barrel_rate_allowed:.1f}%)")
                vulnerability_analysis['situational_factors']['barrel_vulnerability'] = 'high'
            elif barrel_rate_allowed > league_avg_barrel:  # Any above average
                score = 10 + (barrel_rate_allowed - league_avg_barrel)
                total_vulnerability_score += score
                all_factors.append(f"Above-average barrel rate allowed ({barrel_rate_allowed:.1f}%)")
                vulnerability_analysis['situational_factors']['barrel_vulnerability'] = 'moderate'
            
            # Hard hit rate with percentile context - More generous detection
            hard_hit_allowed = pitcher_ev['hard_hit_percent_allowed']
            if hard_hit_allowed > 42:  # Lower threshold (was 45)
                total_vulnerability_score += 25
                all_factors.append(f"Extreme hard contact allowed ({hard_hit_allowed:.1f}%)")
            elif hard_hit_allowed > 38:  # Moderate threshold
                total_vulnerability_score += 15
                all_factors.append(f"High hard contact allowed ({hard_hit_allowed:.1f}%)")
            elif hard_hit_allowed > 35:  # Above average threshold
                total_vulnerability_score += 8
                all_factors.append(f"Above-average hard contact allowed ({hard_hit_allowed:.1f}%)")
            
            vulnerability_analysis['confidence'] += 0.25
        
        # 2. Recent Performance Trend Analysis
        if normalized_name in self.pitcher_trends:
            trend_data = self.pitcher_trends[normalized_name]
            if trend_data.get('trend') == 'deteriorating':
                total_vulnerability_score += 20
                all_factors.append("Deteriorating recent performance")
                vulnerability_analysis['trend_analysis'] = trend_data
        
        # 3. Platoon Split Vulnerabilities
        if normalized_name in self.custom_pitchers:
            pitcher_data = self.custom_pitchers[normalized_name]
            pitch_hand = pitcher_data.get('pitch_hand', 'R')
            
            # Check for reverse splits or extreme platoon disadvantages
            vulnerability_analysis['situational_factors']['pitch_hand'] = pitch_hand
            
            # Phase 2: Enhanced Arsenal vulnerability analysis with major scoring
            if normalized_name in self.pitcher_arsenal:
                arsenal = self.pitcher_arsenal[normalized_name]['pitch_types']
                arsenal_vulnerability_bonus = 0
                
                # Analyze individual pitch vulnerabilities with usage weighting
                for pitch_type, pitch_data in arsenal.items():
                    ba_against = float(pitch_data.get('ba_against', 0))
                    usage_percent = float(pitch_data.get('usage', 0))
                    whiff_percent = float(pitch_data.get('whiff_percent', 0))
                    
                    # High BA against with frequent usage = major vulnerability
                    if ba_against > 0.320 and usage_percent > 25:  # Extreme vulnerability
                        arsenal_vulnerability_bonus += 25
                        all_factors.append(f"Major {pitch_data['pitch_name']} vulnerability ({ba_against:.3f} BA, {usage_percent:.1f}% usage)")
                    elif ba_against > 0.300 and usage_percent > 20:  # High vulnerability
                        arsenal_vulnerability_bonus += 18
                        all_factors.append(f"High {pitch_data['pitch_name']} vulnerability ({ba_against:.3f} BA, {usage_percent:.1f}% usage)")
                    elif ba_against > 0.280 and usage_percent > 15:  # Moderate vulnerability
                        arsenal_vulnerability_bonus += 12
                        all_factors.append(f"{pitch_data['pitch_name']} vulnerability ({ba_against:.3f} BA, {usage_percent:.1f}% usage)")
                    
                    # Low whiff rate on frequently thrown pitches = vulnerability
                    if whiff_percent < 18 and usage_percent > 20:
                        arsenal_vulnerability_bonus += 10
                        all_factors.append(f"Low {pitch_data['pitch_name']} whiff rate ({whiff_percent:.1f}%, {usage_percent:.1f}% usage)")
                
                # Analyze pitch mix predictability (Phase 2 enhancement)
                fastball_types = [p for p in arsenal.values() if any(fb in p['pitch_name'].lower() for fb in ['4-seam', 'sinker', 'fastball'])]
                breaking_balls = [p for p in arsenal.values() if any(bb in p['pitch_name'].lower() for bb in ['slider', 'curve', 'cutter'])]
                offspeed = [p for p in arsenal.values() if any(os in p['pitch_name'].lower() for os in ['change', 'split', 'knuckle'])]
                
                total_fastball_usage = sum(float(p.get('usage', 0)) for p in fastball_types)
                avg_breaking_whiff = sum(float(p.get('whiff_percent', 0)) for p in breaking_balls) / len(breaking_balls) if breaking_balls else 0
                
                # Predictable arsenal patterns
                if total_fastball_usage > 65:  # Fastball heavy
                    arsenal_vulnerability_bonus += 15
                    all_factors.append(f"Fastball-heavy arsenal ({total_fastball_usage:.1f}% usage)")
                    vulnerability_analysis['situational_factors']['arsenal_vulnerability'] = 'fastball_heavy'
                elif len(breaking_balls) == 0:  # No breaking balls
                    arsenal_vulnerability_bonus += 20
                    all_factors.append("Limited pitch mix - no breaking balls")
                    vulnerability_analysis['situational_factors']['arsenal_vulnerability'] = 'limited'
                elif avg_breaking_whiff < 25:  # Poor breaking ball quality
                    arsenal_vulnerability_bonus += 12
                    all_factors.append(f"Poor breaking ball quality ({avg_breaking_whiff:.1f}% avg whiff)")
                    vulnerability_analysis['situational_factors']['arsenal_vulnerability'] = 'poor_secondary'
                
                total_vulnerability_score += arsenal_vulnerability_bonus
        
        # NEW: Pitcher League Rankings Analysis (Integration with Card Data)
        league_ranking_bonus = 0
        
        # Hits allowed ranking vulnerability
        if normalized_name in self.pitcher_hits_rankings:
            hits_ranking = self.pitcher_hits_rankings[normalized_name]
            hits_rank = hits_ranking.get('league_rank_hits', 999)
            hits_percentile = hits_ranking.get('percentile_hits', 0.5)
            hits_per_game = hits_ranking.get('hits_per_game', 0)
            
            # Top vulnerability based on league rank (worse rank = higher vulnerability)  
            if hits_rank <= 10:  # Top 10 worst for hits allowed
                league_ranking_bonus += 30
                all_factors.append(f"Elite hit vulnerability (#{hits_rank} in MLB, {hits_per_game:.1f} hits/game)")
                vulnerability_analysis['situational_factors']['hits_vulnerability'] = 'elite'
            elif hits_rank <= 25:  # Top 25 worst
                league_ranking_bonus += 20
                all_factors.append(f"High hit vulnerability (#{hits_rank} in MLB, {hits_per_game:.1f} hits/game)")
                vulnerability_analysis['situational_factors']['hits_vulnerability'] = 'high'
            elif hits_percentile < 0.3:  # Bottom 30%
                league_ranking_bonus += 12
                all_factors.append(f"Above-average hit vulnerability ({hits_per_game:.1f} hits/game)")
                vulnerability_analysis['situational_factors']['hits_vulnerability'] = 'moderate'
        
        # HR allowed ranking vulnerability
        if normalized_name in self.pitcher_hrs_rankings:
            hrs_ranking = self.pitcher_hrs_rankings[normalized_name]
            hrs_rank = hrs_ranking.get('league_rank_hrs', 999)
            hrs_percentile = hrs_ranking.get('percentile_hrs', 0.5)
            hrs_per_game = hrs_ranking.get('hrs_per_game', 0)
            
            # Top vulnerability based on league rank (worse rank = higher vulnerability)
            if hrs_rank <= 10:  # Top 10 worst for HRs allowed
                league_ranking_bonus += 35  # Higher bonus for HR vulnerability
                all_factors.append(f"Elite HR vulnerability (#{hrs_rank} in MLB, {hrs_per_game:.2f} HR/game)")
                vulnerability_analysis['situational_factors']['hr_vulnerability'] = 'elite'
            elif hrs_rank <= 25:  # Top 25 worst
                league_ranking_bonus += 25
                all_factors.append(f"High HR vulnerability (#{hrs_rank} in MLB, {hrs_per_game:.2f} HR/game)")
                vulnerability_analysis['situational_factors']['hr_vulnerability'] = 'high'
            elif hrs_percentile < 0.3:  # Bottom 30%
                league_ranking_bonus += 15
                all_factors.append(f"Above-average HR vulnerability ({hrs_per_game:.2f} HR/game)")
                vulnerability_analysis['situational_factors']['hr_vulnerability'] = 'moderate'
        
        # Combine ranking vulnerabilities (both hits and HRs create a dangerous pitcher)
        if (normalized_name in self.pitcher_hits_rankings and 
            normalized_name in self.pitcher_hrs_rankings):
            
            hits_rank = self.pitcher_hits_rankings[normalized_name].get('league_rank_hits', 999)
            hrs_rank = self.pitcher_hrs_rankings[normalized_name].get('league_rank_hrs', 999)
            
            # Compound vulnerability bonus for pitchers bad at both
            if hits_rank <= 20 and hrs_rank <= 20:
                league_ranking_bonus += 20  # Extra bonus for double vulnerability
                all_factors.append("Compound vulnerability - poor in both hits and HRs allowed")
                vulnerability_analysis['situational_factors']['compound_vulnerability'] = True
        
        total_vulnerability_score += league_ranking_bonus
        
        # 4. Fatigue and Workload Analysis
        if normalized_name in self.recent_performance:
            recent_games = sorted(self.recent_performance[normalized_name], key=lambda x: x['date'])[-3:]
            if len(recent_games) >= 2:
                # Simple fatigue indicator
                recent_innings = sum(g.get('IP', 0) for g in recent_games)
                if recent_innings > 18:  # High recent workload
                    total_vulnerability_score += 10
                    all_factors.append("High recent workload")
                    vulnerability_analysis['situational_factors']['fatigue_risk'] = 'elevated'
        
        # 5. Create comprehensive vulnerability profile - More generous
        if total_vulnerability_score >= 25 and len(all_factors) >= 1:  # Lower threshold for more opportunities
            vulnerability_analysis['vulnerabilities'] = [{
                'category': 'enhanced_comprehensive_vulnerability',
                'vulnerability_score': round(total_vulnerability_score, 1),
                'factors': all_factors[:6],  # Top 6 factors
                'confidence_level': 'high' if total_vulnerability_score >= 70 else 'moderate',
                'exploitation_windows': self.identify_exploitation_windows(normalized_name)
            }]
            
            # Boost confidence based on data completeness (Enhanced with ranking data)
            data_sources = sum([
                normalized_name in self.pitcher_exit_velocity,
                normalized_name in self.custom_pitchers,
                normalized_name in self.pitcher_arsenal,
                normalized_name in self.pitcher_trends,
                normalized_name in self.pitcher_hits_rankings,  # NEW: Hits ranking data
                normalized_name in self.pitcher_hrs_rankings    # NEW: HRs ranking data
            ])
            
            # Enhanced confidence calculation with more data sources
            vulnerability_analysis['confidence'] = min(0.95, 0.25 + (data_sources * 0.12))
            vulnerability_analysis['data_quality'] = ['limited', 'fair', 'good', 'excellent', 'comprehensive', 'elite'][min(5, data_sources)]
        
        # Update vulnerability score for new format
        if len(vulnerability_analysis['vulnerabilities']) > 0:
            vulnerability_analysis['vulnerabilityScore'] = vulnerability_analysis['vulnerabilities'][0]['vulnerability_score']
        else:
            vulnerability_analysis['vulnerabilityScore'] = 50
        
        return vulnerability_analysis
    
    def extract_key_weakness(self, pitcher_analysis, exploit_analysis):
        """Extract the most relevant weakness for display"""
        if exploit_analysis.get('regression_opportunity'):
            return f"Regression opportunity: {exploit_analysis['regression_opportunity']['type']}"
        elif exploit_analysis.get('contact_quality_edge'):
            return f"Contact quality edge: {exploit_analysis['contact_quality_edge']['type']}"
        elif pitcher_analysis.get('vulnerabilities') and len(pitcher_analysis['vulnerabilities']) > 0:
            return pitcher_analysis['vulnerabilities'][0]['factors'][0]
        else:
            return "Comprehensive matchup analysis"
    
    def generate_comprehensive_justification(self, batter_name, pitcher_name, pitcher_analysis, exploit_analysis):
        """Generate comprehensive multi-factor justification combining all data sources"""
        justification_components = []
        stats_components = []
        
        # 1. PITCHER VULNERABILITY ANALYSIS
        vulnerability_score = pitcher_analysis.get('vulnerabilityScore', 50)
        if vulnerability_score >= 80:
            justification_components.append(f"Extreme pitcher vulnerability (Score: {vulnerability_score}/100)")
        elif vulnerability_score >= 70:
            justification_components.append(f"High pitcher vulnerability (Score: {vulnerability_score}/100)")
        elif vulnerability_score >= 60:
            justification_components.append(f"Notable pitcher vulnerability (Score: {vulnerability_score}/100)")
            
        # 2. BARREL RATE ANALYSIS
        normalized_pitcher = self.normalize_name(pitcher_name)
        if normalized_pitcher in self.pitcher_exit_velocity:
            pitcher_ev = self.pitcher_exit_velocity[normalized_pitcher]
            barrel_rate = float(pitcher_ev.get('real_barrel_rate_allowed', 0))
            if barrel_rate > 12:
                stats_components.append(f"Extreme barrel rate allowed ({barrel_rate:.1f}% vs 7.5% league avg)")
            elif barrel_rate > 10:
                stats_components.append(f"High barrel rate allowed ({barrel_rate:.1f}% vs 7.5% league avg)")
            elif barrel_rate > 8:
                stats_components.append(f"Above-average barrel rate allowed ({barrel_rate:.1f}%)")
                
        # 3. ARSENAL-SPECIFIC VULNERABILITIES
        if normalized_pitcher in self.pitcher_arsenal:
            arsenal = self.pitcher_arsenal[normalized_pitcher]['pitch_types']
            vulnerable_pitches = []
            
            for pitch_type, pitch_data in arsenal.items():
                ba_against = float(pitch_data.get('ba_against', 0))
                slg_against = float(pitch_data.get('slg_against', 0))
                usage_percent = float(pitch_data.get('usage_percent', 0))
                
                if ba_against > 0.320 and usage_percent > 20:
                    vulnerable_pitches.append(f"Vulnerable {pitch_data['pitch_name']} ({ba_against:.3f} BA, {slg_against:.3f} SLG, {usage_percent:.1f}% usage)")
                elif ba_against > 0.300 and usage_percent > 15:
                    vulnerable_pitches.append(f"Weak {pitch_data['pitch_name']} ({ba_against:.3f} BA, {usage_percent:.1f}% usage)")
                    
            if vulnerable_pitches:
                stats_components.extend(vulnerable_pitches[:2])  # Top 2 most vulnerable pitches
                
        # 4. REGRESSION OPPORTUNITY ANALYSIS
        normalized_batter = self.normalize_name(batter_name)
        if normalized_batter in self.custom_batters:
            batter_data = self.custom_batters[normalized_batter]
            xba_diff = float(batter_data.get('xba_diff', 0))
            xslg_diff = float(batter_data.get('xslg_diff', 0))
            woba_diff = float(batter_data.get('woba_diff', 0))
            
            if xba_diff < -0.03 or xslg_diff < -0.05:
                regression_type = "BA" if xba_diff < -0.03 else "Power"
                gap_value = abs(xba_diff) if xba_diff < -0.03 else abs(xslg_diff)
                stats_components.append(f"{regression_type} regression due (+{gap_value:.3f} x{regression_type.lower()} gap)")
                
        # 5. PLATOON ADVANTAGE
        batter_hand = self.get_batter_handedness(batter_name)
        pitcher_hand = pitcher_analysis.get('situational_factors', {}).get('pitch_hand', 'R')
        if (batter_hand == 'L' and pitcher_hand == 'R') or (batter_hand == 'R' and pitcher_hand == 'L'):
            justification_components.append(f"{batter_hand}HB vs {pitcher_hand}HP platoon advantage")
            
        # 6. HITS/POWER RANKING VULNERABILITIES
        hits_rank = pitcher_analysis.get('situational_factors', {}).get('hits_rank')
        hrs_rank = pitcher_analysis.get('situational_factors', {}).get('hrs_rank')
        
        if hits_rank and hits_rank <= 5:
            hits_per_game = pitcher_analysis.get('situational_factors', {}).get('hits_per_game', 0)
            stats_components.append(f"Elite hit vulnerability (#{hits_rank} worst in MLB, {hits_per_game:.1f} hits/game)")
        elif hits_rank and hits_rank <= 10:
            hits_per_game = pitcher_analysis.get('situational_factors', {}).get('hits_per_game', 0)
            stats_components.append(f"High hit vulnerability (#{hits_rank} in MLB, {hits_per_game:.1f} hits/game)")
            
        if hrs_rank and hrs_rank <= 5:
            hrs_per_game = pitcher_analysis.get('situational_factors', {}).get('hrs_per_game', 0)
            stats_components.append(f"Elite power vulnerability (#{hrs_rank} worst in MLB, {hrs_per_game:.2f} HR/game)")
        elif hrs_rank and hrs_rank <= 10:
            hrs_per_game = pitcher_analysis.get('situational_factors', {}).get('hrs_per_game', 0)
            stats_components.append(f"High power vulnerability (#{hrs_rank} in MLB, {hrs_per_game:.2f} HR/game)")
            
        # 7. CONTACT QUALITY EDGE
        if normalized_batter in self.custom_batters:
            batter_data = self.custom_batters[normalized_batter]
            barrel_percent = float(batter_data.get('barrel_percent', 0))
            hard_hit_percent = float(batter_data.get('hard_hit_percent', 0))
            
            if barrel_percent > 12:
                stats_components.append(f"Elite contact quality ({barrel_percent}% barrels, {hard_hit_percent}% hard hit)")
            elif barrel_percent > 8:
                stats_components.append(f"Strong contact quality ({barrel_percent}% barrels)")
                
        # 8. RECENT TRENDS
        if normalized_batter in self.batter_trends:
            trend = self.batter_trends[normalized_batter]
            if trend['trend'] == 'hot':
                justification_components.append(f"Hot hitter streak ({trend['recent_avg']:.3f} recent)")
                
        if normalized_pitcher in self.pitcher_trends:
            trend = self.pitcher_trends[normalized_pitcher]
            if trend['trend'] == 'deteriorating':
                justification_components.append(f"Struggling pitcher trend")
                
        # COMPILE FINAL JUSTIFICATION
        if len(stats_components) >= 3:
            # Full comprehensive justification with stats
            primary_weakness = stats_components[0]
            secondary_factors = " + ".join(stats_components[1:3])
            situational_factors = " + ".join(justification_components[:2]) if justification_components else ""
            
            if situational_factors:
                comprehensive_justification = f"{primary_weakness} + {secondary_factors} + {situational_factors}"
            else:
                comprehensive_justification = f"{primary_weakness} + {secondary_factors}"
                
        elif len(stats_components) >= 2:
            # Moderate comprehensive justification
            comprehensive_justification = " + ".join(stats_components[:2])
            if justification_components:
                comprehensive_justification += f" + {justification_components[0]}"
                
        elif stats_components:
            # Basic justification with some stats
            comprehensive_justification = stats_components[0]
            if justification_components:
                comprehensive_justification += f" + {justification_components[0]}"
        else:
            # Fallback to basic analysis
            comprehensive_justification = justification_components[0] if justification_components else "Matchup analysis indicates potential"
            
        return comprehensive_justification
    
    def generate_detailed_exploit_factors(self, batter_name, pitcher_name, pitcher_analysis, modern_analytics):
        """Generate detailed exploit factors from comprehensive analysis including arsenal breakdown"""
        exploit_factors = []
        
        # 1. ENHANCED Arsenal Exploitation (Most Important - First Priority)
        arsenal_exploitation = modern_analytics.get('arsenalExploitation', {})
        if arsenal_exploitation and arsenal_exploitation.get('vulnerable_pitches'):
            exploitation_score = arsenal_exploitation.get('exploitation_score', 0)
            
            # Overall arsenal matchup assessment
            if exploitation_score > 30:
                exploit_factors.append(f"EXCELLENT arsenal matchup ({exploitation_score} total exploit points)")
            elif exploitation_score > 20:
                exploit_factors.append(f"STRONG arsenal advantage ({exploitation_score} exploit points)")
            elif exploitation_score > 10:
                exploit_factors.append(f"Good arsenal matchup opportunity ({exploitation_score} points)")
            
            # Add top 3 specific pitch vulnerabilities
            best_matchups = arsenal_exploitation.get('best_matchups', [])[:3]
            for i, matchup in enumerate(best_matchups):
                pitch_name = matchup.get('pitch_name', 'Unknown')
                vuln_score = matchup.get('vulnerability_score', 0)
                usage_pct = matchup.get('usage_percent', 0)
                ba_against = matchup.get('ba_against', 0)
                
                # Get primary exploitation factor
                factors = matchup.get('exploitation_factors', [])
                primary_factor = factors[0] if factors else f"Vulnerable {pitch_name}"
                
                rank_indicator = f"#{i+1} " if len(best_matchups) > 1 else ""
                exploit_factors.append(f"{rank_indicator}Arsenal: {primary_factor}")
                
            # Add pitch type advantage summaries
            pitch_advantages = arsenal_exploitation.get('pitch_type_advantages', [])
            for advantage in pitch_advantages[:2]:  # Top 2 detailed advantages
                if advantage not in [f for f in exploit_factors if 'Arsenal:' in f]:
                    exploit_factors.append(f"Pitch Advantage: {advantage}")
        
        # 2. Arsenal Vulnerabilities (Legacy support + additional context)
        if modern_analytics.get('arsenalVulnerability'):
            for arsenal in modern_analytics['arsenalVulnerability']:
                pitch = arsenal.get('pitch', '')
                ba_against = arsenal.get('ba_against', 0)
                usage = arsenal.get('usage', 0)
                if ba_against > 0.290 and usage > 20:
                    exploit_factors.append(f"Critical {pitch} weakness: {ba_against:.3f} BA on {usage:.1f}% usage")
                elif ba_against > 0.280 and usage > 15:
                    exploit_factors.append(f"Vulnerable {pitch} allows {ba_against:.3f} BA on {usage:.1f}% usage")
        
        # 3. Expected Stats Regression Opportunities
        if modern_analytics.get('expectedStatsGap'):
            gaps = modern_analytics['expectedStatsGap']
            xba_gap = gaps.get('xba_gap', 0)
            xslg_gap = gaps.get('xslg_gap', 0)
            woba_gap = gaps.get('woba_gap', 0)
            
            if xba_gap < -0.025:
                exploit_factors.append(f"Major batting regression due (xBA gap: {xba_gap:.3f})")
            elif xba_gap < -0.020:
                exploit_factors.append(f"Batting regression opportunity (xBA gap: {xba_gap:.3f})")
                
            if xslg_gap < -0.040:
                exploit_factors.append(f"Major power regression due (xSLG gap: {xslg_gap:.3f})")
            elif xslg_gap < -0.035:
                exploit_factors.append(f"Power regression opportunity (xSLG gap: {xslg_gap:.3f})")
                
            if woba_gap < -0.030:
                exploit_factors.append(f"Overall performance regression due (wOBA gap: {woba_gap:.3f})")
            elif woba_gap < -0.025:
                exploit_factors.append(f"Overall performance regression (wOBA gap: {woba_gap:.3f})")
        
        # 4. Contact Quality & Exit Velocity Advantages
        normalized_batter = self.normalize_name(batter_name)
        if normalized_batter in self.hitter_exit_velocity:
            hitter_ev = self.hitter_exit_velocity[normalized_batter]
            barrel_rate = hitter_ev.get('real_barrel_rate', 0)
            hard_hit_percent = hitter_ev.get('hard_hit_percent', 0)
            avg_exit_velo = hitter_ev.get('avg_exit_velocity', 0)
            
            if barrel_rate > 15:
                exploit_factors.append(f"Elite barrel rate vs pitcher vulnerability ({barrel_rate:.1f}% barrels)")
            elif barrel_rate > 12:
                exploit_factors.append(f"Elite barrel rate advantage ({barrel_rate:.1f}% vs pitcher vulnerability)")
                
            if hard_hit_percent > 48:
                exploit_factors.append(f"Elite hard contact rate ({hard_hit_percent:.1f}% hard hit)")
            elif hard_hit_percent > 45:
                exploit_factors.append(f"Hard contact specialist ({hard_hit_percent:.1f}% hard hit rate)")
                
            if avg_exit_velo > 92:
                exploit_factors.append(f"Elite exit velocity vs vulnerable pitching ({avg_exit_velo:.1f} mph avg)")
            elif avg_exit_velo > 90:
                exploit_factors.append(f"Strong exit velocity advantage ({avg_exit_velo:.1f} mph avg)")
        
        # 5. Barrel Rate Matchup Analysis
        barrel_matchup = modern_analytics.get('barrelMatchup')
        if barrel_matchup and barrel_matchup.get('compound_advantage', 0) > 1.5:
            hitter_rate = barrel_matchup.get('hitter_rate', 0)
            pitcher_allowed = barrel_matchup.get('pitcher_allowed', 0)
            advantage = barrel_matchup.get('compound_advantage', 0)
            exploit_factors.append(f"Elite barrel matchup: {hitter_rate:.1f}% rate vs {pitcher_allowed:.1f}% allowed ({advantage:.1f}x advantage)")
        
        # 6. Ranking-Based Vulnerabilities (High-Value Targets)
        hits_rank = pitcher_analysis.get('situational_factors', {}).get('hits_rank')
        hrs_rank = pitcher_analysis.get('situational_factors', {}).get('hrs_rank')
        
        if hits_rank and hits_rank <= 5:
            hits_per_game = pitcher_analysis.get('situational_factors', {}).get('hits_per_game', 0)
            exploit_factors.append(f"Targets MLB #{hits_rank} most hits allowed ({hits_per_game:.1f}/game)")
        elif hits_rank and hits_rank <= 10:
            hits_per_game = pitcher_analysis.get('situational_factors', {}).get('hits_per_game', 0)
            exploit_factors.append(f"Targets top-10 hits allowed (#{hits_rank}, {hits_per_game:.1f}/game)")
            
        if hrs_rank and hrs_rank <= 5:
            hrs_per_game = pitcher_analysis.get('situational_factors', {}).get('hrs_per_game', 0)
            exploit_factors.append(f"Targets MLB #{hrs_rank} most HRs allowed ({hrs_per_game:.2f}/game)")
        elif hrs_rank and hrs_rank <= 10:
            hrs_per_game = pitcher_analysis.get('situational_factors', {}).get('hrs_per_game', 0)
            exploit_factors.append(f"Targets top-10 HR vulnerability (#{hrs_rank}, {hrs_per_game:.2f}/game)")
        
        # 5. Platoon and Handedness Advantages
        batter_hand = self.get_batter_handedness(batter_name)
        pitcher_hand = pitcher_analysis.get('situational_factors', {}).get('pitch_hand', 'R')
        if (batter_hand == 'L' and pitcher_hand == 'R') or (batter_hand == 'R' and pitcher_hand == 'L'):
            exploit_factors.append(f"Optimal platoon matchup ({batter_hand}HB vs {pitcher_hand}HP)")
        
        # 6. Recent Form Advantages (Enhanced)
        normalized_batter = self.normalize_name(batter_name)
        if normalized_batter in self.batter_trends:
            trend = self.batter_trends[normalized_batter]
            if trend['trend'] == 'hot':
                recent_avg = trend.get('recent_avg', 0)
                exploit_factors.append(f"Riding hot streak ({recent_avg:.3f} recent batting average)")
        
        # NEW: Enhanced Recent Form Analysis (Phase 5)
        if normalized_batter in self.recent_form_data:
            form_data = self.recent_form_data[normalized_batter]
            
            # Hot streak with specific metrics
            if form_data.get('hot_streak', False) or form_data.get('last_7_avg', 0) > 0.320:
                avg_7 = form_data.get('last_7_avg', 0)
                exploit_factors.append(f"Hot 7-game streak ({avg_7:.3f} BA, trending up)")
                
            # Power surge detection
            if form_data.get('last_7_hr', 0) >= 3:
                hr_count = form_data.get('last_7_hr', 0)
                exploit_factors.append(f"Power surge ({hr_count} HR in last 7 games)")
                
            # Momentum indicators
            if form_data.get('trend_direction') == 'improving':
                exploit_factors.append("Recent performance trending upward")
        
        # NEW: Lineup Position Context (Phase 6)
        if normalized_batter in self.lineup_data:
            lineup_info = self.lineup_data[normalized_batter]
            position = lineup_info.get('position', 0)
            
            # Prime RBI spots (3-4-5)
            if position in [3, 4, 5] and lineup_info.get('rbi_opportunities', 1.0) > 1.1:
                exploit_factors.append(f"Prime RBI position (#{position} in batting order)")
                
            # Table setters (1-2)
            elif position in [1, 2] and lineup_info.get('run_scoring_opportunities', 1.0) > 1.1:
                exploit_factors.append(f"Table setter role (#{position} in batting order)")
                
            # Strong protection
            if lineup_info.get('protection_quality', 0.5) > 0.7:
                exploit_factors.append("Strong lineup protection behind batter")
        
        return exploit_factors[:10]  # Expanded to top 10 factors for comprehensive analysis
    
    def analyze_arsenal_exploitation_matchup(self, batter_name, pitcher_name):
        """Analyze specific pitch-type vulnerabilities vs batter strengths with comprehensive breakdown"""
        normalized_batter = self.normalize_name(batter_name)
        normalized_pitcher = self.normalize_name(pitcher_name)
        
        arsenal_matchup = {
            'vulnerable_pitches': [],
            'exploitation_score': 0,
            'best_matchups': [],
            'pitch_type_advantages': []
        }
        
        # Get batter contact quality data
        batter_data = self.custom_batters.get(normalized_batter, {})
        batter_barrel_rate = float(batter_data.get('barrel_percent', 0))
        batter_hard_hit = float(batter_data.get('hard_hit_percent', 0))
        batter_bb_rate = float(batter_data.get('bb_percent', 0))
        batter_k_rate = float(batter_data.get('k_percent', 0))
        
        # Get exit velocity data for enhanced analysis
        exit_velo_data = self.hitter_exit_velocity.get(normalized_batter, {})
        batter_avg_ev = float(exit_velo_data.get('avg_exit_velocity', 0))
        batter_max_ev = float(exit_velo_data.get('max_exit_velocity', 0))
        
        # Get pitcher arsenal data
        if normalized_pitcher not in self.pitcher_arsenal:
            # Return with fallback data if no arsenal available
            return arsenal_matchup
            
        arsenal = self.pitcher_arsenal[normalized_pitcher]['pitch_types']
        total_usage = sum(float(p.get('usage_percent', 0)) for p in arsenal.values())
        
        for pitch_type, pitch_data in arsenal.items():
            pitch_name = pitch_data['pitch_name']
            ba_against = float(pitch_data.get('ba_against', 0))
            slg_against = float(pitch_data.get('slg_against', 0))
            usage_percent = float(pitch_data.get('usage_percent', 0))
            whiff_percent = float(pitch_data.get('whiff_percent', 0))
            zone_percent = float(pitch_data.get('zone_percent', 0))
            
            # Skip pitches with very low usage
            if usage_percent < 8:
                continue
                
            pitch_vulnerability_score = 0
            exploitation_factors = []
            
            # 1. FASTBALL EXPLOITATION (Enhanced)
            if any(fb in pitch_name.lower() for fb in ['4-seam', 'fastball', 'sinker', '2-seam']):
                # High contact quality batters vs vulnerable fastballs
                if ba_against > 0.290 and batter_barrel_rate > 10:
                    pitch_vulnerability_score += 18
                    exploitation_factors.append(f"Elite barrel rate vs FB hole ({ba_against:.3f} BA, {batter_barrel_rate:.1f}% barrels)")
                elif ba_against > 0.280 and batter_barrel_rate > 8:
                    pitch_vulnerability_score += 15
                    exploitation_factors.append(f"Elite contact vs vulnerable FB ({ba_against:.3f} BA allowed)")
                elif ba_against > 0.260 and batter_barrel_rate > 6:
                    pitch_vulnerability_score += 10
                    exploitation_factors.append(f"Strong contact vs FB weakness ({ba_against:.3f} BA)")
                    
                # Power hitters vs power-vulnerable fastballs
                if slg_against > 0.520 and batter_barrel_rate > 12:
                    pitch_vulnerability_score += 16
                    exploitation_factors.append(f"Elite power vs FB power leak ({slg_against:.3f} SLG allowed)")
                elif slg_against > 0.500 and batter_barrel_rate > 10:
                    pitch_vulnerability_score += 12
                    exploitation_factors.append(f"Power vs FB power vulnerability ({slg_against:.3f} SLG allowed)")
                
                # Exit velocity advantages
                if batter_avg_ev > 90 and ba_against > 0.270:
                    pitch_vulnerability_score += 8
                    exploitation_factors.append(f"Hard contact specialist vs hittable FB ({batter_avg_ev:.1f} mph avg EV)")
                    
            # 2. SLIDER/CUTTER EXPLOITATION (Enhanced)  
            elif any(x in pitch_name.lower() for x in ['slider', 'cutter']):
                # Patient hitters vs ineffective sliders
                if whiff_percent < 30 and batter_bb_rate > 12:
                    pitch_vulnerability_score += 14
                    exploitation_factors.append(f"Elite patience vs weak {pitch_name} ({whiff_percent:.1f}% whiff, {batter_bb_rate:.1f}% BB)")
                elif whiff_percent < 25 and batter_bb_rate > 10:
                    pitch_vulnerability_score += 12
                    exploitation_factors.append(f"Patient hitter vs poor {pitch_name} ({whiff_percent:.1f}% whiff)")
                elif whiff_percent < 35 and batter_bb_rate > 8:
                    pitch_vulnerability_score += 8
                    exploitation_factors.append(f"Disciplined vs mediocre {pitch_name}")
                    
                # Contact vs hittable sliders
                if ba_against > 0.260 and batter_hard_hit > 42:
                    pitch_vulnerability_score += 12
                    exploitation_factors.append(f"Hard contact vs hittable {pitch_name} ({ba_against:.3f} BA, {batter_hard_hit:.1f}% hard hit)")
                elif ba_against > 0.240 and batter_hard_hit > 40:
                    pitch_vulnerability_score += 8
                    exploitation_factors.append(f"Contact quality vs vulnerable {pitch_name}")
                    
            # 3. CURVEBALL EXPLOITATION (Enhanced)
            elif 'curve' in pitch_name.lower():
                # Low strikeout hitters vs ineffective curves
                if whiff_percent < 35 and batter_k_rate < 20:
                    pitch_vulnerability_score += 12
                    exploitation_factors.append(f"Contact hitter vs weak {pitch_name} ({batter_k_rate:.1f}% K, {whiff_percent:.1f}% whiff)")
                elif whiff_percent < 40 and batter_k_rate < 25:
                    pitch_vulnerability_score += 9
                    exploitation_factors.append(f"Tough-to-K vs poor {pitch_name}")
                    
                # High BA against vulnerable curves
                if ba_against > 0.270:
                    pitch_vulnerability_score += 10
                    exploitation_factors.append(f"Hittable {pitch_name} allows {ba_against:.3f} BA")
                    
            # 4. CHANGEUP/OFFSPEED EXPLOITATION (Enhanced)
            elif any(x in pitch_name.lower() for x in ['change', 'split', 'fork']):
                # Aggressive hitters vs ineffective changeups
                if ba_against > 0.260 and whiff_percent < 40:
                    pitch_vulnerability_score += 12
                    exploitation_factors.append(f"Timing advantage vs weak {pitch_name} ({ba_against:.3f} BA, {whiff_percent:.1f}% whiff)")
                elif ba_against > 0.240 and whiff_percent < 35:
                    pitch_vulnerability_score += 10
                    exploitation_factors.append(f"Good timing vs poor {pitch_name}")
                    
                # Zone command issues with changeups
                if zone_percent < 40 and batter_bb_rate > 10:
                    pitch_vulnerability_score += 8
                    exploitation_factors.append(f"Patient hitter vs wild {pitch_name} ({zone_percent:.1f}% zone)")
                    
            # 5. HEAVY USAGE VULNERABILITY (Enhanced)
            if usage_percent > 35 and ba_against > 0.280:
                pitch_vulnerability_score += 12
                exploitation_factors.append(f"Over-relied weak {pitch_name} ({usage_percent:.1f}% usage, {ba_against:.3f} BA)")
            elif usage_percent > 30 and ba_against > 0.270:
                pitch_vulnerability_score += 8
                exploitation_factors.append(f"Heavily used vulnerable {pitch_name} ({usage_percent:.1f}% usage)")
            elif usage_percent > 25 and ba_against > 0.300:
                pitch_vulnerability_score += 10
                exploitation_factors.append(f"Primary pitch weakness ({usage_percent:.1f}% usage, {ba_against:.3f} BA)")
                
            # 6. ZONE COMMAND ISSUES
            if zone_percent < 45 and usage_percent > 20:
                pitch_vulnerability_score += 6
                exploitation_factors.append(f"Command issues with {pitch_name} ({zone_percent:.1f}% zone rate)")
                
            # Compile detailed pitch analysis
            if pitch_vulnerability_score > 0:
                vulnerable_pitch = {
                    'pitch_name': pitch_name,
                    'vulnerability_score': pitch_vulnerability_score,
                    'usage_percent': usage_percent,
                    'ba_against': ba_against,
                    'slg_against': slg_against,
                    'whiff_percent': whiff_percent,
                    'zone_percent': zone_percent,
                    'exploitation_factors': exploitation_factors[:3],  # Top 3 factors
                    'matchup_quality': 'excellent' if pitch_vulnerability_score >= 15 else 'good' if pitch_vulnerability_score >= 10 else 'fair'
                }
                
                arsenal_matchup['vulnerable_pitches'].append(vulnerable_pitch)
                arsenal_matchup['exploitation_score'] += pitch_vulnerability_score
                
        # Rank and select best matchups
        arsenal_matchup['vulnerable_pitches'].sort(key=lambda x: x['vulnerability_score'], reverse=True)
        arsenal_matchup['best_matchups'] = arsenal_matchup['vulnerable_pitches'][:4]  # Top 4 matchups
        
        # Create comprehensive pitch type advantage summary
        for i, pitch in enumerate(arsenal_matchup['best_matchups']):
            rank_prefix = f"#{i+1} " if len(arsenal_matchup['best_matchups']) > 1 else ""
            advantage_summary = f"{rank_prefix}{pitch['pitch_name']}: {pitch['vulnerability_score']} pts ({pitch['usage_percent']:.1f}% usage, {pitch['ba_against']:.3f} BA)"
            
            if pitch['exploitation_factors']:
                primary_factor = pitch['exploitation_factors'][0]
                advantage_summary += f" - {primary_factor}"
                
            arsenal_matchup['pitch_type_advantages'].append(advantage_summary)
            
        # Add overall arsenal assessment
        if arsenal_matchup['exploitation_score'] > 30:
            arsenal_matchup['overall_assessment'] = f"Excellent arsenal matchup ({arsenal_matchup['exploitation_score']} total points)"
        elif arsenal_matchup['exploitation_score'] > 20:
            arsenal_matchup['overall_assessment'] = f"Good arsenal matchup ({arsenal_matchup['exploitation_score']} total points)"
        elif arsenal_matchup['exploitation_score'] > 10:
            arsenal_matchup['overall_assessment'] = f"Fair arsenal matchup ({arsenal_matchup['exploitation_score']} total points)"
        else:
            arsenal_matchup['overall_assessment'] = f"Limited arsenal advantage ({arsenal_matchup['exploitation_score']} total points)"
            
        return arsenal_matchup
    
    def identify_exploitation_windows(self, pitcher_name):
        """Identify specific situations where pitcher is most vulnerable"""
        windows = []
        
        if pitcher_name in self.pitcher_arsenal:
            arsenal = self.pitcher_arsenal[pitcher_name]['pitch_types']
            
            # First pitch vulnerability
            fastball_data = next((p for p in arsenal.values() if '4-seam' in p['pitch_name'].lower()), None)
            if fastball_data and fastball_data.get('ba_against', 0) > 0.280:
                windows.append("First pitch fastball (high BA against)")
            
            # Behind in count vulnerability
            breaking_balls = [p for p in arsenal.values() if any(x in p['pitch_name'].lower() for x in ['slider', 'curve', 'cutter'])]
            if not breaking_balls or all(p.get('whiff_percent', 0) < 25 for p in breaking_balls):
                windows.append("Behind in count (limited put-away pitches)")
        
        return windows
    
    def analyze_enhanced_batter_exploit_potential(self, batter_name, pitcher_name, pitcher_vulnerabilities, venue='', batter_team='', venue_home_team=''):
        """Enhanced batter exploit analysis with situational advantages"""
        normalized_batter = self.normalize_name(batter_name)
        normalized_pitcher = self.normalize_name(pitcher_name)
        
        # ENHANCED MULTIPLICATIVE SCORING: Increased baseline per baseball-stats-expert recommendations
        # Start with enhanced neutral matchup baseline for comprehensive data
        matchup_score = 65.0  # ENHANCED: Increased from 50.0 to 65.0 for better score distribution
        
        # MATCHUP ANALYSIS: Calculate true pitcher-batter advantage ratios
        batter_quality_multiplier = 1.0
        pitcher_vulnerability_multiplier = 1.0
        situational_multiplier = 1.0
        
        # 1. BATTER QUALITY ASSESSMENT (0.7 - 1.3 multiplier range)
        custom_data = self.find_batter_data(batter_name)
        if custom_data:
            # Real performance metrics - create meaningful differentiation
            barrel_percent = float(custom_data.get('barrel_percent', 0))
            bb_percent = float(custom_data.get('bb_percent', 0))
            k_percent = float(custom_data.get('k_percent', 0))
            sprint_speed = float(custom_data.get('sprint_speed', 0))
            
            # Expected stats vs actual (regression potential)
            xba_diff = float(custom_data.get('xba_diff', 0))  # BA - xBA (negative = underperforming)
            xslg_diff = float(custom_data.get('xslg_diff', 0))  # SLG - xSLG (negative = underperforming)
            
            # BARREL RATE FACTOR (20% weight) - most predictive of power success
            if barrel_percent >= 15:      # Elite (top 2%)
                barrel_factor = 1.25
            elif barrel_percent >= 12:    # Excellent (top 5%)
                barrel_factor = 1.15
            elif barrel_percent >= 9:     # Good (top 15%)
                barrel_factor = 1.05
            elif barrel_percent >= 6:     # Average (top 50%)
                barrel_factor = 1.0
            elif barrel_percent >= 3:     # Below average
                barrel_factor = 0.95
            else:                         # Poor
                barrel_factor = 0.85
                
            # PLATE DISCIPLINE FACTOR (15% weight)
            if bb_percent > 12 and k_percent < 18:    # Elite patience
                discipline_factor = 1.15
            elif bb_percent > 9 and k_percent < 22:   # Good patience  
                discipline_factor = 1.08
            elif bb_percent > 6 and k_percent < 25:   # Average
                discipline_factor = 1.0
            elif k_percent > 30:                      # Swing-happy
                discipline_factor = 0.90
            else:
                discipline_factor = 0.95
                
            # SPEED FACTOR (10% weight) - affects BABIP and extra bases
            if sprint_speed > 29:        # Elite speed
                speed_factor = 1.1
            elif sprint_speed > 27:      # Fast
                speed_factor = 1.05
            elif sprint_speed > 25:      # Average
                speed_factor = 1.0
            elif sprint_speed > 23:      # Slow
                speed_factor = 0.97
            else:                        # Very slow
                speed_factor = 0.93
                
            # REGRESSION FACTOR (15% weight) - underperformance = opportunity
            if xba_diff < -0.040 or xslg_diff < -0.060:    # Major underperformance
                regression_factor = 1.20
            elif xba_diff < -0.025 or xslg_diff < -0.035:  # Moderate underperformance
                regression_factor = 1.10
            elif xba_diff < -0.015 or xslg_diff < -0.020:  # Minor underperformance
                regression_factor = 1.05
            elif xba_diff > 0.025 or xslg_diff > 0.040:    # Overperforming (negative)
                regression_factor = 0.90
            else:                                          # Neutral
                regression_factor = 1.0
                
            # COMBINE BATTER FACTORS (weighted average)
            batter_quality_multiplier = (
                barrel_factor * 0.35 +          # 35% weight - most important
                discipline_factor * 0.25 +      # 25% weight 
                speed_factor * 0.20 +           # 20% weight
                regression_factor * 0.20        # 20% weight
            )
        
        # 2. PITCHER VULNERABILITY ASSESSMENT (0.8 - 1.2 multiplier range)
        if pitcher_vulnerabilities:
            # ERA and WHIP indicate overall effectiveness
            pitcher_era = pitcher_vulnerabilities.get('pitcher_stats', {}).get('era', 4.50)
            pitcher_whip = pitcher_vulnerabilities.get('pitcher_stats', {}).get('whip', 1.30)
            hr_rate = pitcher_vulnerabilities.get('pitcher_stats', {}).get('hrPerGame', 1.0)
            
            # ERA vulnerability (30% weight)
            if pitcher_era > 5.5:        # Very poor
                era_factor = 1.15
            elif pitcher_era > 4.8:      # Poor
                era_factor = 1.08
            elif pitcher_era > 4.2:      # Below average
                era_factor = 1.03
            elif pitcher_era < 3.0:      # Excellent
                era_factor = 0.85
            elif pitcher_era < 3.5:      # Good
                era_factor = 0.92
            else:                        # Average
                era_factor = 1.0
                
            # HR rate vulnerability (25% weight)
            if hr_rate > 1.5:           # Very vulnerable
                hr_factor = 1.12
            elif hr_rate > 1.2:         # Vulnerable
                hr_factor = 1.06
            elif hr_rate < 0.8:         # Stingy
                hr_factor = 0.88
            elif hr_rate < 1.0:         # Good
                hr_factor = 0.94
            else:                       # Average
                hr_factor = 1.0
                
            # WHIP vulnerability (20% weight)
            if pitcher_whip > 1.45:     # Poor control
                whip_factor = 1.08
            elif pitcher_whip > 1.35:   # Below average
                whip_factor = 1.04
            elif pitcher_whip < 1.15:   # Excellent
                whip_factor = 0.92
            elif pitcher_whip < 1.25:   # Good
                whip_factor = 0.96
            else:                       # Average
                whip_factor = 1.0
                
            # COMBINE PITCHER FACTORS
            pitcher_vulnerability_multiplier = (
                era_factor * 0.40 +         # 40% weight
                hr_factor * 0.35 +          # 35% weight
                whip_factor * 0.25          # 25% weight
            )
        
        # 3. PHASE 1 ENHANCEMENT: HANDEDNESS-SPECIFIC MATCHUP ANALYSIS
        handedness_analysis = self.analyze_handedness_matchup_advantage(batter_name, pitcher_name)
        if handedness_analysis['advantage_score'] > 0:
            handedness_multiplier = 1.0 + (handedness_analysis['advantage_score'] / 100)  # Convert to multiplier
            situational_multiplier *= handedness_multiplier
            
        # 4. PHASE 1 ENHANCEMENT: SWING PATH OPTIMIZATION ANALYSIS  
        swing_optimization = self.analyze_swing_path_optimization(batter_name, pitcher_name)
        if swing_optimization['optimization_score'] > 0:
            swing_multiplier = 1.0 + (swing_optimization['optimization_score'] / 200)  # More conservative multiplier
            situational_multiplier *= swing_multiplier
            
        # 5. PHASE 1 ENHANCEMENT: MULTI-YEAR PITCHER REGRESSION ANALYSIS
        regression_analysis = self.analyze_multi_year_pitcher_regression(pitcher_name)
        if regression_analysis['regression_score'] > 0:
            regression_multiplier = 1.0 + (regression_analysis['regression_score'] / 150)  # Regression bonus
            pitcher_vulnerability_multiplier *= regression_multiplier
            
        # 6. SITUATIONAL MATCHUP FACTORS (0.9 - 1.15 multiplier range)
        situational_factors = []
        
        # Include enhanced analysis factors
        if handedness_analysis['key_advantages']:
            situational_factors.extend(handedness_analysis['key_advantages'][:2])
        if swing_optimization['key_optimizations']:
            situational_factors.extend(swing_optimization['key_optimizations'][:2])
        if regression_analysis['regression_indicators']:
            situational_factors.extend(regression_analysis['regression_indicators'][:1])
        
        # Platoon advantage (traditional analysis)
        batter_hand = self.get_batter_handedness(batter_name)
        pitcher_hand = pitcher_vulnerabilities.get('situational_factors', {}).get('pitch_hand', 'R')
        if (batter_hand == 'L' and pitcher_hand == 'R') or (batter_hand == 'R' and pitcher_hand == 'L'):
            situational_multiplier *= 1.08  # 8% boost for platoon advantage
            situational_factors.append(f"{batter_hand}HB vs {pitcher_hand}HP platoon advantage")
        
        # Hot streak bonus
        if normalized_batter in self.batter_trends:
            trend = self.batter_trends[normalized_batter]
            if trend['trend'] == 'hot':
                situational_multiplier *= 1.06  # 6% boost for hot streak
                situational_factors.append(f"Hot streak ({trend['recent_avg']:.3f} last 5 games)")
        
        # CALCULATE FINAL SCORE using multiplicative model
        final_score = matchup_score * batter_quality_multiplier * pitcher_vulnerability_multiplier * situational_multiplier
        
        # Round to 1 decimal place for readability
        final_score = round(final_score, 1)
        
        exploit_analysis = {
            'exploit_score': final_score,
            'confidence': 0.6,  # ENHANCED: Increased baseline from 0.4 to 0.6 for comprehensive data
            'exploit_factors': [],
            'batter_classification': 'unknown',
            'modern_analytics': {
                'batter_quality_multiplier': round(batter_quality_multiplier, 3),
                'pitcher_vulnerability_multiplier': round(pitcher_vulnerability_multiplier, 3),
                'situational_multiplier': round(situational_multiplier, 3)
            },
            'situational_advantages': situational_factors,
            'matchup_intelligence': {},
            'park_adjustment': 1.0
        }
        
        # 1. Enhanced Contact Quality Analysis
        # PHASE 3: Refined exit velocity analysis with controlled scoring
        if normalized_batter in self.hitter_exit_velocity:
            hitter_ev = self.hitter_exit_velocity[normalized_batter]
            
            # ENHANCED MODERN ANALYTICS: Barrel rate with increased weighting per baseball-stats-expert recommendations
            barrel_rate = hitter_ev['real_barrel_rate']
            if barrel_rate >= 12:  # True elite (top 5%)
                exploit_analysis['exploit_score'] += 30  # ENHANCED: Increased from 18 to 30 for elite barrel rate
                exploit_analysis['exploit_factors'].append(f"Elite barrel rate ({barrel_rate:.1f}%)")
                exploit_analysis['batter_classification'] = 'elite_power'
                
                # Check pitcher vulnerability with meaningful bonuses
                if pitcher_vulnerabilities.get('situational_factors', {}).get('barrel_vulnerability') == 'extreme':
                    exploit_analysis['exploit_score'] += 20  # ENHANCED: Increased from 15 to 20
                    exploit_analysis['situational_advantages'].append("Elite power vs extreme vulnerability")
                elif pitcher_vulnerabilities.get('situational_factors', {}).get('barrel_vulnerability') == 'high':
                    exploit_analysis['exploit_score'] += 18  # ENHANCED: Increased from 12 to 18
                    
            elif barrel_rate >= 9:  # Very good (top 20%)
                exploit_analysis['exploit_score'] += 20  # ENHANCED: Increased from 12 to 20
                exploit_analysis['exploit_factors'].append(f"Strong barrel rate ({barrel_rate:.1f}%)")
                exploit_analysis['batter_classification'] = 'power_threat'
                
                if pitcher_vulnerabilities.get('situational_factors', {}).get('barrel_vulnerability') in ['extreme', 'high']:
                    exploit_analysis['exploit_score'] += 12  # ENHANCED: Increased from 8 to 12
                    
            elif barrel_rate >= 7:  # Above average
                exploit_analysis['exploit_score'] += 10  # ENHANCED: Increased from 6 to 10
                exploit_analysis['exploit_factors'].append(f"Good barrel rate ({barrel_rate:.1f}%)")
                
            elif barrel_rate < 4:  # Below average (penalty)
                exploit_analysis['exploit_score'] -= 3
                exploit_analysis['exploit_factors'].append(f"Low barrel rate ({barrel_rate:.1f}%)")
            
            # RESTORED: Max exit velocity with meaningful impact
            max_velo = hitter_ev['max_hit_speed']
            if max_velo >= 116:  # True elite power
                exploit_analysis['exploit_score'] += 8  # RESTORED meaningful scoring
                exploit_analysis['exploit_factors'].append(f"Elite max exit velocity ({max_velo:.1f} mph)")
            elif max_velo >= 113:
                exploit_analysis['exploit_score'] += 5  # RESTORED meaningful scoring
            elif max_velo >= 110:
                exploit_analysis['exploit_score'] += 3  # RESTORED - meaningful difference
            elif max_velo < 105:  # Weak power
                exploit_analysis['exploit_score'] -= 2
            
            exploit_analysis['confidence'] += 0.25
            
            # ENHANCED: Data completeness bonus when modern analytics are present
            exploit_analysis['confidence'] += 0.2  # Additional confidence for comprehensive exit velocity data
        
        # 1.5. Phase 1 Enhancement: Contact Exploiter Detection
        # Reuse custom_data from earlier lookup or find again if needed
        if not custom_data:
            custom_data = self.find_batter_data(batter_name)
        if custom_data:
            
            # Contact quality metrics (NEW)
            sweet_spot_percent = float(custom_data.get('sweet_spot_percent', 0))
            whiff_rate = float(custom_data.get('whiff_percent', 0))
            k_percent = float(custom_data.get('k_percent', 0))
            
            # ENHANCED CONTACT SCORING: More realistic thresholds for contact hitter identification
            contact_bonus = 0
            
            # Elite contact hitters (top 5%)
            if sweet_spot_percent > 38:  # Lowered from 40 for more realistic elite threshold
                contact_bonus += 20  # Increased from 12 for better recognition
                if whiff_rate < 18:  # Elite whiff avoidance
                    contact_bonus += 10  # Increased from 6
                    if k_percent < 16:  # Elite strikeout avoidance
                        contact_bonus += 8  # Increased from 4
                        exploit_analysis['batter_classification'] = 'elite_contact'
                        exploit_analysis['exploit_factors'].append(f"ELITE contact profile ({sweet_spot_percent:.1f}% sweet spot, {k_percent:.1f}% K)")
                elif whiff_rate < 22:
                    contact_bonus += 6  # Increased from 3
                    exploit_analysis['batter_classification'] = 'elite_contact'
                    
            # Strong contact hitters (top 15%)
            elif sweet_spot_percent > 35:  # Lowered from 37 for better recognition
                contact_bonus += 15  # Increased from 8
                if whiff_rate < 20:
                    contact_bonus += 8  # Increased from 4
                    if k_percent < 18:
                        contact_bonus += 5  # Increased from 2
                        exploit_analysis['batter_classification'] = 'strong_contact'
                        exploit_analysis['exploit_factors'].append(f"Strong contact profile ({sweet_spot_percent:.1f}% sweet spot, {k_percent:.1f}% K)")
                elif whiff_rate < 24:
                    contact_bonus += 4  # Increased from 2
                    exploit_analysis['batter_classification'] = 'strong_contact'
                    
            # Good contact hitters (top 35%)
            elif sweet_spot_percent > 32:  # Lowered from 34 for broader recognition
                contact_bonus += 12  # Increased from 5
                if whiff_rate < 22 and k_percent < 20:
                    contact_bonus += 6  # Increased from 3
                    exploit_analysis['batter_classification'] = 'contact_hitter'
                    exploit_analysis['exploit_factors'].append(f"Good contact profile ({sweet_spot_percent:.1f}% sweet spot, {k_percent:.1f}% K)")
                elif whiff_rate < 25:
                    contact_bonus += 3
                    exploit_analysis['batter_classification'] = 'contact_hitter'
                    
            # Average contact (top 50%)
            elif sweet_spot_percent > 29:  # Lowered from 31 for average recognition
                contact_bonus += 8  # Increased from 2
                if whiff_rate < 24:
                    contact_bonus += 3  # Increased from 1
                    exploit_analysis['batter_classification'] = 'contact_hitter'
                    exploit_analysis['exploit_factors'].append(f"Solid contact rate ({sweet_spot_percent:.1f}% sweet spot)")
                    
            # Below average contact (penalty)
            elif sweet_spot_percent < 26:  # Lowered from 28 for more realistic penalty threshold
                contact_bonus -= 5  # Increased penalty from -3
                if whiff_rate > 30:  # High whiff rate
                    contact_bonus -= 4  # Increased penalty from -2
                    exploit_analysis['exploit_factors'].append(f"Contact concerns ({sweet_spot_percent:.1f}% sweet spot, {whiff_rate:.1f}% whiff)")
            
            # Walk exploiter detection (Phase 1)
            z_swing_percent = float(custom_data.get('z_swing_percent', 0))  
            oz_swing_percent = float(custom_data.get('oz_swing_percent', 0))
            bb_percent = float(custom_data.get('bb_percent', 0))
            
            # Phase 2: Enhanced walk specialist scoring with major bonuses
            walk_bonus = 0
            if bb_percent > 16:  # Elite+ walk rate
                walk_bonus += 40
                if oz_swing_percent < 20:  # Elite plate discipline
                    walk_bonus += 25
                    if z_swing_percent > 75:  # Perfect selectivity
                        walk_bonus += 20
                        exploit_analysis['batter_classification'] = 'elite_walk_specialist'
                        exploit_analysis['exploit_factors'].append(f"ELITE walk specialist ({bb_percent:.1f}% BB rate, {oz_swing_percent:.1f}% chase, {z_swing_percent:.1f}% zone aggression)")
            elif bb_percent > 14:  # Elite walk rate
                walk_bonus += 30
                if oz_swing_percent < 22:  # Excellent plate discipline
                    walk_bonus += 20
                    if z_swing_percent > 72:  # Selective but aggressive in zone
                        walk_bonus += 15
                        if exploit_analysis['batter_classification'] in ['unknown', 'marginal_opportunity']:
                            exploit_analysis['batter_classification'] = 'elite_walk_specialist'
                        exploit_analysis['exploit_factors'].append(f"Elite walk specialist ({bb_percent:.1f}% BB rate, {oz_swing_percent:.1f}% chase)")
            elif bb_percent > 12:  # Strong walk rate
                walk_bonus += 22
                if oz_swing_percent < 25:  # Good plate discipline
                    walk_bonus += 15
                    if z_swing_percent > 70:
                        walk_bonus += 10
                        exploit_analysis['batter_classification'] = 'strong_walk_specialist'
                        exploit_analysis['exploit_factors'].append(f"Strong walk specialist ({bb_percent:.1f}% BB rate, {oz_swing_percent:.1f}% chase)")
            elif bb_percent > 10:  # Above average walks
                walk_bonus += 15
                if oz_swing_percent < 28:
                    walk_bonus += 8
                    exploit_analysis['batter_classification'] = 'walk_specialist'
                    exploit_analysis['exploit_factors'].append(f"Walk specialist ({bb_percent:.1f}% BB rate)")
            elif bb_percent > 8:  # Decent walks
                walk_bonus += 8
                if oz_swing_percent < 30:
                    walk_bonus += 5
                    exploit_analysis['exploit_factors'].append(f"Good discipline ({bb_percent:.1f}% BB rate)")
            
            # Phase 2: Enhanced speed threat scoring with major bonuses
            sprint_speed = float(custom_data.get('sprint_speed', 0))
            speed_bonus = 0
            if sprint_speed > 30:  # Elite+ speed
                speed_bonus += 35
                exploit_analysis['batter_classification'] = 'elite_speed_threat'
                exploit_analysis['exploit_factors'].append(f"ELITE speed threat ({sprint_speed:.1f} ft/sec - top tier)")
            elif sprint_speed > 29:  # Elite speed
                speed_bonus += 28
                exploit_analysis['batter_classification'] = 'elite_speed_threat'
                exploit_analysis['exploit_factors'].append(f"Elite speed threat ({sprint_speed:.1f} ft/sec)")
            elif sprint_speed > 27:  # Fast runner
                speed_bonus += 20
                exploit_analysis['batter_classification'] = 'strong_speed_threat'
                exploit_analysis['exploit_factors'].append(f"Strong speed threat ({sprint_speed:.1f} ft/sec)")
            elif sprint_speed > 25:  # Above average speed
                speed_bonus += 12
                exploit_analysis['batter_classification'] = 'speed_threat'
                exploit_analysis['exploit_factors'].append(f"Speed threat ({sprint_speed:.1f} ft/sec)")
            elif sprint_speed > 23:  # Decent speed
                speed_bonus += 8
                exploit_analysis['exploit_factors'].append(f"Good speed ({sprint_speed:.1f} ft/sec)")
            
            # Enhanced expected stats regression (Phase 1 improvement)
            xba_diff = float(custom_data.get('xba_diff', 0))
            xslg_diff = float(custom_data.get('xslg_diff', 0))
            woba_diff = float(custom_data.get('woba_diff', 0))
            
            # ENHANCED EXPECTED STATS: Increased regression impact by 50% per baseball-stats-expert recommendations
            regression_bonus = 0
            if xba_diff < -0.05:  # Extreme BA underperformance (BA much lower than xBA)
                regression_bonus += 38  # ENHANCED: Increased from 25 to 38 (50% boost)
                exploit_analysis['exploit_factors'].append(f"EXTREME BA regression opportunity (underperforming xBA by {abs(xba_diff):.3f})")
            elif xba_diff < -0.04:  # Major BA underperformance
                regression_bonus += 30  # ENHANCED: Increased from 20 to 30 (50% boost)
                exploit_analysis['exploit_factors'].append(f"Major BA regression opportunity (underperforming xBA by {abs(xba_diff):.3f})")
            elif xba_diff < -0.025:  # Significant BA underperformance
                regression_bonus += 23  # ENHANCED: Increased from 15 to 23 (50% boost)
                exploit_analysis['exploit_factors'].append(f"BA regression opportunity (underperforming xBA by {abs(xba_diff):.3f})")
            elif xba_diff < -0.015:  # Moderate BA underperformance
                regression_bonus += 15  # ENHANCED: Increased from 10 to 15 (50% boost)
                exploit_analysis['exploit_factors'].append(f"Mild BA regression opportunity (underperforming xBA by {abs(xba_diff):.3f})")
                
            if xslg_diff < -0.08:  # Extreme SLG underperformance (SLG much lower than xSLG)
                regression_bonus += 45  # ENHANCED: Increased from 30 to 45 (50% boost)
                exploit_analysis['exploit_factors'].append(f"EXTREME SLG regression opportunity (underperforming xSLG by {abs(xslg_diff):.3f})")
            elif xslg_diff < -0.06:  # Major SLG underperformance
                regression_bonus += 38  # ENHANCED: Increased from 25 to 38 (50% boost)
                exploit_analysis['exploit_factors'].append(f"Major SLG regression opportunity (underperforming xSLG by {abs(xslg_diff):.3f})")
            elif xslg_diff < -0.04:  # Significant SLG underperformance
                regression_bonus += 27  # ENHANCED: Increased from 18 to 27 (50% boost)
                exploit_analysis['exploit_factors'].append(f"SLG regression opportunity (underperforming xSLG by {abs(xslg_diff):.3f})")
            elif xslg_diff < -0.025:  # Moderate SLG underperformance
                regression_bonus += 18  # ENHANCED: Increased from 12 to 18 (50% boost)
                exploit_analysis['exploit_factors'].append(f"Mild SLG regression opportunity (underperforming xSLG by {abs(xslg_diff):.3f})")
                
            
            # FIXED: Apply ALL category bonuses (contact hitters were being ignored!)
            # Contact hitters need their bonuses applied alongside walk/speed bonuses
            total_category_bonus = contact_bonus + walk_bonus + speed_bonus
            total_enhancement = total_category_bonus + regression_bonus
            exploit_analysis['exploit_score'] += total_enhancement
            
            # Enhanced contact hitter recognition and classification preservation
            if contact_bonus > 0:
                exploit_analysis['exploit_factors'].append(f"Contact bonus: +{contact_bonus} pts (Sweet Spot: {sweet_spot_percent:.1f}%, Whiff: {whiff_rate:.1f}%)")
                
                # Preserve contact hitter classifications - don't let other categories override
                if sweet_spot_percent > 32 and exploit_analysis['batter_classification'] in ['unknown', 'marginal_opportunity', 'weak_opportunity']:
                    if sweet_spot_percent > 38:
                        exploit_analysis['batter_classification'] = 'elite_contact'
                    elif sweet_spot_percent > 35:
                        exploit_analysis['batter_classification'] = 'strong_contact'
                    else:
                        exploit_analysis['batter_classification'] = 'contact_hitter'
                        
                # Add contact-specific situational advantages
                if k_percent < 18 and whiff_rate < 22:
                    exploit_analysis['situational_advantages'].append(f"Low strikeout contact hitter ({k_percent:.1f}% K, {whiff_rate:.1f}% whiff)")
                elif sweet_spot_percent > 35:
                    exploit_analysis['situational_advantages'].append(f"High contact quality ({sweet_spot_percent:.1f}% sweet spot rate)")
            
            # ENHANCED: Improved confidence for comprehensive data with multi-source validation
            if total_enhancement > 20:
                exploit_analysis['confidence'] += 0.25  # ENHANCED: Increased from 0.2
            elif total_enhancement > 10:
                exploit_analysis['confidence'] += 0.20  # ENHANCED: Increased from 0.15
            else:
                exploit_analysis['confidence'] += 0.15  # ENHANCED: Increased from 0.1
                
            # ENHANCED: Multi-source validation bonus per baseball-stats-expert recommendations
            data_sources_count = 0
            if custom_data: data_sources_count += 1
            if normalized_batter in self.hitter_exit_velocity: data_sources_count += 1
            if normalized_batter in self.batter_trends: data_sources_count += 1
            if normalized_batter in self.recent_form_data: data_sources_count += 1
            if normalized_batter in self.lineup_data: data_sources_count += 1
            
            if data_sources_count >= 4:
                exploit_analysis['confidence'] += 0.15  # Multi-source validation bonus
                exploit_analysis['exploit_factors'].append(f"High data quality ({data_sources_count} sources)")
            elif data_sources_count >= 3:
                exploit_analysis['confidence'] += 0.10  # Good data coverage
        
        # ENHANCED TREND DATA: Improved trend impact and added cold streak penalties per baseball-stats-expert recommendations
        if normalized_batter in self.batter_trends:
            trend = self.batter_trends[normalized_batter]
            if trend['trend'] == 'hot':
                exploit_analysis['exploit_score'] += 25  # ENHANCED: Increased from 15 to 25 for hot streaks
                exploit_analysis['exploit_factors'].append(f"Hot streak ({trend['recent_avg']:.3f} last 5 games)")
                
                # Extra boost if pitcher is struggling
                if pitcher_vulnerabilities.get('trend_analysis', {}).get('trend') == 'deteriorating':
                    exploit_analysis['exploit_score'] += 15  # ENHANCED: Increased from 10 to 15
                    exploit_analysis['situational_advantages'].append("Hot hitter vs struggling pitcher")
            elif trend['trend'] == 'cold':
                # ENHANCED: Added cold streak penalties as recommended
                exploit_analysis['exploit_score'] -= 12  # NEW: Cold streak penalty
                exploit_analysis['exploit_factors'].append(f"Cold streak ({trend['recent_avg']:.3f} last 5 games)")
                exploit_analysis['confidence'] -= 0.1  # Additional confidence penalty for cold streaks
        
        # 3. Platoon Advantage Analysis
        if not custom_data:
            custom_data = self.find_batter_data(batter_name)
        if custom_data:
            batter_hand = self.get_batter_handedness(batter_name)
            pitcher_hand = pitcher_vulnerabilities.get('situational_factors', {}).get('pitch_hand', 'R')
            
            # RESTORED: Traditional platoon advantage with meaningful impact
            if (batter_hand == 'L' and pitcher_hand == 'R') or (batter_hand == 'R' and pitcher_hand == 'L'):
                exploit_analysis['exploit_score'] += 12  # RESTORED meaningful impact
                exploit_analysis['matchup_intelligence']['platoon_advantage'] = True
                exploit_analysis['situational_advantages'].append(f"{batter_hand}HB vs {pitcher_hand}HP advantage")
        
        # FIXED: Park Factor Adjustment - Use additive bonuses instead of multipliers
        normalized_venue = self.normalize_venue_name(venue)
        park_adjustment = 1.0
        if normalized_venue and normalized_venue in self.park_factors:
            park_data = self.park_factors[normalized_venue]
            hr_factor = park_data['hr_factor']
            park_adjustment = hr_factor
            
            # Apply additive park bonuses instead of destructive multipliers
            if hr_factor > 1.15:  # Very hitter-friendly
                exploit_analysis['exploit_score'] += 15
                exploit_analysis['situational_advantages'].append(f"Very hitter-friendly park ({park_data['category']})")
            elif hr_factor > 1.05:  # Hitter-friendly
                exploit_analysis['exploit_score'] += 8
                exploit_analysis['situational_advantages'].append(f"Hitter-friendly park ({park_data['category']})")
            elif hr_factor < 0.85:  # Very pitcher-friendly
                exploit_analysis['exploit_score'] -= 8
                exploit_analysis['situational_advantages'].append(f"Pitcher-friendly park (challenging)")
            elif hr_factor < 0.95:  # Pitcher-friendly
                exploit_analysis['exploit_score'] -= 3
        
        # Store the factor for display but don't use as destructive multiplier
        exploit_analysis['park_adjustment'] = park_adjustment
        
        # FIXED: Weather Context Integration - Use additive bonuses instead of multipliers
        weather_factor = 1.0
        if normalized_venue and normalized_venue in self.weather_context:
            weather_data = self.weather_context[normalized_venue]
            weather_factor = weather_data['weather_factor']
            
            # Apply additive weather adjustments instead of destructive multipliers
            if weather_factor > 1.10:  # Very favorable weather
                exploit_analysis['exploit_score'] += 10
                exploit_analysis['situational_advantages'].append("Very favorable weather conditions")
            elif weather_factor > 1.05:  # Favorable weather
                exploit_analysis['exploit_score'] += 5
                if weather_data.get('temperature', 0) >= 85:
                    exploit_analysis['situational_advantages'].append("Hot weather favoring ball carry")
                if weather_data.get('wind_speed', 0) >= 8 and weather_data.get('wind_direction', '') in ['out', 'outfield', 'favorable']:
                    exploit_analysis['situational_advantages'].append(f"Favorable wind ({weather_data.get('wind_speed', 0)} mph)")
            elif weather_factor < 0.90:  # Very unfavorable weather
                exploit_analysis['exploit_score'] -= 8
                exploit_analysis['situational_advantages'].append("Challenging weather conditions")
            elif weather_factor < 0.95:  # Unfavorable weather
                exploit_analysis['exploit_score'] -= 3
                if weather_data['temperature'] <= 50:
                    exploit_analysis['situational_advantages'].append("Cold weather reducing ball carry")
                if weather_data['wind_speed'] >= 8 and weather_data['wind_direction'] in ['in', 'infield', 'against']:
                    exploit_analysis['situational_advantages'].append(f"Unfavorable wind ({weather_data['wind_speed']} mph)")
        
        # NEW: Recent Form and Momentum Integration (Phase 5)  
        if normalized_batter in self.recent_form_data:
            form_data = self.recent_form_data[normalized_batter]
            
            # Hot streak bonus
            if form_data.get('hot_streak', False) or form_data.get('last_7_avg', 0) > 0.320:
                hot_streak_bonus = min(15, (form_data.get('last_7_avg', 0) - 0.250) * 60)
                exploit_analysis['exploit_score'] += hot_streak_bonus
                exploit_analysis['situational_advantages'].append(f"Hot streak ({form_data.get('last_7_avg', 0):.3f} last 7 games)")
                
            # Recent HR power surge
            if form_data.get('last_7_hr', 0) >= 3:
                power_surge_bonus = form_data.get('last_7_hr', 0) * 3
                exploit_analysis['exploit_score'] += power_surge_bonus
                exploit_analysis['situational_advantages'].append(f"Power surge ({form_data.get('last_7_hr', 0)} HR in last 7)")
                
            # Momentum trending
            if form_data.get('trend_direction') == 'improving':
                exploit_analysis['exploit_score'] += 8
                exploit_analysis['situational_advantages'].append("Improving recent form")
            elif form_data.get('trend_direction') == 'declining':
                exploit_analysis['exploit_score'] -= 5
                
            # Cold streak penalty
            if form_data.get('cold_streak', False):
                exploit_analysis['exploit_score'] -= 10
        
        # NEW: Lineup Position and Protection Analysis (Phase 6)
        lineup_bonus = 0
        if normalized_batter in self.lineup_data:
            lineup_info = self.lineup_data[normalized_batter]
            
            # RBI opportunity bonus for middle-order batters
            rbi_factor = lineup_info.get('rbi_opportunities', 1.0)
            if rbi_factor > 1.1:  # Cleanup/3-4-5 hitters
                lineup_bonus += (rbi_factor - 1.0) * 25  # Up to 6.25 bonus for cleanup
                exploit_analysis['situational_advantages'].append(f"Prime RBI spot (#{lineup_info.get('position', 0)} in order)")
                
            # Run scoring bonus for top-of-order batters
            run_factor = lineup_info.get('run_scoring_opportunities', 1.0)
            if run_factor > 1.1:  # Leadoff/2-hole
                lineup_bonus += (run_factor - 1.0) * 20  # Up to 5 bonus for leadoff
                exploit_analysis['situational_advantages'].append(f"Table setter (#{lineup_info.get('position', 0)} in order)")
                
            # Protection quality bonus
            protection = lineup_info.get('protection_quality', 0.5)
            if protection > 0.7:
                lineup_bonus += protection * 8  # Up to ~8 bonus for good protection
                exploit_analysis['situational_advantages'].append("Strong lineup protection")
            elif protection < 0.3:
                lineup_bonus -= 3  # Penalty for poor protection
                
            # Heart of order context
            lineup_context = lineup_info.get('lineup_context', [])
            if 'heart_of_order' in lineup_context:
                lineup_bonus += 5
                exploit_analysis['situational_advantages'].append("Heart of the order positioning")
                
            exploit_analysis['exploit_score'] += lineup_bonus
            
        # Store lineup context in analysis  
        exploit_analysis['lineup_context'] = self.lineup_data.get(normalized_batter, {})
        
        # Store weather and form context in analysis
        exploit_analysis['weather_factor'] = weather_factor
        recent_form_context = self.recent_form_data.get(normalized_batter, {}).copy()
        # CRITICAL FIX: Ensure team in recent form context matches current game team
        if recent_form_context and batter_team:
            recent_form_context['team'] = batter_team
        
        # NEW: Integrate comprehensive venue analytics into recent form context
        venue_analytics = self.generate_comprehensive_venue_analytics(venue, batter_team, pitcher_name, venue_home_team)
        if venue_analytics:
            recent_form_context.update(venue_analytics)
        
        # ENHANCED: Apply Home Field Advantage Impact for Away Team Players
        # This addresses the critical issue where away team players weren't properly penalized
        if recent_form_context and 'venue_context' in recent_form_context:
            venue_context = recent_form_context['venue_context']
            home_field_impact = venue_context.get('home_field_impact', {})
            
            # Handle both penalties and bonuses
            if home_field_impact.get('away_team_penalty', False):
                penalty_factor = home_field_impact.get('penalty_factor', 0.95)
                penalty_percentage = home_field_impact.get('penalty_percentage', 5)
                
                # Apply penalty to away team players
                exploit_analysis['exploit_score'] -= penalty_percentage
                exploit_analysis['situational_advantages'].append(
                    f"Away team penalty: -{penalty_percentage}% ({home_field_impact.get('reasoning', 'Home field disadvantage')})"
                )
                
                print(f"   ðŸŸï¸ Applied away team penalty: -{penalty_percentage}% for {batter_name}")
                
            elif home_field_impact.get('bonus_percentage'):
                bonus_percentage = home_field_impact.get('bonus_percentage', 0)
                
                # Apply bonus for away team at away-friendly venues
                exploit_analysis['exploit_score'] += bonus_percentage
                exploit_analysis['situational_advantages'].append(
                    f"Away team bonus: +{bonus_percentage}% ({home_field_impact.get('reasoning', 'Away team advantage')})"
                )
                
                print(f"   ðŸŸï¸ Applied away team bonus: +{bonus_percentage}% for {batter_name}")
        
        exploit_analysis['recent_form_context'] = recent_form_context
        
        # 5. Exploitation Window Matching
        if pitcher_vulnerabilities.get('vulnerabilities'):
            windows = pitcher_vulnerabilities['vulnerabilities'][0].get('exploitation_windows', [])
            
            # Match batter strengths to pitcher weaknesses
            if "First pitch fastball" in str(windows):
                # Check first pitch aggression using enhanced lookup
                if not custom_data:
                    custom_data = self.find_batter_data(batter_name)
                if custom_data:
                    z_swing = custom_data.get('z_swing_percent', 0)
                    if z_swing > 35:  # Aggressive in zone
                        exploit_analysis['exploit_score'] += 12
                        # Generate enhanced arsenal-specific justification
                        enhanced_justification = self.generate_enhanced_arsenal_justification(batter_name, pitcher_name, exploit_analysis)
                        exploit_analysis['situational_advantages'].append(enhanced_justification)
        
        # NEW: Add League Position Context from Pitcher Rankings
        normalized_pitcher = self.normalize_name(pitcher_name)
        
        # Add hits vulnerability ranking context
        if normalized_pitcher in self.pitcher_hits_rankings:
            hits_rank = self.pitcher_hits_rankings[normalized_pitcher].get('league_rank_hits', 999)
            if hits_rank <= 10:
                exploit_analysis['situational_advantages'].append(f"Pitcher ranks #{hits_rank} worst in hits allowed")
                exploit_analysis['league_context'] = {'hits_rank': hits_rank, 'hits_category': 'elite_vulnerable'}
            elif hits_rank <= 25:
                exploit_analysis['situational_advantages'].append(f"Pitcher ranks #{hits_rank} in hits allowed")
                exploit_analysis['league_context'] = {'hits_rank': hits_rank, 'hits_category': 'high_vulnerable'}
        
        # Add HR vulnerability ranking context
        if normalized_pitcher in self.pitcher_hrs_rankings:
            hrs_rank = self.pitcher_hrs_rankings[normalized_pitcher].get('league_rank_hrs', 999)
            if hrs_rank <= 10:
                exploit_analysis['situational_advantages'].append(f"Pitcher ranks #{hrs_rank} worst in HRs allowed")
                if 'league_context' not in exploit_analysis:
                    exploit_analysis['league_context'] = {}
                exploit_analysis['league_context']['hrs_rank'] = hrs_rank
                exploit_analysis['league_context']['hrs_category'] = 'elite_vulnerable'
            elif hrs_rank <= 25:
                exploit_analysis['situational_advantages'].append(f"Pitcher ranks #{hrs_rank} in HRs allowed")
                if 'league_context' not in exploit_analysis:
                    exploit_analysis['league_context'] = {}
                exploit_analysis['league_context']['hrs_rank'] = hrs_rank
                exploit_analysis['league_context']['hrs_category'] = 'high_vulnerable'
        
        # Add compound ranking context for extra insight
        if (normalized_pitcher in self.pitcher_hits_rankings and 
            normalized_pitcher in self.pitcher_hrs_rankings):
            hits_rank = self.pitcher_hits_rankings[normalized_pitcher].get('league_rank_hits', 999)
            hrs_rank = self.pitcher_hrs_rankings[normalized_pitcher].get('league_rank_hrs', 999)
            
            if hits_rank <= 15 and hrs_rank <= 15:
                exploit_analysis['situational_advantages'].append("Pitcher vulnerable in both hits & HRs (double threat)")
                if 'league_context' not in exploit_analysis:
                    exploit_analysis['league_context'] = {}
                exploit_analysis['league_context']['compound_vulnerability'] = True
        
        # GENERATE MEANINGFUL EXPLOIT FACTORS from multiplier analysis
        exploit_factors = []
        
        # Batter quality factors
        if batter_quality_multiplier > 1.15:
            if barrel_percent >= 12:
                exploit_factors.append(f"Elite barrel rate ({barrel_percent:.1f}%)")
            if bb_percent > 12 and k_percent < 18:
                exploit_factors.append(f"Elite plate discipline ({bb_percent:.1f}% BB, {k_percent:.1f}% K)")
            if sprint_speed > 29:
                exploit_factors.append(f"Elite speed ({sprint_speed:.1f} ft/sec)")
            if xba_diff < -0.040 or xslg_diff < -0.060:
                exploit_factors.append(f"Major regression opportunity (underperforming expected stats)")
        elif batter_quality_multiplier > 1.05:
            if barrel_percent >= 9:
                exploit_factors.append(f"Strong barrel rate ({barrel_percent:.1f}%)")
            if bb_percent > 9:
                exploit_factors.append(f"Good plate discipline ({bb_percent:.1f}% BB)")
            if sprint_speed > 27:
                exploit_factors.append(f"Strong speed ({sprint_speed:.1f} ft/sec)")
        elif batter_quality_multiplier < 0.95:
            exploit_factors.append("Below-average batter profile")
            
        # Pitcher vulnerability factors
        if pitcher_vulnerability_multiplier > 1.08:
            if pitcher_era > 5.0:
                exploit_factors.append(f"Vulnerable pitcher (ERA: {pitcher_era:.2f})")
            if hr_rate > 1.3:
                exploit_factors.append(f"HR vulnerable ({hr_rate:.1f} HR/game)")
        elif pitcher_vulnerability_multiplier < 0.92:
            exploit_factors.append("Strong pitcher profile")
            
        exploit_analysis['exploit_factors'] = exploit_factors
        
        # ENHANCED CLASSIFICATION: Preserve contact hitter classifications while adjusting thresholds
        score = exploit_analysis['exploit_score']
        current_classification = exploit_analysis.get('batter_classification', 'unknown')
        
        # Preserve contact/walk/speed specific classifications - don't override them with generic opportunity levels
        if current_classification in ['elite_contact', 'strong_contact', 'contact_hitter', 
                                    'elite_walk_specialist', 'strong_walk_specialist', 'walk_specialist',
                                    'elite_speed_threat', 'strong_speed_threat', 'speed_threat']:
            # Keep the specific classification - it's more valuable than generic opportunity levels
            pass
        else:
            # Apply generic opportunity classification for players without specific skills
            if score >= 85:  # ENHANCED: Increased from 65 for more selective elite classification
                exploit_analysis['batter_classification'] = 'elite_opportunity'
            elif score >= 75:  # ENHANCED: Increased from 58 for strong opportunities
                exploit_analysis['batter_classification'] = 'strong_opportunity'  
            elif score >= 65:  # ENHANCED: Increased from 52 for good opportunities
                exploit_analysis['batter_classification'] = 'good_opportunity'
            elif score >= 55:  # ENHANCED: Increased from 47 for moderate opportunities
                exploit_analysis['batter_classification'] = 'moderate_opportunity'
            elif score >= 45:  # ENHANCED: Increased from 42 for weak opportunities
                exploit_analysis['batter_classification'] = 'weak_opportunity'
            else:
                exploit_analysis['batter_classification'] = 'marginal_opportunity'
        
        # Add comprehensive analytics metadata with enhanced arsenal analysis
        exploit_analysis['expected_stats_gap'] = self.calculate_expected_stats_gap(normalized_batter)
        exploit_analysis['barrel_matchup'] = self.calculate_barrel_matchup(normalized_batter, normalized_pitcher)
        exploit_analysis['arsenal_vulnerability'] = self.calculate_arsenal_vulnerability(normalized_pitcher)
        
        # NEW: Enhanced arsenal exploitation matchup analysis
        arsenal_matchup = self.analyze_arsenal_exploitation_matchup(batter_name, pitcher_name)
        exploit_analysis['arsenal_exploitation'] = arsenal_matchup
        
        # Boost exploit score based on arsenal matchup strength
        if arsenal_matchup['exploitation_score'] > 20:
            exploit_analysis['exploit_score'] += 8
            exploit_analysis['exploit_factors'].append(f"Strong arsenal matchup ({arsenal_matchup['exploitation_score']} pts)")
        elif arsenal_matchup['exploitation_score'] > 10:
            exploit_analysis['exploit_score'] += 5
            exploit_analysis['exploit_factors'].append(f"Good arsenal matchup ({arsenal_matchup['exploitation_score']} pts)")
            
        # Add specific pitch type advantages to situational advantages
        if arsenal_matchup['pitch_type_advantages']:
            for advantage in arsenal_matchup['pitch_type_advantages'][:2]:  # Top 2 advantages
                exploit_analysis['situational_advantages'].append(f"Arsenal: {advantage}")
        
        exploit_analysis['data_quality'] = self.assess_overall_data_quality(normalized_batter, normalized_pitcher)
        
        # PHASE 1 ENHANCEMENT: Add comprehensive enhanced analysis results
        exploit_analysis['handedness_analysis'] = handedness_analysis
        exploit_analysis['swing_optimization'] = swing_optimization  
        exploit_analysis['multi_year_regression'] = regression_analysis
        
        # PHASE 1 ENHANCEMENT: Enhanced data quality scoring
        enhanced_data_quality = self.calculate_enhanced_data_quality_score(batter_name, pitcher_name)
        exploit_analysis['enhanced_data_quality'] = enhanced_data_quality
        
        # Apply data quality confidence multiplier
        exploit_analysis['confidence'] *= enhanced_data_quality['confidence_multiplier']
        
        # Update data quality string based on enhanced scoring
        exploit_analysis['data_quality'] = enhanced_data_quality['quality_level']
        
        # Add enhanced factors to exploit factors
        if handedness_analysis['key_advantages']:
            exploit_analysis['exploit_factors'].extend([f"Handedness: {adv}" for adv in handedness_analysis['key_advantages'][:2]])
        if swing_optimization['key_optimizations']:
            exploit_analysis['exploit_factors'].extend([f"Swing: {opt}" for opt in swing_optimization['key_optimizations'][:2]])
        if regression_analysis['regression_indicators']:
            exploit_analysis['exploit_factors'].extend([f"Regression: {ind}" for ind in regression_analysis['regression_indicators'][:1]])
        
        # Critical fix: Penalize confidence and score for TBD pitchers
        if pitcher_name.upper() in ['TBD', 'TO BE DECIDED', 'UNKNOWN']:
            exploit_analysis['exploit_score'] = max(30, exploit_analysis['exploit_score'] * 0.6)  # 40% penalty
            exploit_analysis['confidence'] = max(0.2, exploit_analysis['confidence'] * 0.4)  # Major confidence penalty
            exploit_analysis['exploit_factors'].append("Unknown pitcher reduces confidence")
        
        # Enhanced confidence adjustment based on comprehensive analysis
        base_data_points = len(exploit_analysis['exploit_factors']) + len(exploit_analysis['situational_advantages'])
        enhanced_data_bonus = enhanced_data_quality['overall_score'] / 1000  # 0-0.1 bonus based on data completeness
        exploit_analysis['confidence'] = min(0.95, exploit_analysis['confidence'] + (base_data_points * 0.03) + enhanced_data_bonus)
        
        return exploit_analysis
    
    def calculate_expected_stats_gap(self, batter_name):
        """Calculate expected statistics gap for regression opportunities"""
        batter_data = self.find_batter_data(batter_name)
        if not batter_data:
            return None
        gaps = {}
        
        if batter_data.get('xba_diff', 0) != 0:
            gaps['xba_gap'] = batter_data['xba_diff']
        if batter_data.get('xslg_diff', 0) != 0:
            gaps['xslg_gap'] = batter_data['xslg_diff']
        if batter_data.get('woba_diff', 0) != 0:
            gaps['woba_gap'] = batter_data['woba_diff']
        
        return gaps if gaps else None
    
    def calculate_barrel_matchup(self, batter_name, pitcher_name):
        """Calculate barrel rate matchup advantage"""
        hitter_barrel = 0
        pitcher_barrel_allowed = 0
        
        if batter_name in self.hitter_exit_velocity:
            hitter_barrel = self.hitter_exit_velocity[batter_name]['real_barrel_rate']
        
        if pitcher_name in self.pitcher_exit_velocity:
            pitcher_barrel_allowed = self.pitcher_exit_velocity[pitcher_name]['real_barrel_rate_allowed']
        
        if hitter_barrel > 0 and pitcher_barrel_allowed > 0:
            advantage = (hitter_barrel * pitcher_barrel_allowed) / 100  # Compound advantage
            return {
                'hitter_rate': hitter_barrel,
                'pitcher_allowed': pitcher_barrel_allowed,
                'compound_advantage': advantage
            }
        
        return None
    
    def calculate_arsenal_vulnerability(self, pitcher_name):
        """Calculate pitcher arsenal vulnerability summary"""
        if pitcher_name not in self.pitcher_arsenal:
            return None
        
        arsenal = self.pitcher_arsenal[pitcher_name]['pitch_types']
        vulnerabilities = []
        
        for pitch_type, pitch_data in arsenal.items():
            if pitch_data.get('ba_against', 0) > 0.270 and pitch_data.get('usage', 0) > 10:
                vulnerabilities.append({
                    'pitch': pitch_data['pitch_name'],
                    'ba_against': pitch_data['ba_against'],
                    'usage': pitch_data['usage']
                })
        
        return vulnerabilities if vulnerabilities else None
    
    def assess_overall_data_quality(self, batter_name, pitcher_name):
        """Assess overall data quality for the matchup"""
        sources_available = 0
        
        if batter_name in self.custom_batters:
            sources_available += 1
        if batter_name in self.hitter_exit_velocity:
            sources_available += 1
        if batter_name in self.handedness_data:
            sources_available += 1
        if pitcher_name in self.custom_pitchers:
            sources_available += 1
        if pitcher_name in self.pitcher_exit_velocity:
            sources_available += 1
        if pitcher_name in self.pitcher_arsenal:
            sources_available += 1
        
        if sources_available >= 5:
            return 'excellent'
        elif sources_available >= 4:
            return 'good'
        elif sources_available >= 2:
            return 'fair'
        else:
            return 'limited'
    
    def generate_enhanced_weakspot_exploiters(self, date):
        """Generate comprehensive weakspot exploiters using all CSV data"""
        print(f"ðŸŽ¯ Generating comprehensive weakspot exploiters for {date}...")
        
        # Load starting lineups
        lineups_data = self.load_starting_lineups(date)
        
        if not lineups_data or 'games' not in lineups_data:
            print(f"âŒ No starting lineups found for {date}")
            print("ðŸ”„ Attempting fallback analysis with available data...")
            # Fallback: Use recent data to generate some exploiters
            return self.generate_fallback_exploiters(date)
        
        exploiters = []
        games_analyzed = 0
        
        # Comprehensive analysis using all 1,885+ data points  
        for game in lineups_data['games']:  # Analyze ALL games for complete coverage
            home_team = game['teams']['home']['abbr']
            away_team = game['teams']['away']['abbr']
            home_pitcher = game['pitchers']['home']['name']
            away_pitcher = game['pitchers']['away']['name']
            venue = game['venue']['name']
            
            print(f"ðŸŸï¸ Comprehensive analysis: {away_team}@{home_team} at {venue}")
            
            # Enhanced pitcher vulnerability analysis
            away_hitters = self.get_team_hitters(away_team, date)
            home_pitcher_analysis = self.analyze_enhanced_pitcher_vulnerabilities(home_pitcher)
            
            print(f"   ðŸŽ¯ {home_pitcher}: Vulnerability Score {home_pitcher_analysis.get('vulnerabilityScore', 50)}/100")
            
            # Generate multiple exploiters per matchup using sophisticated algorithms
            for hitter in away_hitters:
                try:
                    exploit_analysis = self.analyze_enhanced_batter_exploit_potential(
                        hitter['name'], 
                        home_pitcher, 
                        home_pitcher_analysis,
                        venue,
                        away_team,
                        home_team  # Pass home team to determine if batter is away
                    )
                    
                    # Multi-tier scoring with dynamic thresholds
                    combined_score = exploit_analysis['exploit_score'] * exploit_analysis['confidence']
                    
                    # EXTREMELY INCLUSIVE APPROACH: Generate opportunities across ALL games
                    base_threshold = 1.0  # Very low base threshold
                    confidence_threshold = 0.08  # Very forgiving confidence threshold
                    
                    # AGGRESSIVE threshold reductions to ensure comprehensive coverage
                    if exploit_analysis.get('exploit_factors'):  # Has ANY factors
                        base_threshold -= 0.5  # Small reductions, not large jumps
                    if exploit_analysis.get('situational_advantages'):
                        base_threshold -= 0.5
                    if exploit_analysis.get('regression_opportunity'):
                        base_threshold -= 1.0  # Regression opportunities are valuable
                    if exploit_analysis.get('contact_quality_edge'):
                        base_threshold -= 0.5
                    if home_pitcher_analysis.get('vulnerabilityScore', 50) >= 45:  # Much lower bar
                        base_threshold -= 0.5
                    if exploit_analysis.get('data_quality') in ['excellent', 'good', 'fair', 'limited']:  # Include all data
                        base_threshold -= 0.5
                    if exploit_analysis.get('batter_classification') not in ['unknown']:
                        base_threshold -= 0.5  # Reward any classification
                    
                    # Minimum threshold of 0.1 to ensure we get opportunities from all games
                    final_threshold = max(0.1, base_threshold)
                    
                    # DEBUG: Log threshold decisions
                    print(f"      ðŸ” {hitter['name']}: Score={exploit_analysis['exploit_score']:.1f}, Confidence={exploit_analysis['confidence']:.3f}, Combined={combined_score:.1f}, Threshold={final_threshold}")
                    
                    if combined_score >= final_threshold and exploit_analysis['confidence'] >= confidence_threshold:
                        # Generate comprehensive justification combining all data sources
                        comprehensive_justification = self.generate_comprehensive_justification(
                            hitter['name'], home_pitcher, home_pitcher_analysis, exploit_analysis
                        )
                        
                        # Build modernAnalytics structure first
                        modern_analytics = {
                            'expectedStatsGap': exploit_analysis.get('expected_stats_gap'),
                            'barrelMatchup': exploit_analysis.get('barrel_matchup'),
                            'arsenalVulnerability': exploit_analysis.get('arsenal_vulnerability'),
                            'arsenalExploitation': exploit_analysis.get('arsenal_exploitation')  # NEW: Enhanced analysis
                        }
                        
                        # Generate detailed exploit factors from all available data
                        detailed_exploit_factors = self.generate_detailed_exploit_factors(
                            hitter['name'], home_pitcher, home_pitcher_analysis, modern_analytics
                        )
                        
                        exploiter = {
                            'player': hitter['name'],
                            'team': away_team,
                            'pitcher': home_pitcher,
                            'opposingTeam': home_team,
                            'venue': venue,
                            'exploitIndex': round(exploit_analysis['exploit_score'], 1),
                            'confidence': round(exploit_analysis['confidence'], 3),
                            'combinedScore': round(combined_score, 1),
                            'batterClassification': exploit_analysis['batter_classification'],
                            'keyWeakness': self.extract_key_weakness(home_pitcher_analysis, exploit_analysis),
                            'comprehensiveJustification': comprehensive_justification,  # NEW: Enhanced justification
                            'exploitFactors': detailed_exploit_factors,  # NEW: Enhanced multi-factor analysis
                            'situationalAdvantages': exploit_analysis['situational_advantages'][:3],
                            'regressionOpportunity': exploit_analysis.get('regression_opportunity'),
                            'contactQualityEdge': exploit_analysis.get('contact_quality_edge'),
                            'arsenalExploitation': exploit_analysis.get('arsenal_exploitation', {}),  # NEW: Arsenal exploitation analysis
                            'handednessAnalysis': exploit_analysis.get('handedness_analysis'),
                            'parkAdjustment': exploit_analysis.get('park_adjustment', 1.0),
                            'weatherFactor': exploit_analysis.get('weather_factor', 1.0),
                            'recentFormContext': exploit_analysis.get('recent_form_context', {}),
                            'lineupContext': exploit_analysis.get('lineup_context', {}),
                            'modernAnalytics': modern_analytics,
                            'dataQuality': exploit_analysis.get('data_quality', 'good'),
                            'analysisTimestamp': datetime.now().isoformat()
                        }
                        
                        exploiters.append(exploiter)
                        print(f"      âœ… {hitter['name']}: Score={exploit_analysis['exploit_score']:.1f}, Combined={combined_score:.1f}")
                        
                        # Show detailed advantages for top opportunities
                        if combined_score >= 50:
                            advantages = exploit_analysis.get('situational_advantages', [])
                            if advantages:
                                print(f"         ðŸŽ¯ Key Advantages: {', '.join(advantages[:2])}")
                            if exploit_analysis.get('regression_opportunity'):
                                print(f"         ðŸ“ˆ Regression Boost: {exploit_analysis['regression_opportunity']['type']}")
                
                except Exception as e:
                    print(f"      âŒ Error analyzing {hitter['name']}: {e}")
                    continue
            
            # Analyze home hitters vs away pitcher
            home_hitters = self.get_team_hitters(home_team, date)
            away_pitcher_analysis = self.analyze_enhanced_pitcher_vulnerabilities(away_pitcher)
            
            print(f"   ðŸŽ¯ {away_pitcher}: Vulnerability Score {away_pitcher_analysis.get('vulnerabilityScore', 50)}/100")
            
            for hitter in home_hitters:
                try:
                    exploit_analysis = self.analyze_enhanced_batter_exploit_potential(
                        hitter['name'], 
                        away_pitcher, 
                        away_pitcher_analysis,
                        venue,
                        home_team,
                        home_team  # Pass home team - these are home team hitters
                    )
                    
                    combined_score = exploit_analysis['exploit_score'] * exploit_analysis['confidence']
                    
                    # SAME EXTREMELY INCLUSIVE APPROACH for away team
                    base_threshold = 1.0  # Very low base threshold  
                    confidence_threshold = 0.08  # Very forgiving confidence threshold
                    
                    # AGGRESSIVE threshold reductions to ensure comprehensive coverage
                    if exploit_analysis.get('exploit_factors'):  # Has ANY factors
                        base_threshold -= 0.5  # Small reductions, not large jumps
                    if exploit_analysis.get('situational_advantages'):
                        base_threshold -= 0.5
                    if exploit_analysis.get('regression_opportunity'):
                        base_threshold -= 1.0  # Regression opportunities are valuable
                    if exploit_analysis.get('contact_quality_edge'):
                        base_threshold -= 0.5
                    if away_pitcher_analysis.get('vulnerabilityScore', 50) >= 45:  # Much lower bar
                        base_threshold -= 0.5
                    if exploit_analysis.get('data_quality') in ['excellent', 'good', 'fair', 'limited']:  # Include all data
                        base_threshold -= 0.5
                    if exploit_analysis.get('batter_classification') not in ['unknown']:
                        base_threshold -= 0.5  # Reward any classification
                    
                    # Minimum threshold of 0.1 to ensure we get opportunities from all games
                    final_threshold = max(0.1, base_threshold)
                    
                    # DEBUG: Log threshold decisions
                    print(f"      ðŸ” {hitter['name']}: Score={exploit_analysis['exploit_score']:.1f}, Confidence={exploit_analysis['confidence']:.3f}, Combined={combined_score:.1f}, Threshold={final_threshold}")
                    
                    if combined_score >= final_threshold and exploit_analysis['confidence'] >= confidence_threshold:
                        # Generate comprehensive justification combining all data sources
                        comprehensive_justification = self.generate_comprehensive_justification(
                            hitter['name'], away_pitcher, away_pitcher_analysis, exploit_analysis
                        )
                        
                        # Build modernAnalytics structure first
                        modern_analytics = {
                            'expectedStatsGap': exploit_analysis.get('expected_stats_gap'),
                            'barrelMatchup': exploit_analysis.get('barrel_matchup'),
                            'arsenalVulnerability': exploit_analysis.get('arsenal_vulnerability'),
                            'arsenalExploitation': exploit_analysis.get('arsenal_exploitation')  # NEW: Enhanced analysis
                        }
                        
                        # Generate detailed exploit factors from all available data
                        detailed_exploit_factors = self.generate_detailed_exploit_factors(
                            hitter['name'], away_pitcher, away_pitcher_analysis, modern_analytics
                        )
                        
                        exploiter = {
                            'player': hitter['name'],
                            'team': home_team,
                            'pitcher': away_pitcher,
                            'opposingTeam': away_team,
                            'venue': venue,
                            'exploitIndex': round(exploit_analysis['exploit_score'], 1),
                            'confidence': round(exploit_analysis['confidence'], 3),
                            'combinedScore': round(combined_score, 1),
                            'batterClassification': exploit_analysis['batter_classification'],
                            'keyWeakness': self.extract_key_weakness(away_pitcher_analysis, exploit_analysis),
                            'comprehensiveJustification': comprehensive_justification,  # NEW: Enhanced justification
                            'exploitFactors': detailed_exploit_factors,  # NEW: Enhanced multi-factor analysis
                            'situationalAdvantages': exploit_analysis['situational_advantages'][:3],
                            'regressionOpportunity': exploit_analysis.get('regression_opportunity'),
                            'contactQualityEdge': exploit_analysis.get('contact_quality_edge'),
                            'arsenalExploitation': exploit_analysis.get('arsenal_exploitation', {}),  # NEW: Arsenal exploitation analysis
                            'handednessAnalysis': exploit_analysis.get('handedness_analysis'),
                            'parkAdjustment': exploit_analysis.get('park_adjustment', 1.0),
                            'weatherFactor': exploit_analysis.get('weather_factor', 1.0),
                            'recentFormContext': exploit_analysis.get('recent_form_context', {}),
                            'lineupContext': exploit_analysis.get('lineup_context', {}),
                            'modernAnalytics': modern_analytics,
                            'dataQuality': exploit_analysis.get('data_quality', 'good'),
                            'analysisTimestamp': datetime.now().isoformat()
                        }
                        
                        exploiters.append(exploiter)
                        print(f"      âœ… {hitter['name']}: Score={exploit_analysis['exploit_score']:.1f}, Combined={combined_score:.1f}")
                        
                        if combined_score >= 50:
                            advantages = exploit_analysis.get('situational_advantages', [])
                            if advantages:
                                print(f"         ðŸŽ¯ Key Advantages: {', '.join(advantages[:2])}")
                            if exploit_analysis.get('regression_opportunity'):
                                print(f"         ðŸ“ˆ Regression Boost: {exploit_analysis['regression_opportunity']['type']}")
                
                except Exception as e:
                    print(f"      âŒ Error analyzing {hitter['name']}: {e}")
                    continue
            
            games_analyzed += 1
        
        # Advanced multi-tier ranking system
        exploiters.sort(key=lambda x: (
            x['combinedScore'],
            len(x.get('situationalAdvantages', [])),
            1 if x.get('regressionOpportunity') else 0,
            1 if x.get('contactQualityEdge') else 0
        ), reverse=True)
        
        print(f"ðŸŽ¯ Comprehensive analysis complete: {len(exploiters)} sophisticated exploiters from {games_analyzed} games")
        print(f"ðŸ“Š Analysis utilized {len(self.hitter_exit_velocity) + len(self.pitcher_exit_velocity) + len(self.custom_batters) + len(self.custom_pitchers)} total data points")
        
        if exploiters:
            print(f"\nðŸ† TOP 5 COMPREHENSIVE EXPLOITERS:")
            for i, exploiter in enumerate(exploiters[:5], 1):
                print(f"  {i}. {exploiter['player']} vs {exploiter['pitcher']}")
                print(f"     ðŸ“Š Combined Score: {exploiter['combinedScore']:.1f} (Index: {exploiter['exploitIndex']}, Confidence: {exploiter['confidence']})")
                print(f"     ðŸŽ¯ Classification: {exploiter['batterClassification']}")
                if exploiter.get('situationalAdvantages'):
                    print(f"     ðŸ” Advantages: {', '.join(exploiter['situationalAdvantages'][:2])}")
                if exploiter.get('regressionOpportunity'):
                    print(f"     ðŸ“ˆ Regression: {exploiter['regressionOpportunity']['type']}")
                print()
        
        return exploiters
    
    def generate_fallback_exploiters(self, date):
        """Generate exploiters using available data when lineups are missing"""
        print("ðŸ”„ Generating fallback exploiters using available player data...")
        
        exploiters = []
        
        # Use top players from available data
        top_hitters = []
        
        # Get hitters from exit velocity data (elite power candidates)
        for name, data in self.hitter_exit_velocity.items():
            barrel_rate = data.get('real_barrel_rate', 0)
            if barrel_rate >= 8:  # Above average barrel rate
                top_hitters.append({
                    'name': name,
                    'team': 'TBD',  # Team to be determined
                    'barrel_rate': barrel_rate,
                    'source': 'exit_velocity'
                })
        
        # Get additional hitters from custom batters data
        for name, data in self.custom_batters.items():
            if name not in [h['name'] for h in top_hitters]:
                xwoba = data.get('xwOBA', 0)
                if xwoba >= 0.340:  # Above average expected weighted on-base average
                    top_hitters.append({
                        'name': name,
                        'team': 'TBD',
                        'xwoba': xwoba,
                        'source': 'custom_batters'
                    })
        
        # Limit to top 50 candidates for fallback
        top_hitters = top_hitters[:50]
        
        # Create fallback pitcher (generic vulnerable pitcher)
        fallback_pitcher_analysis = {
            'vulnerabilityScore': 65,  # Moderately vulnerable
            'vulnerabilities': [{
                'vulnerability_score': 65,
                'factors': ['Fallback analysis - Limited pitcher data'],
                'confidence_level': 'moderate'
            }]
        }
        
        # Analyze each candidate
        for hitter in top_hitters:
            try:
                exploit_analysis = self.analyze_enhanced_batter_exploit_potential(
                    hitter['name'], 
                    'Generic Pitcher',  # Fallback pitcher name
                    fallback_pitcher_analysis,
                    'Generic Stadium',
                    hitter.get('team', 'TBD')
                )
                
                combined_score = exploit_analysis['exploit_score'] * exploit_analysis['confidence']
                
                # More lenient threshold for fallback
                if combined_score >= 8 and exploit_analysis['confidence'] >= 0.1:
                    
                    comprehensive_justification = self.generate_comprehensive_justification(
                        hitter['name'], 'Generic Pitcher', fallback_pitcher_analysis, exploit_analysis
                    )
                    
                    modern_analytics = exploit_analysis.get('modern_analytics', {})
                    
                    exploiter = {
                        'playerName': hitter['name'],
                        'team': hitter.get('team', 'TBD'),
                        'pitcherName': 'Generic Pitcher',
                        'opposingTeam': 'TBD',
                        'venue': 'Generic Stadium',
                        'exploitIndex': round(exploit_analysis['exploit_score'], 1),
                        'confidence': round(exploit_analysis['confidence'], 3),
                        'combinedScore': round(combined_score, 1),
                        'batterClassification': exploit_analysis['batter_classification'],
                        'keyWeakness': 'Fallback analysis',
                        'comprehensiveJustification': comprehensive_justification,
                        'exploitFactors': exploit_analysis.get('exploit_factors', []),
                        'situationalAdvantages': exploit_analysis.get('situational_advantages', []),
                        'regressionOpportunity': exploit_analysis.get('regression_opportunity', {}),
                        'contactQualityEdge': exploit_analysis.get('contact_quality_edge', {}),
                        'arsenalExploitation': exploit_analysis.get('arsenal_exploitation', {}),
                        'parkAdjustment': exploit_analysis.get('park_adjustment', 1.0),
                        'weatherFactor': exploit_analysis.get('weather_factor', 1.0),
                        'recentFormContext': exploit_analysis.get('recent_form_context', {}),
                        'lineupContext': exploit_analysis.get('lineup_context', {}),
                        'modernAnalytics': modern_analytics,
                        'dataQuality': 'fallback',
                        'analysisTimestamp': datetime.now().isoformat()
                    }
                    
                    exploiters.append(exploiter)
                    
                    if len(exploiters) >= 30:  # Cap fallback exploiters
                        break
                        
            except Exception as e:
                continue
        
        print(f"ðŸ”„ Generated {len(exploiters)} fallback exploiters using available data")
        return exploiters
    
    # Include all the base methods from the original class
    def load_hitter_exit_velocity_data(self):
        """Load real hitter exit velocity data with actual barrel rates"""
        file_path = self.stats_path / "hitter_exit_velocity_2025.csv"
        
        if not file_path.exists():
            print("âš ï¸ Hitter exit velocity file not found")
            return
        
        try:
            with open(file_path, 'r', encoding='utf-8-sig') as f:
                reader = csv.DictReader(f)
                count = 0
                
                for row in reader:
                    player_name = self.normalize_name(row['last_name, first_name'])
                    
                    def safe_int(value, default=0):
                        try:
                            return int(value) if value and value.strip() else default
                        except (ValueError, AttributeError):
                            return default
                    
                    def safe_float(value, default=0.0):
                        try:
                            return float(value) if value and value.strip() else default
                        except (ValueError, AttributeError):
                            return default
                    
                    self.hitter_exit_velocity[player_name] = {
                        'attempts': safe_int(row.get('attempts', 0)),
                        'real_barrel_rate': safe_float(row.get('brl_percent', 0)),
                        'barrel_count': safe_int(row.get('barrels', 0)),
                        'barrel_pa': safe_float(row.get('brl_pa', 0)),
                        'avg_hit_speed': safe_float(row.get('avg_hit_speed', 0)),
                        'max_hit_speed': safe_float(row.get('max_hit_speed', 0)),
                        'ev50': safe_float(row.get('ev50', 0)),
                        'ev95_plus': safe_int(row.get('ev95plus', 0)),
                        'ev95_percent': safe_float(row.get('ev95percent', 0)),
                        'sweet_spot_percent': safe_float(row.get('anglesweetspotpercent', 0)),
                        'avg_hit_angle': safe_float(row.get('avg_hit_angle', 0)),
                        'max_distance': safe_int(row.get('max_distance', 0)),
                        'avg_distance': safe_int(row.get('avg_distance', 0)),
                        'avg_hr_distance': safe_int(row.get('avg_hr_distance', 0)),
                        'flyball_linedrive_rate': safe_float(row.get('fbld', 0)),
                        'groundball_rate': safe_float(row.get('gb', 0)),
                        'player_id': row.get('player_id', ''),
                        'data_quality': self.assess_data_quality(safe_int(row.get('attempts', 0)), 'hitter')
                    }
                    count += 1
                
                print(f"   ðŸ“Š Loaded real exit velocity data for {count} hitters")
                
        except Exception as e:
            print(f"âŒ Error loading hitter exit velocity data: {e}")
    
    def load_pitcher_exit_velocity_data(self):
        """Load real pitcher exit velocity data (contact quality allowed)"""
        file_path = self.stats_path / "pitcher_exit_velocity_2025.csv"
        
        if not file_path.exists():
            print("âš ï¸ Pitcher exit velocity file not found")
            return
        
        try:
            with open(file_path, 'r', encoding='utf-8-sig') as f:
                reader = csv.DictReader(f)
                count = 0
                
                for row in reader:
                    player_name = self.normalize_name(row['last_name, first_name'])
                    
                    def safe_int(value, default=0):
                        try:
                            return int(value) if value and value.strip() else default
                        except (ValueError, AttributeError):
                            return default
                    
                    def safe_float(value, default=0.0):
                        try:
                            return float(value) if value and value.strip() else default
                        except (ValueError, AttributeError):
                            return default
                    
                    self.pitcher_exit_velocity[player_name] = {
                        'attempts': safe_int(row.get('attempts', 0)),
                        'real_barrel_rate_allowed': safe_float(row.get('brl_percent', 0)),
                        'barrels_allowed': safe_int(row.get('barrels', 0)),
                        'barrel_pa_allowed': safe_float(row.get('brl_pa', 0)),
                        'avg_hit_speed_allowed': safe_float(row.get('avg_hit_speed', 0)),
                        'max_hit_speed_allowed': safe_float(row.get('max_hit_speed', 0)),
                        'hard_hit_percent_allowed': safe_float(row.get('hard_hit_percent', 0)),
                        'ev50_allowed': safe_float(row.get('ev50', 0)),
                        'ev95_plus_allowed': safe_int(row.get('ev95plus', 0)),
                        'ev95_percent_allowed': safe_float(row.get('ev95percent', 0)),
                        'sweet_spot_percent_allowed': safe_float(row.get('anglesweetspotpercent', 0)),
                        'avg_hit_angle_allowed': safe_float(row.get('avg_hit_angle', 0)),
                        'max_distance_allowed': safe_int(row.get('max_distance', 0)),
                        'avg_distance_allowed': safe_int(row.get('avg_distance', 0)),
                        'avg_hr_distance_allowed': safe_int(row.get('avg_hr_distance', 0)),
                        'flyball_linedrive_rate_allowed': safe_float(row.get('fbld', 0)),
                        'groundball_rate_allowed': safe_float(row.get('gb', 0)),
                        'player_id': row.get('player_id', ''),
                        'data_quality': self.assess_data_quality(safe_int(row.get('attempts', 0)), 'pitcher')
                    }
                    count += 1
                
                print(f"   âš¾ Loaded real exit velocity data for {count} pitchers")
                
        except Exception as e:
            print(f"âŒ Error loading pitcher exit velocity data: {e}")
    
    def load_custom_batter_data(self):
        """Load comprehensive custom batter data with expected statistics"""
        file_path = self.stats_path / "custom_batter_2025.csv"
        
        if not file_path.exists():
            print("âš ï¸ Custom batter file not found")
            return
        
        try:
            with open(file_path, 'r', encoding='utf-8-sig') as f:
                reader = csv.DictReader(f)
                count = 0
                
                for row in reader:
                    # Enhanced name handling for comprehensive matching
                    csv_name = row['last_name, first_name']  # "Henderson, Gunnar"
                    normalized_name = self.normalize_name(csv_name)  # "gunnar henderson"
                    
                    def safe_int(value, default=0):
                        try:
                            return int(value) if value and value.strip() else default
                        except (ValueError, AttributeError):
                            return default
                    
                    def safe_float(value, default=0.0):
                        try:
                            return float(value) if value and value.strip() else default
                        except (ValueError, AttributeError):
                            return default
                    
                    # Store data using normalized name for lookup
                    batter_data = {
                        # Traditional stats
                        'ab': safe_int(row.get('ab', 0)),
                        'pa': safe_int(row.get('pa', 0)),
                        'hit': safe_int(row.get('hit', 0)),
                        'home_run': safe_int(row.get('home_run', 0)),
                        'strikeout': safe_int(row.get('strikeout', 0)),
                        'walk': safe_int(row.get('walk', 0)),
                        
                        # Rate stats
                        'batting_avg': safe_float(row.get('batting_avg', 0)),
                        'on_base_percent': safe_float(row.get('on_base_percent', 0)),
                        'slugging_percent': safe_float(row.get('slg_percent', 0)),
                        'ops': safe_float(row.get('on_base_plus_slg', 0)),
                        'isolated_power': safe_float(row.get('isolated_power', 0)),
                        'babip': safe_float(row.get('babip', 0)),
                        'k_percent': safe_float(row.get('k_percent', 0)),
                        'bb_percent': safe_float(row.get('bb_percent', 0)),
                        
                        # Expected statistics
                        'xba': safe_float(row.get('xba', 0)),
                        'xslg': safe_float(row.get('xslg', 0)),
                        'xwoba': safe_float(row.get('xwoba', 0)),
                        'woba': safe_float(row.get('woba', 0)),
                        'xobp': safe_float(row.get('xobp', 0)),
                        'xiso': safe_float(row.get('xiso', 0)),
                        
                        # Expected stats gaps
                        'xba_diff': safe_float(row.get('xbadiff', 0)),
                        'xslg_diff': safe_float(row.get('xslgdiff', 0)),
                        'woba_diff': safe_float(row.get('wobadiff', 0)),
                        
                        # Contact quality
                        'barrel': safe_int(row.get('barrel', 0)),
                        'barrel_batted_rate': safe_float(row.get('barrel_batted_rate', 0)),
                        'hard_hit_percent': safe_float(row.get('hard_hit_percent', 0)),
                        'sweet_spot_percent': safe_float(row.get('sweet_spot_percent', 0)),
                        'exit_velocity_avg': safe_float(row.get('exit_velocity_avg', 0)),
                        'launch_angle_avg': safe_float(row.get('launch_angle_avg', 0)),
                        
                        # Plate discipline
                        'z_swing_percent': safe_float(row.get('z_swing_percent', 0)),
                        'oz_swing_percent': safe_float(row.get('oz_swing_percent', 0)),
                        'whiff_percent': safe_float(row.get('whiff_percent', 0)),
                        'swing_percent': safe_float(row.get('swing_percent', 0)),
                        
                        # Metadata
                        'player_id': row.get('player_id', ''),
                        'player_age': safe_int(row.get('player_age', 0)),
                        'sprint_speed': safe_float(row.get('sprint_speed', 0)),
                        'data_quality': self.assess_data_quality(safe_int(row.get('pa', 0)), 'batter'),
                        'csv_name': csv_name,  # Store original CSV name for reference
                        'normalized_name': normalized_name  # Store normalized name
                    }
                    
                    # Store using normalized name as key for lookup
                    self.custom_batters[normalized_name] = batter_data
                    count += 1
                
                print(f"   ðŸ“ˆ Loaded comprehensive data for {count} batters")
                
        except Exception as e:
            print(f"âŒ Error loading custom batter data: {e}")
    
    def load_custom_pitcher_data(self):
        """Load comprehensive custom pitcher data with expected statistics"""
        file_path = self.stats_path / "custom_pitcher_2025.csv"
        
        if not file_path.exists():
            print("âš ï¸ Custom pitcher file not found")
            return
        
        try:
            with open(file_path, 'r', encoding='utf-8-sig') as f:
                reader = csv.DictReader(f)
                count = 0
                
                for row in reader:
                    player_name = self.normalize_name(row['last_name, first_name'])
                    
                    def safe_int(value, default=0):
                        try:
                            return int(value) if value and value.strip() else default
                        except (ValueError, AttributeError):
                            return default
                    
                    def safe_float(value, default=0.0):
                        try:
                            return float(value) if value and value.strip() else default
                        except (ValueError, AttributeError):
                            return default
                    
                    self.custom_pitchers[player_name] = {
                        # Basic stats
                        'games': safe_int(row.get('p_game', 0)),
                        'innings_pitched': safe_float(row.get('p_formatted_ip', 0)),
                        'era': safe_float(row.get('p_era', 0)),
                        
                        # Batters faced stats
                        'pa': safe_int(row.get('pa', 0)),
                        'ab': safe_int(row.get('ab', 0)),
                        'hits_allowed': safe_int(row.get('hit', 0)),
                        'home_runs_allowed': safe_int(row.get('home_run', 0)),
                        'strikeouts': safe_int(row.get('strikeout', 0)),
                        'walks': safe_int(row.get('walk', 0)),
                        
                        # Opponent rate stats
                        'opp_batting_avg': safe_float(row.get('batting_avg', 0)),
                        'opp_on_base_percent': safe_float(row.get('on_base_percent', 0)),
                        'opp_slugging_percent': safe_float(row.get('slg_percent', 0)),
                        'opp_ops': safe_float(row.get('on_base_plus_slg', 0)),
                        'opp_isolated_power': safe_float(row.get('isolated_power', 0)),
                        'opp_babip': safe_float(row.get('babip', 0)),
                        'k_percent': safe_float(row.get('k_percent', 0)),
                        'bb_percent': safe_float(row.get('bb_percent', 0)),
                        
                        # Expected statistics allowed
                        'xba_allowed': safe_float(row.get('xba', 0)),
                        'xslg_allowed': safe_float(row.get('xslg', 0)),
                        'xwoba_allowed': safe_float(row.get('xwoba', 0)),
                        'woba_allowed': safe_float(row.get('woba', 0)),
                        
                        # Expected stats gaps
                        'xba_diff': safe_float(row.get('xbadiff', 0)),
                        'xslg_diff': safe_float(row.get('xslgdiff', 0)),
                        'woba_diff': safe_float(row.get('wobadiff', 0)),
                        
                        # Contact quality allowed
                        'barrels_allowed': safe_int(row.get('barrel', 0)),
                        'barrel_batted_rate_allowed': safe_float(row.get('barrel_batted_rate', 0)),
                        'hard_hit_percent_allowed': safe_float(row.get('hard_hit_percent', 0)),
                        'sweet_spot_percent_allowed': safe_float(row.get('sweet_spot_percent', 0)),
                        'exit_velocity_avg_allowed': safe_float(row.get('exit_velocity_avg', 0)),
                        'launch_angle_avg_allowed': safe_float(row.get('launch_angle_avg', 0)),
                        
                        # Arsenal data
                        'pitch_hand': row.get('pitch_hand', 'R'),
                        'arm_angle': safe_float(row.get('arm_angle', 0)),
                        
                        # Metadata
                        'player_id': row.get('player_id', ''),
                        'player_age': safe_int(row.get('player_age', 0)),
                        'data_quality': self.assess_data_quality(safe_int(row.get('pa', 0)), 'pitcher')
                    }
                    count += 1
                
                print(f"   ðŸ¹ Loaded comprehensive data for {count} pitchers")
                
        except Exception as e:
            print(f"âŒ Error loading custom pitcher data: {e}")
    
    def load_pitcher_arsenal_data(self):
        """Load pitcher arsenal data by pitch type"""
        file_path = self.stats_path / "pitcherpitcharsenalstats_2025.csv"
        
        if not file_path.exists():
            print("âš ï¸ Pitcher arsenal file not found")
            return
        
        try:
            with open(file_path, 'r', encoding='utf-8-sig') as f:
                reader = csv.DictReader(f)
                count = 0
                
                for row in reader:
                    pitcher_name = self.normalize_name(row['last_name, first_name'])
                    
                    if pitcher_name not in self.pitcher_arsenal:
                        self.pitcher_arsenal[pitcher_name] = {
                            'team': row.get('team_name_alt', ''),
                            'pitch_types': {}
                        }
                    
                    pitch_type = row['pitch_type']
                    pitch_data = {
                        'pitch_name': row['pitch_name'],
                        'run_value_per_100': float(row.get('run_value_per_100', 0)),
                        'usage': float(row.get('pitch_usage', 0)),
                        'ba_against': float(row.get('ba', 0)),
                        'slg_against': float(row.get('slg', 0)),
                        'woba_against': float(row.get('woba', 0)),
                        'whiff_percent': float(row.get('whiff_percent', 0)),
                        'hard_hit_percent': float(row.get('hard_hit_percent', 0)),
                        'k_percent': float(row.get('k_percent', 0)),
                        'pitches': int(row.get('pitches', 0))
                    }
                    
                    self.pitcher_arsenal[pitcher_name]['pitch_types'][pitch_type] = pitch_data
                    count += 1
                
                print(f"   ðŸŽ¯ Loaded arsenal data for {len(self.pitcher_arsenal)} pitchers")
                
        except Exception as e:
            print(f"âŒ Error loading pitcher arsenal data: {e}")
    
    def load_handedness_data(self):
        """Load handedness-specific batted ball data"""
        handedness_combinations = [
            ('batters-batted-ball-bat-left-pitch-hand-left-2025.csv', 'L', 'L'),
            ('batters-batted-ball-bat-left-pitch-hand-right-2025.csv', 'L', 'R'),
            ('batters-batted-ball-bat-right-pitch-hand-left-2025.csv', 'R', 'L'),
            ('batters-batted-ball-bat-right-pitch-hand-right-2025.csv', 'R', 'R')
        ]
        
        for filename, bat_hand, pitch_hand in handedness_combinations:
            file_path = self.stats_path / filename
            
            if not file_path.exists():
                print(f"âš ï¸ Handedness file not found: {filename}")
                continue
            
            try:
                with open(file_path, 'r', encoding='utf-8-sig') as f:
                    reader = csv.DictReader(f)
                    count = 0
                    
                    for row in reader:
                        batter_name = self.normalize_name(row['name'])
                        
                        if batter_name not in self.handedness_data:
                            self.handedness_data[batter_name] = {}
                        
                        matchup_key = f"{bat_hand}v{pitch_hand}"
                        self.handedness_data[batter_name][matchup_key] = {
                            'bbe': int(row.get('bbe', 0)),
                            'gb_rate': float(row.get('gb_rate', 0)),
                            'air_rate': float(row.get('air_rate', 0)),
                            'fb_rate': float(row.get('fb_rate', 0)),
                            'ld_rate': float(row.get('ld_rate', 0)),
                            'pull_rate': float(row.get('pull_rate', 0)),
                            'oppo_rate': float(row.get('oppo_rate', 0)),
                            'pull_air_rate': float(row.get('pull_air_rate', 0))
                        }
                        count += 1
                
                print(f"   ðŸ“Š Loaded {filename}: {count} records")
            
            except Exception as e:
                print(f"âŒ Error loading {filename}: {e}")
    
    def load_roster_data(self):
        """Load roster data for name mapping and team assignments"""
        roster_file = self.data_path / "rosters.json"
        
        if not roster_file.exists():
            print("âš ï¸ Roster file not found")
            return
        
        try:
            with open(roster_file, 'r') as f:
                roster_data = json.load(f)
                
                for player in roster_data:
                    name = self.normalize_name(player['name'])
                    self.rosters[name] = {
                        'team': player.get('team', ''),
                        'position': player.get('type', ''),  # 'type' is either 'pitcher' or 'hitter'
                        'batter_hand': player.get('bats', ''),  # 'bats' for batters
                        'pitcher_hand': player.get('ph', ''),  # 'ph' for pitchers
                        'fullName': player.get('fullName', ''),
                        'playerId': player.get('playerId', '')
                    }
                
                print(f"   ðŸ“‹ Loaded roster data for {len(self.rosters)} players")
        
        except Exception as e:
            print(f"âŒ Error loading roster data: {e}")
    
    def load_starting_lineups(self, date):
        """Load starting lineups for the given date"""
        # Try date-specific lineup file first
        lineups_file = self.data_path / f"lineups/starting_lineups_{date}.json"
        
        if not lineups_file.exists():
            # Try generic lineup file as fallback
            lineups_file = self.data_path / "starting_lineups.json"
            
            if not lineups_file.exists():
                print("âš ï¸ Starting lineups file not found")
                return None
        
        try:
            with open(lineups_file, 'r') as f:
                lineups_data = json.load(f)
                
                # Check if date matches
                if lineups_data.get('date') == date:
                    return lineups_data
                else:
                    print(f"âš ï¸ Lineups data is for {lineups_data.get('date')}, not {date}")
                    return lineups_data  # Use anyway as fallback
        
        except Exception as e:
            print(f"âŒ Error loading starting lineups: {e}")
            return None
    
    def get_team_hitters(self, team_abbr, date):
        """Get hitters for a team from roster data with recent game fallback"""
        team_hitters = []
        
        # PRIMARY: Use full roster data for comprehensive analysis
        if hasattr(self, 'rosters') and self.rosters:
            roster_hitters = []
            for player_name, player_data in self.rosters.items():
                if (teams_match(player_data.get('team', ''), team_abbr) and 
                    player_data.get('position') == 'hitter'):  # Only include hitters
                    
                    roster_hitters.append({
                        'name': player_name,
                        'team': team_abbr,
                        'position': player_data.get('position', 'hitter'),
                        'bats': player_data.get('batter_hand', 'R'),
                        'fullName': player_data.get('fullName', player_name),
                        'playerId': player_data.get('playerId', ''),
                        'stats': {
                            'AB': 0,  # Will be filled from other data sources if available
                            'H': 0,
                            'HR': 0,
                            'RBI': 0,
                            'AVG': 0.250  # Default reasonable batting average
                        }
                    })
            
            if roster_hitters:
                print(f"   ðŸ“Š Found {len(roster_hitters)} roster hitters for {team_abbr}")
                return roster_hitters  # Return ALL roster hitters, not just 9
        
        # FALLBACK: Use recent game data if roster not available
        for i in range(7):  # Look back up to 7 days
            check_date = datetime.strptime(date, '%Y-%m-%d') - timedelta(days=i)
            year = check_date.year
            month = check_date.strftime('%B').lower()
            day = check_date.day
            
            file_path = self.data_path / f"{year}/{month}/{month}_{day:02d}_{year}.json"
            
            if file_path.exists():
                try:
                    with open(file_path, 'r') as f:
                        game_data = json.load(f)
                    
                    if 'players' in game_data:
                        for player in game_data['players']:
                            if (player.get('playerType') == 'hitter' and 
                                (teams_match(player.get('team', ''), team_abbr) or teams_match(player.get('Team', ''), team_abbr)) and
                                player.get('name') and
                                (player.get('AB', 0) > 0 or player.get('H', 0) > 0)):
                                
                                team_hitters.append({
                                    'name': player['name'],
                                    'team': team_abbr,
                                    'stats': {
                                        'AB': player.get('AB', 0),
                                        'H': player.get('H', 0),
                                        'HR': player.get('HR', 0),
                                        'RBI': player.get('RBI', 0),
                                        'AVG': player.get('AVG', 0)
                                    }
                                })
                    
                    if team_hitters:
                        print(f"   ðŸ“Š Found {len(team_hitters)} recent hitters for {team_abbr}")
                        return team_hitters  # Return all found hitters, not limited to 9
                
                except Exception as e:
                    continue
        
        print(f"   âš ï¸ No hitters found for team {team_abbr}")
        return []
    
    def get_pitcher_handedness(self, pitcher_name):
        """Determine pitcher handedness from roster data"""
        normalized_name = self.normalize_name(pitcher_name)
        
        if normalized_name in self.rosters:
            ph = self.rosters[normalized_name].get('pitcher_hand', '')
            if ph in ['L', 'R']:
                return ph
        
        return 'R'  # Default to right-handed
    
    def get_batter_handedness(self, batter_name):
        """Determine batter handedness from roster data"""
        normalized_name = self.normalize_name(batter_name)
        
        if normalized_name in self.rosters:
            bats = self.rosters[normalized_name].get('batter_hand', '')
            if bats in ['L', 'R', 'S']:
                return 'L' if bats == 'L' else 'R'
        
        if normalized_name in self.handedness_data:
            perf_data = self.handedness_data[normalized_name]
            if 'LvL' in perf_data or 'LvR' in perf_data:
                return 'L'
            elif 'RvL' in perf_data or 'RvR' in perf_data:
                return 'R'
        
        return 'R'  # Default to right-handed
    
    def assess_data_quality(self, sample_size, player_type):
        """Assess data quality based on sample size"""
        if player_type == 'hitter':
            if sample_size >= 250: return 'excellent'
            if sample_size >= 150: return 'good'
            if sample_size >= 75: return 'fair'
            return 'limited'
        else:  # pitcher
            if sample_size >= 200: return 'excellent'
            if sample_size >= 100: return 'good'
            if sample_size >= 50: return 'fair'
            return 'limited'
    
    def normalize_name(self, name):
        """Normalize player names for consistent matching"""
        if not name:
            return ""
        
        # Handle "Last, First" format
        if ',' in name:
            parts = name.split(',')
            if len(parts) == 2:
                last, first = parts[0].strip(), parts[1].strip()
                name = f"{first} {last}"
        
        # Clean up the name
        name = re.sub(r'[^\w\s\.]', '', name)
        name = ' '.join(name.split())
        
        return name.strip()
    
    def normalize_venue_name(self, venue_name):
        """Normalize venue names to match stadium HR analysis data"""
        if not venue_name:
            return ""
        
        # Venue name mappings to handle naming inconsistencies
        venue_mappings = {
            # Oakland A's stadium variations
            'Daikin Park': 'Oakland Coliseum',
            'Oakland-Alameda County Coliseum': 'Oakland Coliseum',
            'RingCentral Coliseum': 'Oakland Coliseum',
            'O.co Coliseum': 'Oakland Coliseum',
            'Overstock.com Coliseum': 'Oakland Coliseum',
            'Network Associates Coliseum': 'Oakland Coliseum',
            'McAfee Coliseum': 'Oakland Coliseum',
            # Chicago White Sox stadium variations
            'Rate Field': 'Guaranteed Rate Field',
            'U.S. Cellular Field': 'Guaranteed Rate Field',
            'Comiskey Park': 'Guaranteed Rate Field',
            # Other common venue variations
            'Minute Maid Park': 'Minute Maid Park',
            'Globe Life Field': 'Globe Life Field',
            'Chase Field': 'Chase Field',
            'Tropicana Field': 'Tropicana Field',
            'Rogers Centre': 'Rogers Centre',
            'Marlins Park': 'Marlins Park'
        }
        
        # Return mapped name or original if no mapping exists
        return venue_mappings.get(venue_name, venue_name)
    
    def generate_comprehensive_venue_analytics(self, venue, batter_team, pitcher_name, venue_home_team=''):
        """
        Generate comprehensive venue analytics for the Game Context section
        Uses daily game files for recent series data (like successful JS components)
        Implements proper home field advantage impact on away team players
        venue_home_team: The actual home team for today's game (critical for correct home/away determination)
        """
        if not venue:
            return {}
        
        normalized_venue = self.normalize_venue_name(venue)
        venue_analytics = {}
        
        try:
            # PHASE 1: Load stadium baseline data (park factors, overall stats)
            stadium_file = self.data_path / "stadium/stadium_hr_analysis.json"
            if stadium_file.exists():
                with open(stadium_file, 'r') as f:
                    stadium_data = json.load(f)
                
                stadiums = stadium_data.get('stadiums', {})
                venue_data = stadiums.get(normalized_venue)
                
                if not venue_data:
                    # Try alternative venue names
                    for stadium_name in stadiums.keys():
                        if normalized_venue.lower() in stadium_name.lower() or stadium_name.lower() in normalized_venue.lower():
                            venue_data = stadiums[stadium_name]
                            break
                
                if venue_data:
                    # Stadium HR Statistics (baseline data)
                    venue_analytics['stadium_hr_stats'] = {
                        'total_home_runs': venue_data.get('totalHomeRuns', 0),
                        'total_games': venue_data.get('totalGames', 0),
                        'average_hrs_per_game': venue_data.get('averageHRsPerGame', '0.00'),
                        'home_team_hrs': venue_data.get('homeTeamHomeRuns', 0),
                        'away_team_hrs': venue_data.get('awayTeamHomeRuns', 0),
                        'home_team': venue_data.get('homeTeam', '')
                    }
                    
                    # Home field advantage baseline
                    home_team_hrs = venue_data.get('homeTeamHomeRuns', 0)
                    away_team_hrs = venue_data.get('awayTeamHomeRuns', 0)
                    venue_analytics['home_field_advantage'] = {
                        'exists': home_team_hrs > away_team_hrs,
                        'home_advantage_pct': (home_team_hrs / max(home_team_hrs + away_team_hrs, 1)) * 100,
                        'away_penalty_factor': 0.85 if home_team_hrs > away_team_hrs * 1.2 else 0.95
                    }
            
            # PHASE 2: Load recent series data from daily game files (like CurrentSeriesCards)
            recent_venue_trends = self.load_recent_venue_series_data(normalized_venue, batter_team)
            if recent_venue_trends:
                venue_analytics.update(recent_venue_trends)
            
            # PHASE 3: Enhanced stadium analytics (park factors from existing system)
            if normalized_venue in self.park_factors:
                park_data = self.park_factors[normalized_venue]
                venue_analytics['enhanced_stadium_analytics'] = {
                    'park_factor': park_data.get('hr_factor', 1.0),
                    'park_category': park_data.get('category', 'neutral'),
                    'park_description': self.get_park_factor_description(park_data.get('hr_factor', 1.0))
                }
            
            # PHASE 4: Generate actionable venue context with actual game's home team
            venue_analytics['venue_context'] = self.generate_actionable_venue_context(
                venue_analytics, normalized_venue, batter_team, venue_home_team
            )
            
            print(f"   ðŸŸï¸ Generated comprehensive venue analytics for {normalized_venue}")
                
        except Exception as e:
            print(f"   âŒ Error generating venue analytics: {e}")
            return {}
        
        return venue_analytics
    
    def get_park_factor_description(self, factor):
        """Get human-readable park factor description"""
        if factor > 1.1:
            return "Very Hitter-Friendly"
        elif factor > 1.05:
            return "Hitter-Friendly"
        elif factor < 0.9:
            return "Very Pitcher-Friendly"
        elif factor < 0.95:
            return "Pitcher-Friendly"
        else:
            return "Neutral"
    
    def load_recent_venue_series_data(self, venue, batter_team):
        """
        Load recent series data from daily game files (like CurrentSeriesCards does)
        This provides actual recent venue performance instead of "insufficient data"
        """
        venue_trends = {}
        
        try:
            # Get date range for last 14 days
            from datetime import datetime, timedelta
            
            current_date = datetime.now()
            recent_games = []
            venue_home_team = None
            
            # Load games from last 14 days
            for days_back in range(14):
                check_date = current_date - timedelta(days=days_back)
                date_str = check_date.strftime('%Y-%m-%d')
                
                # Load daily game file
                year = check_date.year
                month_name = check_date.strftime('%B').lower()
                day = check_date.day
                
                game_file = self.data_path / f"{year}/{month_name}/{month_name}_{day:02d}_{year}.json"
                
                if game_file.exists():
                    try:
                        with open(game_file, 'r') as f:
                            daily_data = json.load(f)
                        
                        # Find games at this venue
                        for game in daily_data.get('games', []):
                            game_venue = self.normalize_venue_name(game.get('venue', ''))
                            if game_venue == venue and game.get('status') == 'Final':
                                recent_games.append({
                                    'date': date_str,
                                    'home_team': game.get('homeTeam'),
                                    'away_team': game.get('awayTeam'),
                                    'home_score': game.get('homeScore', 0),
                                    'away_score': game.get('awayScore', 0),
                                    'venue': game.get('venue')
                                })
                                
                                # Track venue's home team
                                if not venue_home_team:
                                    venue_home_team = game.get('homeTeam')
                    
                    except Exception as e:
                        # Skip problematic files silently
                        continue
            
            # Analyze recent venue performance
            if recent_games:
                recent_games.sort(key=lambda x: x['date'], reverse=True)  # Most recent first
                
                venue_trends['recent_venue_performance'] = {
                    'games_found': len(recent_games),
                    'last_3_games': recent_games[:3],
                    'venue_home_team': venue_home_team,
                    'recent_trend': self.analyze_recent_series_trend(recent_games)
                }
                
                # Team-specific performance at venue
                if batter_team:
                    team_games = [g for g in recent_games 
                                if g['home_team'] == batter_team or g['away_team'] == batter_team]
                    
                    if team_games:
                        home_games = [g for g in team_games if g['home_team'] == batter_team]
                        away_games = [g for g in team_games if g['away_team'] == batter_team]
                        
                        venue_trends['team_venue_performance'] = {
                            'team': batter_team,
                            'recent_games_at_venue': len(team_games),
                            'home_games': len(home_games),
                            'away_games': len(away_games),
                            'is_playing_away': batter_team != venue_home_team,
                            'recent_series_context': f"Last {len(team_games)} games at {venue}"
                        }
            
            else:
                venue_trends['recent_venue_performance'] = {
                    'games_found': 0,
                    'recent_trend': 'No recent games at venue'
                }
            
        except Exception as e:
            print(f"   âš ï¸ Error loading recent venue data: {e}")
            venue_trends['recent_venue_performance'] = {
                'games_found': 0,
                'recent_trend': 'Data loading error'
            }
        
        return venue_trends
    
    def analyze_recent_series_trend(self, recent_games):
        """
        Enhanced trend analysis using comprehensive venue data
        Fixed to provide meaningful trends instead of "insufficient data"
        """
        if not recent_games:
            return "No recent games available"
        
        if len(recent_games) < 2:
            return "Limited sample size"
        
        # Take last 5 games for trend analysis (or all if less than 5)
        trend_games = recent_games[:min(5, len(recent_games))]
        
        # Enhanced scoring analysis with multiple factors
        total_scores = [g['home_score'] + g['away_score'] for g in trend_games]
        home_scores = [g['home_score'] for g in trend_games]
        away_scores = [g['away_score'] for g in trend_games]
        
        # Calculate averages
        avg_total_runs = sum(total_scores) / len(total_scores)
        avg_home_runs = sum(home_scores) / len(home_scores)
        avg_away_runs = sum(away_scores) / len(away_scores)
        
        # Determine venue characteristics based on recent data
        venue_trend = None
        venue_indicators = []
        
        # High scoring trend indicators
        if avg_total_runs > 10:
            venue_trend = "trending_up"
            venue_indicators.append(f"High scoring ({avg_total_runs:.1f} runs/game)")
        elif avg_total_runs > 8.5:
            venue_trend = "stable" 
            venue_indicators.append(f"Above average scoring ({avg_total_runs:.1f} runs/game)")
        elif avg_total_runs < 6:
            venue_trend = "trending_down"
            venue_indicators.append(f"Low scoring ({avg_total_runs:.1f} runs/game)")
        else:
            venue_trend = "stable"
            venue_indicators.append(f"Average scoring ({avg_total_runs:.1f} runs/game)")
        
        # Home field advantage indicators
        if avg_home_runs > avg_away_runs * 1.3:
            venue_indicators.append("Strong home field advantage")
        elif avg_home_runs > avg_away_runs * 1.1:
            venue_indicators.append("Moderate home field advantage")
        elif avg_away_runs > avg_home_runs * 1.1:
            venue_indicators.append("Away team friendly")
        
        # Game progression analysis (if enough games)
        if len(trend_games) >= 3:
            recent_2 = sum(total_scores[:2]) / 2 if len(total_scores) >= 2 else total_scores[0]
            earlier_2 = sum(total_scores[-2:]) / 2 if len(total_scores) >= 2 else total_scores[-1]
            
            if recent_2 > earlier_2 * 1.4:
                venue_trend = "trending_up"
                venue_indicators.append("Recent uptick in scoring")
            elif recent_2 < earlier_2 * 0.6:
                venue_trend = "trending_down" 
                venue_indicators.append("Recent decline in scoring")
        
        # Return comprehensive trend description
        trend_description = venue_trend.replace('_', ' ').title()
        if venue_indicators:
            return f"{trend_description} - {', '.join(venue_indicators)}"
        else:
            return f"{trend_description} based on {len(trend_games)} recent games"
    
    def generate_actionable_venue_context(self, venue_analytics, venue_name, batter_team, venue_home_team=''):
        """
        Generate actionable venue context for weakspot analysis
        Properly applies home field advantage impact based on actual game matchup
        """
        context = {
            'venue_name': venue_name,
            'analysis_confidence': 'medium'  # Default
        }
        
        # CRITICAL FIX: Determine if batter team is playing away based on ACTUAL GAME MATCHUP
        # Not based on historical venue data
        recent_perf = venue_analytics.get('recent_venue_performance', {})
        team_perf = venue_analytics.get('team_venue_performance', {})
        
        # Use the actual game's home team, not historical data
        is_away_team = batter_team != venue_home_team if venue_home_team else team_perf.get('is_playing_away', False)
        
        # Enhanced home field advantage analysis with meaningful impact
        home_advantage = venue_analytics.get('home_field_advantage', {})
        
        # Determine actual home field advantage from recent games
        recent_trend = recent_perf.get('recent_trend', '')
        
        # Extract home field advantage strength from trend analysis
        home_field_strength = 0.0
        if 'Strong home field advantage' in recent_trend:
            home_field_strength = 0.15  # 15% penalty for away teams
        elif 'Moderate home field advantage' in recent_trend:
            home_field_strength = 0.08  # 8% penalty for away teams
        elif 'Away team friendly' in recent_trend:
            home_field_strength = -0.05  # 5% bonus for away teams
        else:
            # Default analysis from stadium data
            home_field_strength = 0.05 if home_advantage.get('exists', False) else 0.0
        
        if is_away_team and home_field_strength > 0:
            penalty_factor = 1.0 - home_field_strength
            context['home_field_impact'] = {
                'away_team_penalty': True,
                'penalty_factor': penalty_factor,
                'penalty_percentage': int(home_field_strength * 100),
                'reasoning': f"Away team at {venue_name} - {int(home_field_strength * 100)}% scoring penalty based on recent trends"
            }
        elif is_away_team and home_field_strength < 0:
            bonus_factor = 1.0 + abs(home_field_strength)
            context['home_field_impact'] = {
                'away_team_penalty': False,
                'penalty_factor': bonus_factor,
                'bonus_percentage': int(abs(home_field_strength) * 100),
                'reasoning': f"Away team advantage at {venue_name} - {int(abs(home_field_strength) * 100)}% scoring bonus"
            }
        else:
            context['home_field_impact'] = {
                'away_team_penalty': False,
                'penalty_factor': 1.0,
                'reasoning': f"{'Home team' if not is_away_team else 'Neutral venue'} - no field advantage penalty"
            }
        
        # Stadium characteristics
        stadium_stats = venue_analytics.get('stadium_hr_stats', {})
        avg_hrs = float(stadium_stats.get('average_hrs_per_game', '0.0'))
        
        context['stadium_profile'] = {
            'is_hitter_friendly': avg_hrs > 1.0,
            'avg_hrs_per_game': avg_hrs,
            'category': 'hitter-friendly' if avg_hrs > 1.2 else 'pitcher-friendly' if avg_hrs < 0.8 else 'neutral'
        }
        
        # Recent trend context
        recent_trend = recent_perf.get('recent_trend', 'Unknown')
        context['recent_trend'] = recent_trend
        
        # Enhanced analysis confidence based on data availability
        games_found = recent_perf.get('games_found', 0)
        if games_found >= 5:
            context['analysis_confidence'] = 'high'
        elif games_found >= 2:
            context['analysis_confidence'] = 'medium'
        else:
            context['analysis_confidence'] = 'low'
        
        return context
    
    def safe_int(self, value, default=0):
        """Safely convert value to integer with error handling"""
        try:
            if value is None or value == '':
                return default
            if isinstance(value, str):
                value = value.strip()
                if not value:
                    return default
            return int(float(value))  # Handle strings like "1.0"
        except (ValueError, TypeError, AttributeError):
            return default
    
    def safe_float(self, value, default=0.0):
        """Safely convert value to float with error handling"""
        try:
            if value is None or value == '':
                return default
            if isinstance(value, str):
                value = value.strip()
                if not value:
                    return default
            return float(value)
        except (ValueError, TypeError, AttributeError):
            return default
    
    def comprehensive_name_matching(self, search_name, target_name):
        """Enhanced name matching to handle G. Henderson vs Henderson, Gunnar"""
        if not search_name or not target_name:
            return False
            
        # Direct match after normalization
        search_norm = self.normalize_name(search_name).lower()
        target_norm = self.normalize_name(target_name).lower()
        
        if search_norm == target_norm:
            return True
            
        # Handle abbreviated names "G. Henderson" vs "gunnar henderson" 
        search_parts = search_norm.split()
        target_parts = target_norm.split()
        
        if len(search_parts) >= 2 and len(target_parts) >= 2:
            # Check if first initial matches and last name matches
            search_first = search_parts[0].replace('.', '')
            target_first = target_parts[0].replace('.', '')
            
            # First initial + last name match
            if (len(search_first) == 1 and search_first == target_first[0] and 
                search_parts[-1] == target_parts[-1]):
                return True
                
            # Target initial + search full first name match  
            if (len(target_first) == 1 and target_first == search_first[0] and
                search_parts[-1] == target_parts[-1]):
                return True
        
        # Handle "Last, First" in original formats before normalization
        if ', ' in search_name or ', ' in target_name:
            # Convert both to "First Last" format for comparison
            search_converted = self.normalize_name(search_name).lower()
            target_converted = self.normalize_name(target_name).lower()
            
            if search_converted == target_converted:
                return True
        
        return False
    
    def get_csv_format_name(self, player_name):
        """Convert player name to CSV format (Last, First) using roster data"""
        # If already in CSV format, return as is
        if ', ' in player_name:
            return player_name
            
        # Try to find in roster for full name
        if hasattr(self, 'rosters'):
            for roster_entry in self.rosters:
                if ('name' in roster_entry and 
                    self.comprehensive_name_matching(player_name, roster_entry['name'])):
                    
                    # Use fullName if available
                    full_name = roster_entry.get('fullName', roster_entry['name'])
                    
                    # Convert to CSV format
                    if ', ' not in full_name:
                        parts = full_name.split()
                        if len(parts) >= 2:
                            first_name = parts[0]  
                            last_name = ' '.join(parts[1:])
                            return f"{last_name}, {first_name}"
                    
                    return full_name
        
        # Fallback: convert manually if no roster match
        parts = player_name.split()
        if len(parts) >= 2:
            first_name = parts[0].replace('.', '')  # Remove periods from initials
            last_name = ' '.join(parts[1:])
            return f"{last_name}, {first_name}"
        
        return player_name
    
    def find_batter_data(self, player_name):
        """Find batter data using comprehensive name matching"""
        # Try direct lookup first
        normalized_search = self.normalize_name(player_name)
        if normalized_search in self.custom_batters:
            return self.custom_batters[normalized_search]
        
        # Try comprehensive matching against all stored names
        for stored_name, batter_data in self.custom_batters.items():
            if self.comprehensive_name_matching(player_name, stored_name):
                return batter_data
                
            # Also try matching against the original CSV name
            if 'csv_name' in batter_data:
                if self.comprehensive_name_matching(player_name, batter_data['csv_name']):
                    return batter_data
        
        return None
    
    def generate_enhanced_arsenal_justification(self, batter_name, pitcher_name, exploit_analysis):
        """Generate detailed arsenal-based justification with specific statistical evidence"""
        # Get normalized names for lookup
        normalized_batter = self.normalize_name(batter_name)
        normalized_pitcher = self.normalize_name(pitcher_name)
        
        # Get batter data
        batter_data = self.find_batter_data(batter_name)
        if not batter_data:
            return "Limited batter data available for detailed analysis"
        
        # Get pitcher arsenal data
        if normalized_pitcher not in self.pitcher_arsenal:
            return "No detailed arsenal data available for pitcher"
        
        arsenal_data = self.pitcher_arsenal[normalized_pitcher]
        
        # Find most vulnerable pitch
        most_vulnerable_pitch = None
        highest_vulnerability = 0
        
        for pitch_type, pitch_data in arsenal_data['pitch_types'].items():
            usage = pitch_data.get('usage', 0)
            ba_against = pitch_data.get('ba_against', 0)
            whiff_percent = pitch_data.get('whiff_percent', 100)
            
            # Skip low-usage pitches
            if usage < 10:
                continue
            
            # Calculate vulnerability score
            vulnerability_score = 0
            
            # BA vulnerability
            if ba_against > 0.300:
                vulnerability_score += 25
            elif ba_against > 0.280:
                vulnerability_score += 20
            elif ba_against > 0.260:
                vulnerability_score += 15
            
            # Whiff rate vulnerability (lower is worse for pitcher)
            if whiff_percent < 20:
                vulnerability_score += 15
            elif whiff_percent < 25:
                vulnerability_score += 10
            
            # Usage factor (over-reliance penalty)
            if usage > 30 and ba_against > 0.270:
                vulnerability_score += 20
            elif usage > 25 and ba_against > 0.250:
                vulnerability_score += 15
            
            if vulnerability_score > highest_vulnerability:
                highest_vulnerability = vulnerability_score
                most_vulnerable_pitch = {
                    'name': pitch_data.get('pitch_name', pitch_type),
                    'usage': usage,
                    'ba_against': ba_against,
                    'whiff_percent': whiff_percent,
                    'vulnerability_score': vulnerability_score
                }
        
        if not most_vulnerable_pitch:
            return "No significant pitch vulnerabilities identified"
        
        # Generate specific justification based on batter profile vs pitch weakness
        justifications = []
        
        # Extract key batter metrics
        z_swing = float(batter_data.get('z_swing_percent', 0))
        oz_swing = float(batter_data.get('oz_swing_percent', 0))
        bb_rate = float(batter_data.get('bb_percent', 0))
        barrel_rate = float(batter_data.get('barrel_percent', 0))
        whiff_rate = float(batter_data.get('whiff_percent', 0))
        
        pitch_name = most_vulnerable_pitch['name']
        usage = most_vulnerable_pitch['usage']
        ba_against = most_vulnerable_pitch['ba_against']
        pitch_whiff = most_vulnerable_pitch['whiff_percent']
        
        # Specific batter vs pitch matchup analysis
        if 'fastball' in pitch_name.lower() or '4-seam' in pitch_name.lower():
            if z_swing > 65:
                justifications.append(f"Zone aggressive hitter ({z_swing:.1f}% zone swing) vs vulnerable {pitch_name}")
            elif z_swing > 50:
                justifications.append(f"Above average zone aggression ({z_swing:.1f}%) vs {pitch_name} weakness")
            
            if barrel_rate > 8 and ba_against > 0.280:
                justifications.append(f"Power threat ({barrel_rate:.1f}% barrels) vs contact-vulnerable {pitch_name}")
                
        elif any(x in pitch_name.lower() for x in ['slider', 'curve', 'cutter']):
            if whiff_rate < 20 and pitch_whiff < 25:
                justifications.append(f"Contact specialist ({whiff_rate:.1f}% whiff) vs ineffective {pitch_name}")
            if bb_rate > 12 and oz_swing < 25:
                justifications.append(f"Plate discipline ({oz_swing:.1f}% chase) vs poor {pitch_name} command")
                
        # Usage exploitation
        if usage > 30:
            justifications.append(f"Over-reliance on weak {pitch_name} ({usage:.1f}% usage, .{int(ba_against*1000)} BA)")
        elif usage > 25:
            justifications.append(f"High usage vulnerable {pitch_name} ({usage:.1f}% usage)")
        
        # Add specific statistical evidence
        if ba_against > 0.290:
            justifications.append(f"Extremely hittable {pitch_name} (.{int(ba_against*1000)} BA allowed)")
        elif ba_against > 0.270:
            justifications.append(f"Above average hittability (.{int(ba_against*1000)} BA)")
        
        if pitch_whiff < 22:
            justifications.append(f"Poor {pitch_name} swing-and-miss ({pitch_whiff:.1f}% whiff rate)")
        
        # Combine justifications
        if justifications:
            main_justification = justifications[0]
            if len(justifications) > 1:
                main_justification += f" | {justifications[1]}"
            return main_justification
        else:
            # Fallback
            return f"Batter profile matches {pitch_name} vulnerability ({highest_vulnerability}/100 exploit potential)"
    
    def save_enhanced_results(self, exploiters, date):
        """Save enhanced analysis results"""
        output_dir = self.data_path / "weakspot_exploiters"
        output_dir.mkdir(exist_ok=True)
        
        result = {
            "generated": datetime.now().isoformat(),
            "date": date,
            "analysisType": "enhanced_comprehensive_weakspot_analysis",
            "version": "3.0",
            "dataQuality": "professional_grade_with_situational_intelligence",
            "enhancementsUsed": [
                "Real barrel rate analysis with league context",
                "Recent performance trend integration",
                "Situational advantage detection",
                "Park factor adjustments",
                "Weather context integration (Phase 4)",
                "Recent form and momentum analysis (Phase 5)",
                "Lineup position and protection analysis (Phase 6)",
                "Platoon advantage analysis",
                "Exploitation window matching",
                "Dynamic threshold adjustment",
                "Fatigue and workload considerations"
            ],
            "dataSourcesUsed": [
                "hitter_exit_velocity_2025.csv - Real contact quality metrics",
                "pitcher_exit_velocity_2025.csv - Real contact quality allowed",
                "custom_batter_2025.csv - Comprehensive xwOBA, xBA, xSLG data",
                "custom_pitcher_2025.csv - Complete arsenal with expected stats",
                "pitcherpitcharsenalstats_2025.csv - Pitch-by-pitch effectiveness",
                "batters-batted-ball-*-handedness-2025.csv - 16-scenario analysis",
                "Recent game data - Performance trends",
                "Stadium HR analysis - Park factors",
                "starting_lineups.json - Game context",
                "rosters.json - Player metadata"
            ],
            "professionalFeatures": [
                "Real barrel rate vulnerability analysis with percentile context",
                "Expected performance gap regression detection",
                "Professional batter classification system",
                "Combined scoring algorithm with situational weighting",
                "Multi-tier data quality assessment",
                "Advanced confidence calibration",
                "Expected performance ranges",
                "Modern analytics integration",
                "Trend-based exploitation",
                "Situational advantage identification"
            ],
            "qualityMetrics": {
                "totalExploiters": len(exploiters),
                "averageConfidence": round(sum(e['confidence'] for e in exploiters) / len(exploiters), 3) if exploiters else 0,
                "averageExploitIndex": round(sum(e['exploitIndex'] for e in exploiters) / len(exploiters), 1) if exploiters else 0,
                "averageCombinedScore": round(sum(e['combinedScore'] for e in exploiters) / len(exploiters), 1) if exploiters else 0,
                "eliteOpportunities": len([e for e in exploiters if e['batterClassification'] in ['elite_opportunity', 'strong_opportunity']]),
                "highConfidenceCount": len([e for e in exploiters if e['confidence'] >= 0.75]),
                "situationalAdvantagesCount": len([e for e in exploiters if e.get('situationalAdvantages')])
            },
            "exploiters": exploiters
        }
        
        # Save date-specific file
        date_file = output_dir / f"enhanced_weakspot_exploiters_{date}.json"
        with open(date_file, 'w') as f:
            json.dump(result, f, indent=2)
        
        # Save latest file
        latest_file = output_dir / "enhanced_weakspot_exploiters_latest.json"
        with open(latest_file, 'w') as f:
            json.dump(result, f, indent=2)
        
        # Also save to standard location for compatibility
        standard_latest = output_dir / "weakspot_exploiters_latest.json"
        with open(standard_latest, 'w') as f:
            json.dump(result, f, indent=2)
        
        # CRITICAL: Save to the exact filename the React component expects
        standard_date_file = output_dir / f"weakspot_exploiters_{date}.json"
        with open(standard_date_file, 'w') as f:
            json.dump(result, f, indent=2)
        
        print(f"âœ… Enhanced analysis results saved:")
        print(f"   ðŸ“„ {date_file}")
        print(f"   ðŸ“„ {latest_file}")
        print(f"   ðŸ“„ {standard_latest} (compatibility)")
        print(f"   ðŸ“„ {standard_date_file} (REACT COMPONENT FILE)")
        
        # Display quality summary
        metrics = result['qualityMetrics']
        print(f"ðŸ“Š Quality Summary:")
        print(f"   ðŸŽ¯ {metrics['totalExploiters']} total exploiters")
        print(f"   ðŸ“ˆ {metrics['averageConfidence']:.3f} average confidence")
        print(f"   âš¡ {metrics['averageExploitIndex']:.1f} average exploit index")
        print(f"   ðŸ† {metrics['eliteOpportunities']} elite opportunities")
        print(f"   âœ… {metrics['highConfidenceCount']} high confidence plays")
        print(f"   ðŸŽ¯ {metrics['situationalAdvantagesCount']} with situational advantages")


    # PHASE 1 ENHANCEMENT: New CSV data loading methods
    def load_batted_ball_handedness_data(self):
        """Load batted ball data by handedness matchups (L/L, L/R, R/L, R/R)"""
        print("ðŸŽ¯ Loading batted ball handedness matchup data...")
        
        handedness_combinations = [
            ('bat-left-pitch-hand-left', 'L', 'L'),
            ('bat-left-pitch-hand-right', 'L', 'R'),
            ('bat-right-pitch-hand-left', 'R', 'L'),
            ('bat-right-pitch-hand-right', 'R', 'R')
        ]
        
        loaded_files = 0
        total_players = 0
        
        for file_pattern, bat_hand, pitch_hand in handedness_combinations:
            # Try multiple years
            for year in [2025, 2024, 2023, 2022]:
                file_name = f"batters-batted-ball-{file_pattern}-{year}.csv"
                file_path = self.stats_path / file_name
                
                if file_path.exists():
                    try:
                        with open(file_path, 'r') as f:
                            reader = csv.DictReader(f)
                            
                            for row in reader:
                                player_name = self.normalize_name(row.get('name', ''))
                                if not player_name:
                                    continue
                                
                                # Initialize player data structure
                                if player_name not in self.batted_ball_handedness:
                                    self.batted_ball_handedness[player_name] = {}
                                
                                matchup_key = f"{bat_hand}v{pitch_hand}"
                                
                                # Store comprehensive batted ball data
                                self.batted_ball_handedness[player_name][matchup_key] = {
                                    'year': year,
                                    'bbe': int(row.get('bbe', 0)),
                                    'gb_rate': float(row.get('gb_rate', 0)),
                                    'air_rate': float(row.get('air_rate', 0)),
                                    'fb_rate': float(row.get('fb_rate', 0)),
                                    'ld_rate': float(row.get('ld_rate', 0)),
                                    'pu_rate': float(row.get('pu_rate', 0)),
                                    'pull_rate': float(row.get('pull_rate', 0)),
                                    'straight_rate': float(row.get('straight_rate', 0)),
                                    'oppo_rate': float(row.get('oppo_rate', 0)),
                                    'pull_gb_rate': float(row.get('pull_gb_rate', 0)),
                                    'straight_gb_rate': float(row.get('straight_gb_rate', 0)),
                                    'oppo_gb_rate': float(row.get('oppo_gb_rate', 0)),
                                    'pull_air_rate': float(row.get('pull_air_rate', 0)),
                                    'straight_air_rate': float(row.get('straight_air_rate', 0)),
                                    'oppo_air_rate': float(row.get('oppo_air_rate', 0))
                                }
                                total_players += 1
                        
                        loaded_files += 1
                        print(f"   âœ… Loaded {file_name}")
                        break  # Use most recent year available
                        
                    except Exception as e:
                        print(f"   âš ï¸ Could not load {file_name}: {e}")
                        continue
        
        print(f"   ðŸ“Š Loaded {loaded_files} handedness files with {total_players} player-matchup combinations")
        print(f"   ðŸ“ˆ Unique players with handedness data: {len(self.batted_ball_handedness)}")
    
    def load_swing_path_data(self):
        """Load swing path and mechanics data (all/LHP/RHP splits)"""
        print("âš¡ Loading swing path and mechanics data...")
        
        swing_path_files = [
            ('batters-swing-path-all.csv', 'all'),
            ('batters-swing-path-LHP.csv', 'vs_LHP'),
            ('batters-swing-path-RHP.csv', 'vs_RHP')
        ]
        
        loaded_files = 0
        total_players = 0
        
        for file_name, context in swing_path_files:
            file_path = self.stats_path / file_name
            
            if file_path.exists():
                try:
                    with open(file_path, 'r') as f:
                        reader = csv.DictReader(f)
                        
                        for row in reader:
                            player_name = self.normalize_name(row.get('name', ''))
                            if not player_name:
                                continue
                            
                            # Initialize player swing data
                            if player_name not in self.swing_path_data:
                                self.swing_path_data[player_name] = {}
                            
                            # Store swing mechanics data
                            self.swing_path_data[player_name][context] = {
                                'side': row.get('side', ''),
                                'avg_bat_speed': float(row.get('avg_bat_speed', 0)),
                                'swing_tilt': float(row.get('swing_tilt', 0)),
                                'attack_angle': float(row.get('attack_angle', 0)),
                                'attack_direction': float(row.get('attack_direction', 0)),
                                'ideal_attack_angle_rate': float(row.get('ideal_attack_angle_rate', 0)),
                                'avg_intercept_y_vs_plate': float(row.get('avg_intercept_y_vs_plate', 0)),
                                'avg_intercept_y_vs_batter': float(row.get('avg_intercept_y_vs_batter', 0)),
                                'avg_batter_y_position': float(row.get('avg_batter_y_position', 0)),
                                'avg_batter_x_position': float(row.get('avg_batter_x_position', 0)),
                                'competitive_swings': int(row.get('competitive_swings', 0))
                            }
                            total_players += 1
                    
                    loaded_files += 1
                    print(f"   âœ… Loaded {file_name}")
                    
                except Exception as e:
                    print(f"   âš ï¸ Could not load {file_name}: {e}")
        
        print(f"   ðŸ“Š Loaded {loaded_files} swing path files with {total_players} player-context combinations")
        print(f"   ðŸ“ˆ Unique players with swing path data: {len(self.swing_path_data)}")
    
    def load_historical_multi_year_data(self):
        """Load historical data for multi-year trend analysis (2022-2025)"""
        print("ðŸ“š Loading historical multi-year data for trend analysis...")
        
        data_types = [
            ('hitter_exit_velocity', 'hitter_exit_velocity'),
            ('pitcher_exit_velocity', 'pitcher_exit_velocity'),
            ('hitterpitcharsenalstats', 'hitter_arsenal'),
            ('pitcherpitcharsenalstats', 'pitcher_arsenal')
        ]
        
        loaded_files = 0
        total_records = 0
        
        for year in [2022, 2023, 2024, 2025]:
            self.historical_data[year] = {}
            
            for file_prefix, data_type in data_types:
                file_name = f"{file_prefix}_{year}.csv"
                file_path = self.stats_path / file_name
                
                if file_path.exists():
                    try:
                        self.historical_data[year][data_type] = {}
                        
                        with open(file_path, 'r', encoding='utf-8-sig') as f:
                            reader = csv.DictReader(f)
                            
                            for row in reader:
                                # Handle multiple possible field name variations
                                player_name = None
                                for possible_field in ['last_name, first_name', 'name', 'player_name']:
                                    # Check both original and BOM-prefixed field names
                                    if possible_field in row and row[possible_field]:
                                        player_name = row[possible_field]
                                        break
                                    # Also check with BOM prefix and quotes
                                    bom_field = '\ufeff"' + possible_field + '"'
                                    if bom_field in row and row[bom_field]:
                                        player_name = row[bom_field]
                                        break
                                
                                if not player_name:
                                    continue
                                
                                # Clean and normalize the player name
                                player_name = str(player_name).strip('"').strip()
                                
                                # Convert "Last, First" to "First Last" format for consistency
                                if ', ' in player_name:
                                    parts = player_name.split(', ')
                                    if len(parts) == 2:
                                        player_name = f"{parts[1]} {parts[0]}"
                                
                                player_name = self.normalize_name(player_name)
                                if not player_name:
                                    continue
                                
                                # Store the row data with all available fields
                                self.historical_data[year][data_type][player_name] = dict(row)
                                total_records += 1
                        
                        loaded_files += 1
                        print(f"   âœ… Loaded {file_name} ({len(self.historical_data[year][data_type])} players)")
                        
                    except Exception as e:
                        print(f"   âš ï¸ Could not load {file_name}: {e}")
        
        print(f"   ðŸ“Š Loaded {loaded_files} historical files with {total_records} total records")
        print(f"   ðŸ“ˆ Multi-year data available for years: {list(self.historical_data.keys())}")
    
    def load_comprehensive_batter_stats(self):
        """Load comprehensive batter statistics with 150+ metrics"""
        print("ðŸŽ¯ Loading comprehensive batter statistics...")
        
        file_path = self.stats_path / "custom_batter_2025.csv"
        
        if not file_path.exists():
            print("   âš ï¸ Custom batter 2025 file not found")
            return
        
        try:
            with open(file_path, 'r', encoding='utf-8-sig') as f:
                reader = csv.DictReader(f)
                
                # Clean field names to remove BOM and quotes
                fieldnames = [name.replace('\ufeff', '').strip('"').strip() for name in reader.fieldnames]
                
                for row in reader:
                    # Handle multiple possible field name variations with cleaned field names
                    player_name = None
                    for possible_field in ['last_name, first_name', 'last_name,first_name', 'name', 'player_name']:
                        # Check both original and cleaned field names
                        if possible_field in row and row[possible_field]:
                            player_name = row[possible_field]
                            break
                        # Also check with BOM prefix
                        bom_field = '\ufeff"' + possible_field + '"'
                        if bom_field in row and row[bom_field]:
                            player_name = row[bom_field]
                            break
                    
                    if not player_name:
                        continue
                    
                    # Clean and normalize the player name
                    player_name = str(player_name).strip('"').strip()
                    
                    # Convert "Last, First" to "First Last" format for consistency
                    if ', ' in player_name:
                        parts = player_name.split(', ')
                        if len(parts) == 2:
                            player_name = f"{parts[1]} {parts[0]}"
                    
                    player_name = self.normalize_name(player_name)
                    if not player_name:
                        continue
                    
                    # Store comprehensive stats (150+ fields available)
                    self.comprehensive_batter_stats[player_name] = {
                        'player_id': row.get('player_id', ''),
                        'year': row.get('year', '2025'),
                        'player_age': self.safe_int(row.get('player_age', 0)),
                        'ab': self.safe_int(row.get('ab', 0)),
                        'pa': self.safe_int(row.get('pa', 0)),
                        'hit': self.safe_int(row.get('hit', 0)),
                        'home_run': self.safe_int(row.get('home_run', 0)),
                        'strikeout': self.safe_int(row.get('strikeout', 0)),
                        'walk': self.safe_int(row.get('walk', 0)),
                        'k_percent': self.safe_float(row.get('k_percent', 0)),
                        'bb_percent': self.safe_float(row.get('bb_percent', 0)),
                        'batting_avg': self.safe_float(row.get('batting_avg', 0)),
                        'slg_percent': self.safe_float(row.get('slg_percent', 0)),
                        'on_base_percent': self.safe_float(row.get('on_base_percent', 0)),
                        'on_base_plus_slg': self.safe_float(row.get('on_base_plus_slg', 0)),
                        'isolated_power': self.safe_float(row.get('isolated_power', 0)),
                        'babip': self.safe_float(row.get('babip', 0)),
                        # Expected stats
                        'xba': self.safe_float(row.get('xba', 0)),
                        'xslg': self.safe_float(row.get('xslg', 0)),
                        'woba': self.safe_float(row.get('woba', 0)),
                        'xwoba': self.safe_float(row.get('xwoba', 0)),
                        'xobp': self.safe_float(row.get('xobp', 0)),
                        'xiso': self.safe_float(row.get('xiso', 0)),
                        # Contact quality
                        'exit_velocity_avg': self.safe_float(row.get('exit_velocity_avg', 0)),
                        'launch_angle_avg': self.safe_float(row.get('launch_angle_avg', 0)),
                        'barrel': self.safe_int(row.get('barrel', 0)),
                        'barrel_batted_rate': self.safe_float(row.get('barrel_batted_rate', 0)),
                        'hard_hit_percent': self.safe_float(row.get('hard_hit_percent', 0)),
                        # Swing mechanics
                        'avg_swing_speed': self.safe_float(row.get('avg_swing_speed', 0)),
                        'attack_angle': self.safe_float(row.get('attack_angle', 0)),
                        'attack_direction': self.safe_float(row.get('attack_direction', 0)),
                        'ideal_angle_rate': self.safe_float(row.get('ideal_angle_rate', 0)),
                        # Zone discipline
                        'z_swing_percent': self.safe_float(row.get('z_swing_percent', 0)),
                        'oz_swing_percent': self.safe_float(row.get('oz_swing_percent', 0)),
                        'whiff_percent': self.safe_float(row.get('whiff_percent', 0)),
                        'swing_percent': self.safe_float(row.get('swing_percent', 0)),
                        # Directional tendencies
                        'pull_percent': self.safe_float(row.get('pull_percent', 0)),
                        'straightaway_percent': self.safe_float(row.get('straightaway_percent', 0)),
                        'opposite_percent': self.safe_float(row.get('opposite_percent', 0)),
                        'groundballs_percent': self.safe_float(row.get('groundballs_percent', 0)),
                        'flyballs_percent': self.safe_float(row.get('flyballs_percent', 0)),
                        'linedrives_percent': self.safe_float(row.get('linedrives_percent', 0)),
                        'popups_percent': self.safe_float(row.get('popups_percent', 0)),
                        # Speed
                        'sprint_speed': self.safe_float(row.get('sprint_speed', 0))
                    }
            
            print(f"   ðŸ“Š Loaded comprehensive stats for {len(self.comprehensive_batter_stats)} batters")
            print(f"   ðŸ“ˆ Each player has 50+ key metrics available for analysis")
            
        except Exception as e:
            print(f"   âš ï¸ Could not load comprehensive batter stats: {e}")
    
    # PHASE 1 ENHANCEMENT: Methods to analyze new data sources
    def analyze_handedness_matchup_advantage(self, batter_name, pitcher_name):
        """Analyze handedness-specific batted ball advantages"""
        normalized_batter = self.normalize_name(batter_name)
        
        # Get handedness for both players
        batter_hand = self.get_batter_handedness(batter_name)
        pitcher_hand = self.get_pitcher_handedness(pitcher_name)
        
        matchup_key = f"{batter_hand}v{pitcher_hand}"
        
        # Initialize results
        handedness_analysis = {
            'matchup_type': matchup_key,
            'advantage_score': 0,
            'key_advantages': [],
            'batted_ball_profile': {},
            'confidence': 0.3
        }
        
        # Look for handedness-specific batted ball data
        if normalized_batter in self.batted_ball_handedness:
            matchup_data = self.batted_ball_handedness[normalized_batter].get(matchup_key)
            
            if matchup_data:
                # Analyze advantageous patterns
                fb_rate = matchup_data.get('fb_rate', 0)
                ld_rate = matchup_data.get('ld_rate', 0)
                pull_rate = matchup_data.get('pull_rate', 0)
                air_rate = matchup_data.get('air_rate', 0)
                
                # Store profile for reference
                handedness_analysis['batted_ball_profile'] = matchup_data
                handedness_analysis['confidence'] = 0.8
                
                # Analyze advantages
                advantage_score = 0
                
                # High fly ball rate = power potential
                if fb_rate > 0.35:  # 35%+ fly ball rate
                    advantage_score += 15
                    handedness_analysis['key_advantages'].append(f"High fly ball rate vs {pitcher_hand}HP ({fb_rate:.1%})")
                
                # High line drive rate = consistent contact
                if ld_rate > 0.25:  # 25%+ line drive rate
                    advantage_score += 12
                    handedness_analysis['key_advantages'].append(f"Strong line drive rate vs {pitcher_hand}HP ({ld_rate:.1%})")
                
                # Pull tendency with high air rate = power alley
                if pull_rate > 0.40 and air_rate > 0.50:
                    advantage_score += 18
                    handedness_analysis['key_advantages'].append(f"Power alley tendency ({pull_rate:.1%} pull, {air_rate:.1%} air)")
                
                # Opposite field with air balls = all-field power
                if matchup_data.get('oppo_air_rate', 0) > 0.15:
                    advantage_score += 10
                    handedness_analysis['key_advantages'].append("All-field power approach")
                
                handedness_analysis['advantage_score'] = advantage_score
        
        return handedness_analysis
    
    def analyze_swing_path_optimization(self, batter_name, pitcher_name):
        """Analyze swing path matchup optimization"""
        normalized_batter = self.normalize_name(batter_name)
        pitcher_hand = self.get_pitcher_handedness(pitcher_name)
        
        # Determine swing context based on pitcher handedness
        swing_context = 'vs_LHP' if pitcher_hand == 'L' else 'vs_RHP'
        
        swing_analysis = {
            'optimization_score': 0,
            'key_optimizations': [],
            'swing_mechanics': {},
            'matchup_rating': 'neutral',
            'confidence': 0.3
        }
        
        # Check for swing path data
        if normalized_batter in self.swing_path_data:
            # Try specific handedness first, fall back to 'all'
            swing_data = (self.swing_path_data[normalized_batter].get(swing_context) or 
                         self.swing_path_data[normalized_batter].get('all'))
            
            if swing_data:
                swing_analysis['swing_mechanics'] = swing_data
                swing_analysis['confidence'] = 0.8
                
                # Analyze optimization factors
                optimization_score = 0
                
                # Elite bat speed = power potential
                bat_speed = swing_data.get('avg_bat_speed', 0)
                if bat_speed > 75:  # Elite bat speed
                    optimization_score += 20
                    swing_analysis['key_optimizations'].append(f"Elite bat speed vs {pitcher_hand}HP ({bat_speed:.1f} mph)")
                elif bat_speed > 72:  # Above average
                    optimization_score += 12
                    swing_analysis['key_optimizations'].append(f"Above-average bat speed ({bat_speed:.1f} mph)")
                
                # Optimal attack angle for power
                attack_angle = swing_data.get('attack_angle', 0)
                if 8 <= attack_angle <= 25:  # Optimal range for power
                    optimization_score += 15
                    swing_analysis['key_optimizations'].append(f"Optimal attack angle for power ({attack_angle:.1f}Â°)")
                elif 5 <= attack_angle <= 30:  # Good range
                    optimization_score += 8
                    swing_analysis['key_optimizations'].append(f"Good attack angle ({attack_angle:.1f}Â°)")
                
                # High ideal angle rate = swing optimization
                ideal_rate = swing_data.get('ideal_attack_angle_rate', 0)
                if ideal_rate > 0.60:  # 60%+ ideal swings
                    optimization_score += 18
                    swing_analysis['key_optimizations'].append(f"Excellent swing optimization ({ideal_rate:.1%} ideal)")
                elif ideal_rate > 0.50:  # 50%+ ideal swings
                    optimization_score += 10
                    swing_analysis['key_optimizations'].append(f"Good swing optimization ({ideal_rate:.1%} ideal)")
                
                # Sample size consideration
                competitive_swings = swing_data.get('competitive_swings', 0)
                if competitive_swings >= 500:
                    optimization_score += 5
                    swing_analysis['key_optimizations'].append(f"Large sample size ({competitive_swings} swings)")
                
                swing_analysis['optimization_score'] = optimization_score
                
                # Determine overall matchup rating
                if optimization_score >= 40:
                    swing_analysis['matchup_rating'] = 'excellent'
                elif optimization_score >= 25:
                    swing_analysis['matchup_rating'] = 'strong'
                elif optimization_score >= 15:
                    swing_analysis['matchup_rating'] = 'good'
                else:
                    swing_analysis['matchup_rating'] = 'neutral'
        
        return swing_analysis
    
    def analyze_multi_year_pitcher_regression(self, pitcher_name):
        """Analyze pitcher performance regression across multiple years"""
        normalized_pitcher = self.normalize_name(pitcher_name)
        
        regression_analysis = {
            'regression_score': 0,
            'regression_indicators': [],
            'year_over_year_changes': {},
            'overall_trend': 'stable',
            'confidence': 0.3
        }
        
        # Collect data from available years
        pitcher_data_by_year = {}
        for year in [2025, 2024, 2023, 2022]:
            if year in self.historical_data:
                # Check pitcher exit velocity data
                if 'pitcher_exit_velocity' in self.historical_data[year]:
                    if normalized_pitcher in self.historical_data[year]['pitcher_exit_velocity']:
                        pitcher_data_by_year[year] = self.historical_data[year]['pitcher_exit_velocity'][normalized_pitcher]
        
        # Need at least 2 years for comparison
        if len(pitcher_data_by_year) >= 2:
            regression_analysis['confidence'] = 0.8
            years = sorted(pitcher_data_by_year.keys(), reverse=True)
            
            # Compare most recent vs previous year
            if len(years) >= 2:
                current_year = years[0]
                previous_year = years[1]
                
                current_data = pitcher_data_by_year[current_year]
                previous_data = pitcher_data_by_year[previous_year]
                
                regression_score = 0
                
                # Barrel rate regression
                try:
                    current_barrels = float(current_data.get('real_barrel_rate_allowed', 0))
                    previous_barrels = float(previous_data.get('real_barrel_rate_allowed', 0))
                    
                    if current_barrels > previous_barrels + 2.0:  # 2+ percentage point increase
                        regression_score += 25
                        regression_analysis['regression_indicators'].append(
                            f"Barrel rate regression: {previous_barrels:.1f}% ({previous_year}) â†’ {current_barrels:.1f}% ({current_year})"
                        )
                    elif current_barrels > previous_barrels + 1.0:  # 1+ percentage point increase
                        regression_score += 15
                        regression_analysis['regression_indicators'].append(
                            f"Moderate barrel rate increase: {previous_barrels:.1f}% â†’ {current_barrels:.1f}%"
                        )
                except (ValueError, TypeError):
                    pass
                
                # Hard hit rate regression
                try:
                    current_hard_hit = float(current_data.get('hard_hit_percent_allowed', 0))
                    previous_hard_hit = float(previous_data.get('hard_hit_percent_allowed', 0))
                    
                    if current_hard_hit > previous_hard_hit + 3.0:  # 3+ percentage point increase
                        regression_score += 20
                        regression_analysis['regression_indicators'].append(
                            f"Hard hit regression: {previous_hard_hit:.1f}% â†’ {current_hard_hit:.1f}%"
                        )
                except (ValueError, TypeError):
                    pass
                
                # Exit velocity regression
                try:
                    current_ev = float(current_data.get('avg_exit_velocity_allowed', 0))
                    previous_ev = float(previous_data.get('avg_exit_velocity_allowed', 0))
                    
                    if current_ev > previous_ev + 1.5:  # 1.5+ mph increase
                        regression_score += 18
                        regression_analysis['regression_indicators'].append(
                            f"Exit velocity regression: {previous_ev:.1f} â†’ {current_ev:.1f} mph"
                        )
                except (ValueError, TypeError):
                    pass
                
                # Store year-over-year changes
                regression_analysis['year_over_year_changes'] = {
                    'comparison': f"{previous_year} vs {current_year}",
                    'current_data': current_data,
                    'previous_data': previous_data
                }
                
                regression_analysis['regression_score'] = regression_score
                
                # Determine overall trend
                if regression_score >= 30:
                    regression_analysis['overall_trend'] = 'significant_regression'
                elif regression_score >= 15:
                    regression_analysis['overall_trend'] = 'moderate_regression'
                elif regression_score >= 5:
                    regression_analysis['overall_trend'] = 'slight_regression'
                else:
                    regression_analysis['overall_trend'] = 'stable'
        
        return regression_analysis
    
    def calculate_enhanced_data_quality_score(self, batter_name, pitcher_name):
        """Calculate comprehensive data quality score based on available data sources"""
        normalized_batter = self.normalize_name(batter_name)
        normalized_pitcher = self.normalize_name(pitcher_name)
        
        quality_factors = {
            'base_data': 0,
            'handedness_data': 0,
            'swing_path_data': 0,
            'historical_data': 0,
            'comprehensive_stats': 0
        }
        
        # Base data availability (current system)
        if normalized_batter in self.hitter_exit_velocity:
            quality_factors['base_data'] += 20
        if normalized_pitcher in self.pitcher_exit_velocity:
            quality_factors['base_data'] += 20
        if normalized_batter in self.custom_batters:
            quality_factors['base_data'] += 10
        if normalized_pitcher in self.custom_pitchers:
            quality_factors['base_data'] += 10
        
        # Handedness-specific data
        if normalized_batter in self.batted_ball_handedness:
            batter_hand = self.get_batter_handedness(batter_name)
            pitcher_hand = self.get_pitcher_handedness(pitcher_name)
            matchup_key = f"{batter_hand}v{pitcher_hand}"
            
            if matchup_key in self.batted_ball_handedness[normalized_batter]:
                quality_factors['handedness_data'] = 20
            else:
                quality_factors['handedness_data'] = 10  # Has some handedness data
        
        # Swing path data
        if normalized_batter in self.swing_path_data:
            pitcher_hand = self.get_pitcher_handedness(pitcher_name)
            swing_context = 'vs_LHP' if pitcher_hand == 'L' else 'vs_RHP'
            
            if swing_context in self.swing_path_data[normalized_batter]:
                quality_factors['swing_path_data'] = 15
            elif 'all' in self.swing_path_data[normalized_batter]:
                quality_factors['swing_path_data'] = 10
        
        # Historical multi-year data
        historical_years = 0
        for year in [2025, 2024, 2023, 2022]:
            if year in self.historical_data:
                if ('pitcher_exit_velocity' in self.historical_data[year] and 
                    normalized_pitcher in self.historical_data[year]['pitcher_exit_velocity']):
                    historical_years += 1
        
        if historical_years >= 3:
            quality_factors['historical_data'] = 15
        elif historical_years >= 2:
            quality_factors['historical_data'] = 10
        elif historical_years >= 1:
            quality_factors['historical_data'] = 5
        
        # Comprehensive batter stats
        if normalized_batter in self.comprehensive_batter_stats:
            quality_factors['comprehensive_stats'] = 10
        
        # Calculate overall quality score (0-100)
        total_score = sum(quality_factors.values())
        
        # Determine quality level
        if total_score >= 80:
            quality_level = 'excellent'
        elif total_score >= 60:
            quality_level = 'good'
        elif total_score >= 40:
            quality_level = 'fair'
        else:
            quality_level = 'limited'
        
        return {
            'overall_score': total_score,
            'quality_level': quality_level,
            'factor_breakdown': quality_factors,
            'confidence_multiplier': min(1.0, total_score / 100.0)
        }


def main():
    """Main execution function for enhanced weakspot analysis"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Enhanced Weakspot Exploiters Analysis')
    parser.add_argument('--date', type=str, help='Target date (YYYY-MM-DD)', 
                        default=datetime.now().strftime('%Y-%m-%d'))
    
    args = parser.parse_args()
    target_date = args.date
    
    print(f"ðŸš€ Starting Enhanced Weakspot Exploiters Analysis V3.0 for {target_date}")
    print("ðŸ“Š Using professional-grade data with situational intelligence")
    
    try:
        analyzer = EnhancedWeakspotAnalyzer(target_date=target_date)
        exploiters = analyzer.generate_enhanced_weakspot_exploiters(target_date)
        analyzer.save_enhanced_results(exploiters, target_date)
        
        print(f"ðŸŽ‰ Enhanced analysis complete: {len(exploiters)} high-grade weakspot exploiters generated")
        print("ðŸ”¬ Analysis includes trends, park factors, and situational advantages")
        
    except Exception as e:
        print(f"âŒ Error during enhanced analysis: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()